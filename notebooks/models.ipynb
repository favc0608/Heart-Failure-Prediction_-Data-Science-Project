{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30168a6c",
   "metadata": {},
   "source": [
    "# Heart Disease Modeling Notebook\n",
    "This notebook documents the steps taken to train and evaluate models for predicting heart disease.\n",
    "All narrative, findings, and recommendations are written in English for inclusion in the project's GitHub.\n",
    "\n",
    "Run cells sequentially. The `src.models` module contains helper functions used below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d990593a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data handling libraries\n",
    "import pandas as pd\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a4e299e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modeling, evaluation and hyperparameter search libraries\n",
    "import joblib\n",
    "import optuna\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier, StackingClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.inspection import permutation_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e5f6a1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>ChestPainType</th>\n",
       "      <th>RestingBP</th>\n",
       "      <th>Cholesterol</th>\n",
       "      <th>FastingBS</th>\n",
       "      <th>RestingECG</th>\n",
       "      <th>MaxHR</th>\n",
       "      <th>ExerciseAngina</th>\n",
       "      <th>Oldpeak</th>\n",
       "      <th>ST_Slope</th>\n",
       "      <th>HeartDisease</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40</td>\n",
       "      <td>M</td>\n",
       "      <td>ATA</td>\n",
       "      <td>140</td>\n",
       "      <td>289</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>172</td>\n",
       "      <td>N</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Up</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>49</td>\n",
       "      <td>F</td>\n",
       "      <td>NAP</td>\n",
       "      <td>160</td>\n",
       "      <td>180</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>156</td>\n",
       "      <td>N</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Flat</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37</td>\n",
       "      <td>M</td>\n",
       "      <td>ATA</td>\n",
       "      <td>130</td>\n",
       "      <td>283</td>\n",
       "      <td>0</td>\n",
       "      <td>ST</td>\n",
       "      <td>98</td>\n",
       "      <td>N</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Up</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>48</td>\n",
       "      <td>F</td>\n",
       "      <td>ASY</td>\n",
       "      <td>138</td>\n",
       "      <td>214</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>108</td>\n",
       "      <td>Y</td>\n",
       "      <td>1.5</td>\n",
       "      <td>Flat</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>54</td>\n",
       "      <td>M</td>\n",
       "      <td>NAP</td>\n",
       "      <td>150</td>\n",
       "      <td>195</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>122</td>\n",
       "      <td>N</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Up</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age Sex ChestPainType  RestingBP  Cholesterol  FastingBS RestingECG  MaxHR  \\\n",
       "0   40   M           ATA        140          289          0     Normal    172   \n",
       "1   49   F           NAP        160          180          0     Normal    156   \n",
       "2   37   M           ATA        130          283          0         ST     98   \n",
       "3   48   F           ASY        138          214          0     Normal    108   \n",
       "4   54   M           NAP        150          195          0     Normal    122   \n",
       "\n",
       "  ExerciseAngina  Oldpeak ST_Slope  HeartDisease  \n",
       "0              N      0.0       Up             0  \n",
       "1              N      1.0     Flat             1  \n",
       "2              N      0.0       Up             0  \n",
       "3              Y      1.5     Flat             1  \n",
       "4              N      0.0       Up             0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load cleaned dataset from project data folder\n",
    "ROOT = Path.cwd().parent\n",
    "path_raw = ROOT / \"data\" / \"processed\" / \"heart_clean.csv\"\n",
    "df = pd.read_csv(path_raw)\n",
    "# Inspect the first rows to confirm successful load\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20103f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure project root is on sys.path so `src` can be imported\n",
    "import sys\n",
    "root = Path.cwd().parent\n",
    "if str(root) not in sys.path:\n",
    "    sys.path.append(str(root))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b9de6a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import helper functions from the local `src.models` module\n",
    "from src.models import (\n",
    "    baseline,\n",
    "    randomforest_basemodel,\n",
    "    svc_basemodel,\n",
    "    decisiontree_basemodel,\n",
    "    xgboost_basemodel,\n",
    "    logistic_regression_optuna,\n",
    "    random_forest_optuna,\n",
    "    svc_optuna,\n",
    "    create_triple_stacking,\n",
    "    plot_ensemble_importance,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6d242a12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados por fold: [0.91183036 0.92375283 0.89801136 0.91619318 0.93920455]\n",
      "Media: 0.918 (+/- 0.027)\n",
      "Confusion Matrix:\n",
      "[[66  5]\n",
      " [11 68]]\n",
      "Score in Training set: 0.860738255033557\n",
      "Score in Test set: 0.8933333333333333\n",
      "\n",
      "--- Informe de Clasificación (Test Set) ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.93      0.89        71\n",
      "           1       0.93      0.86      0.89        79\n",
      "\n",
      "    accuracy                           0.89       150\n",
      "   macro avg       0.89      0.90      0.89       150\n",
      "weighted avg       0.90      0.89      0.89       150\n",
      "\n",
      "ROC-AUC Score in test: 0.9617\n",
      "ROC-AUC Score in train: 0.9283\n"
     ]
    }
   ],
   "source": [
    "# Evaluate a simple baseline model (Logistic Regression with default params)\n",
    "# This provides a performance floor to compare more complex models against\n",
    "baseline(df, \"HeartDisease\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "59ce634b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados por fold: [0.90987723 0.94061791 0.88039773 0.91789773 0.94517045]\n",
      "Media: 0.919 (+/- 0.047)\n",
      "Confusion Matrix:\n",
      "[[67  4]\n",
      " [ 9 70]]\n",
      "Score in Training set: 1.0\n",
      "Score in Test set: 0.9133333333333333\n",
      "\n",
      "--- Informe de Clasificación (Test Set) ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.94      0.91        71\n",
      "           1       0.95      0.89      0.92        79\n",
      "\n",
      "    accuracy                           0.91       150\n",
      "   macro avg       0.91      0.91      0.91       150\n",
      "weighted avg       0.92      0.91      0.91       150\n",
      "\n",
      "ROC-AUC Score: 0.9583\n",
      "ROC-AUC Score in train: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# Train and evaluate a Random Forest baseline to inspect non-linear performance\n",
    "randomforest_basemodel(df, \"HeartDisease\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cfbd663c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados por fold: [0.90457589 0.92517007 0.90170455 0.90653409 0.93096591]\n",
      "Media: 0.914 (+/- 0.024)\n",
      "Confusion Matrix:\n",
      "[[66  5]\n",
      " [10 69]]\n",
      "Score in Training set: 0.9010067114093959\n",
      "Score in Test set: 0.9\n",
      "\n",
      "--- Informe de Clasificación (Test Set) ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.93      0.90        71\n",
      "           1       0.93      0.87      0.90        79\n",
      "\n",
      "    accuracy                           0.90       150\n",
      "   macro avg       0.90      0.90      0.90       150\n",
      "weighted avg       0.90      0.90      0.90       150\n",
      "\n",
      "ROC-AUC Score: 0.9551\n",
      "ROC-AUC Score in train: 0.9565\n"
     ]
    }
   ],
   "source": [
    "# Evaluate a Support Vector Classifier baseline\n",
    "svc_basemodel(df, \"HeartDisease\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "736080e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados por fold: [0.77566964 0.80555556 0.70752841 0.73991477 0.75298295]\n",
      "Media: 0.756 (+/- 0.066)\n",
      "Confusion Matrix:\n",
      "[[64  7]\n",
      " [14 65]]\n",
      "Score in Training set: 1.0\n",
      "Score in Test set: 0.86\n",
      "\n",
      "--- Informe de Clasificación (Test Set) ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.90      0.86        71\n",
      "           1       0.90      0.82      0.86        79\n",
      "\n",
      "    accuracy                           0.86       150\n",
      "   macro avg       0.86      0.86      0.86       150\n",
      "weighted avg       0.86      0.86      0.86       150\n",
      "\n",
      "ROC-AUC Score: 0.8621\n",
      "ROC-AUC Score in train: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# Evaluate a Decision Tree baseline for interpretability comparisons\n",
    "decisiontree_basemodel(df, \"HeartDisease\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a47bc2ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados por fold: [0.89006696 0.91241497 0.87755682 0.90085227 0.93721591]\n",
      "Media: 0.904 (+/- 0.041)\n",
      "Confusion Matrix:\n",
      "[[67  4]\n",
      " [13 66]]\n",
      "Score in Training set: 1.0\n",
      "Score in Test set: 0.8866666666666667\n",
      "\n",
      "--- Informe de Clasificación (Test Set) ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.94      0.89        71\n",
      "           1       0.94      0.84      0.89        79\n",
      "\n",
      "    accuracy                           0.89       150\n",
      "   macro avg       0.89      0.89      0.89       150\n",
      "weighted avg       0.89      0.89      0.89       150\n",
      "\n",
      "ROC-AUC Score: 0.9472\n",
      "ROC-AUC Score in train: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# Evaluate an XGBoost baseline to capture boosted-tree performance\n",
    "xgboost_basemodel(df, \"HeartDisease\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3e81c35",
   "metadata": {},
   "source": [
    "### Observations and next steps\n",
    "We observed that baseline models provide different performance characteristics (linear vs tree-based).\n",
    "To improve results we perform hyperparameter optimization with Optuna and then build a stacked ensemble."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7b39bf49",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-30 17:12:49,037] A new study created in memory with name: no-name-e5be4412-04b5-426b-99b9-40e8b1f9d4ab\n",
      "[I 2025-12-30 17:12:49,136] Trial 0 finished with value: 0.5 and parameters: {'C': 0.0005687008172331411, 'solver': 'liblinear', 'penalty_lib': 'l1'}. Best is trial 0 with value: 0.5.\n",
      "[I 2025-12-30 17:12:49,226] Trial 1 finished with value: 0.9224937122736419 and parameters: {'C': 0.050451683919192566, 'solver': 'saga', 'penalty_saga': 'l2'}. Best is trial 1 with value: 0.9224937122736419.\n",
      "C:\\Users\\APUESTAS\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\APUESTAS\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\APUESTAS\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2025-12-30 17:12:49,951] Trial 2 finished with value: 0.921097208249497 and parameters: {'C': 46.52067477101703, 'solver': 'saga', 'penalty_saga': 'elasticnet', 'l1_ratio': 0.8273624007455836}. Best is trial 1 with value: 0.9224937122736419.\n",
      "[I 2025-12-30 17:12:50,013] Trial 3 finished with value: 0.5 and parameters: {'C': 2.181875510827362e-05, 'solver': 'liblinear', 'penalty_lib': 'l1'}. Best is trial 1 with value: 0.9224937122736419.\n",
      "[I 2025-12-30 17:12:50,173] Trial 4 finished with value: 0.9230105633802816 and parameters: {'C': 0.6539007042231095, 'solver': 'saga', 'penalty_saga': 'l2'}. Best is trial 4 with value: 0.9230105633802816.\n",
      "[I 2025-12-30 17:12:50,255] Trial 5 finished with value: 0.9211418511066398 and parameters: {'C': 30.13984986066986, 'solver': 'saga', 'penalty_saga': 'l2'}. Best is trial 4 with value: 0.9230105633802816.\n",
      "[I 2025-12-30 17:12:50,329] Trial 6 finished with value: 0.5 and parameters: {'C': 0.0003951712432624763, 'solver': 'liblinear', 'penalty_lib': 'l1'}. Best is trial 4 with value: 0.9230105633802816.\n",
      "[I 2025-12-30 17:12:50,405] Trial 7 finished with value: 0.8974402665995976 and parameters: {'C': 3.6391122346180825e-05, 'solver': 'saga', 'penalty_saga': 'l2'}. Best is trial 4 with value: 0.9230105633802816.\n",
      "[I 2025-12-30 17:12:50,470] Trial 8 finished with value: 0.5 and parameters: {'C': 0.0002992566268208374, 'solver': 'liblinear', 'penalty_lib': 'l1'}. Best is trial 4 with value: 0.9230105633802816.\n",
      "[I 2025-12-30 17:12:50,611] Trial 9 finished with value: 0.9232318913480885 and parameters: {'C': 0.4962567548189112, 'solver': 'saga', 'penalty_saga': 'l2'}. Best is trial 9 with value: 0.9232318913480885.\n",
      "C:\\Users\\APUESTAS\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\APUESTAS\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\APUESTAS\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\APUESTAS\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\APUESTAS\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "[I 2025-12-30 17:12:50,722] Trial 10 finished with value: 0.921097208249497 and parameters: {'C': 1.4088219364044945, 'solver': 'lbfgs', 'penalty_lbfgs': None}. Best is trial 9 with value: 0.9232318913480885.\n",
      "C:\\Users\\APUESTAS\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\APUESTAS\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\APUESTAS\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\APUESTAS\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\APUESTAS\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "[I 2025-12-30 17:12:50,822] Trial 11 finished with value: 0.9210525653923541 and parameters: {'C': 0.28354570167283644, 'solver': 'saga', 'penalty_saga': None}. Best is trial 9 with value: 0.9232318913480885.\n",
      "[I 2025-12-30 17:12:50,939] Trial 12 finished with value: 0.9222082494969819 and parameters: {'C': 1.8332908563374142, 'solver': 'lbfgs', 'penalty_lbfgs': 'l2'}. Best is trial 9 with value: 0.9232318913480885.\n",
      "[I 2025-12-30 17:12:51,053] Trial 13 finished with value: 0.7766794517102616 and parameters: {'C': 0.010642280606446716, 'solver': 'saga', 'penalty_saga': 'l1'}. Best is trial 9 with value: 0.9232318913480885.\n",
      "[I 2025-12-30 17:12:51,395] Trial 14 finished with value: 0.9214084507042253 and parameters: {'C': 4.3560225751844355, 'solver': 'saga', 'penalty_saga': 'l2'}. Best is trial 9 with value: 0.9232318913480885.\n",
      "[I 2025-12-30 17:12:51,494] Trial 15 finished with value: 0.9174081991951711 and parameters: {'C': 0.01611841404390658, 'solver': 'saga', 'penalty_saga': 'l2'}. Best is trial 9 with value: 0.9232318913480885.\n",
      "[I 2025-12-30 17:12:51,595] Trial 16 finished with value: 0.9232658450704226 and parameters: {'C': 0.17616161938861474, 'solver': 'lbfgs', 'penalty_lbfgs': 'l2'}. Best is trial 16 with value: 0.9232658450704226.\n",
      "[I 2025-12-30 17:12:51,696] Trial 17 finished with value: 0.9228162726358148 and parameters: {'C': 0.10852961534928353, 'solver': 'lbfgs', 'penalty_lbfgs': 'l2'}. Best is trial 16 with value: 0.9232658450704226.\n",
      "[I 2025-12-30 17:12:51,787] Trial 18 finished with value: 0.9079979879275655 and parameters: {'C': 0.003964916319614893, 'solver': 'lbfgs', 'penalty_lbfgs': 'l2'}. Best is trial 16 with value: 0.9232658450704226.\n",
      "C:\\Users\\APUESTAS\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\APUESTAS\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\APUESTAS\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\APUESTAS\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\APUESTAS\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "[I 2025-12-30 17:12:51,884] Trial 19 finished with value: 0.921097208249497 and parameters: {'C': 8.796821368496499, 'solver': 'lbfgs', 'penalty_lbfgs': None}. Best is trial 16 with value: 0.9232658450704226.\n",
      "[I 2025-12-30 17:12:51,980] Trial 20 finished with value: 0.9067492454728372 and parameters: {'C': 0.003419792281147955, 'solver': 'lbfgs', 'penalty_lbfgs': 'l2'}. Best is trial 16 with value: 0.9232658450704226.\n",
      "[I 2025-12-30 17:12:52,137] Trial 21 finished with value: 0.9247755281690141 and parameters: {'C': 0.37634357089450937, 'solver': 'saga', 'penalty_saga': 'l1'}. Best is trial 21 with value: 0.9247755281690141.\n",
      "[I 2025-12-30 17:12:52,278] Trial 22 finished with value: 0.9243699698189134 and parameters: {'C': 0.16805074131713102, 'solver': 'saga', 'penalty_saga': 'l1'}. Best is trial 21 with value: 0.9247755281690141.\n",
      "[I 2025-12-30 17:12:52,371] Trial 23 finished with value: 0.9229942152917505 and parameters: {'C': 0.12050667916684832, 'solver': 'lbfgs', 'penalty_lbfgs': 'l2'}. Best is trial 21 with value: 0.9247755281690141.\n",
      "[I 2025-12-30 17:12:52,488] Trial 24 finished with value: 0.9061503395372232 and parameters: {'C': 0.04183538622475249, 'solver': 'saga', 'penalty_saga': 'l1'}. Best is trial 21 with value: 0.9247755281690141.\n",
      "C:\\Users\\APUESTAS\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\APUESTAS\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\APUESTAS\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\APUESTAS\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\APUESTAS\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "[I 2025-12-30 17:12:52,580] Trial 25 finished with value: 0.921097208249497 and parameters: {'C': 7.927689174851856, 'solver': 'lbfgs', 'penalty_lbfgs': None}. Best is trial 21 with value: 0.9247755281690141.\n",
      "[I 2025-12-30 17:12:52,713] Trial 26 finished with value: 0.9248635563380281 and parameters: {'C': 0.30569047067409844, 'solver': 'saga', 'penalty_saga': 'l1'}. Best is trial 26 with value: 0.9248635563380281.\n",
      "[I 2025-12-30 17:12:52,873] Trial 27 finished with value: 0.9219856639839034 and parameters: {'C': 2.4287326457051246, 'solver': 'saga', 'penalty_saga': 'l1'}. Best is trial 26 with value: 0.9248635563380281.\n",
      "[I 2025-12-30 17:12:53,016] Trial 28 finished with value: 0.9245573440643863 and parameters: {'C': 0.5349850700578324, 'solver': 'saga', 'penalty_saga': 'l1'}. Best is trial 26 with value: 0.9248635563380281.\n",
      "[I 2025-12-30 17:12:53,086] Trial 29 finished with value: 0.9229219064386319 and parameters: {'C': 0.830332995502451, 'solver': 'liblinear', 'penalty_lib': 'l2'}. Best is trial 26 with value: 0.9248635563380281.\n",
      "[I 2025-12-30 17:12:53,155] Trial 30 finished with value: 0.5 and parameters: {'C': 0.0036743490808209336, 'solver': 'saga', 'penalty_saga': 'l1'}. Best is trial 26 with value: 0.9248635563380281.\n",
      "[I 2025-12-30 17:12:53,291] Trial 31 finished with value: 0.9248629275653923 and parameters: {'C': 0.28945459256269235, 'solver': 'saga', 'penalty_saga': 'l1'}. Best is trial 26 with value: 0.9248635563380281.\n",
      "[I 2025-12-30 17:12:53,403] Trial 32 finished with value: 0.9173622987927565 and parameters: {'C': 0.06284615759918591, 'solver': 'saga', 'penalty_saga': 'l1'}. Best is trial 26 with value: 0.9248635563380281.\n",
      "[I 2025-12-30 17:12:53,540] Trial 33 finished with value: 0.9249974849094567 and parameters: {'C': 0.3600846391208608, 'solver': 'saga', 'penalty_saga': 'l1'}. Best is trial 33 with value: 0.9249974849094567.\n",
      "[I 2025-12-30 17:12:53,863] Trial 34 finished with value: 0.9211418511066398 and parameters: {'C': 12.721393934762501, 'solver': 'saga', 'penalty_saga': 'l1'}. Best is trial 33 with value: 0.9249974849094567.\n",
      "[I 2025-12-30 17:12:54,000] Trial 35 finished with value: 0.9248201710261569 and parameters: {'C': 0.3699798527582513, 'solver': 'saga', 'penalty_saga': 'l1'}. Best is trial 33 with value: 0.9249974849094567.\n",
      "C:\\Users\\APUESTAS\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\APUESTAS\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\APUESTAS\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\APUESTAS\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\APUESTAS\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "[I 2025-12-30 17:12:54,078] Trial 36 finished with value: 0.9210525653923541 and parameters: {'C': 0.026912708935907585, 'solver': 'saga', 'penalty_saga': None}. Best is trial 33 with value: 0.9249974849094567.\n",
      "[I 2025-12-30 17:12:54,172] Trial 37 finished with value: 0.9210525653923541 and parameters: {'C': 76.98816042607719, 'solver': 'saga', 'penalty_saga': 'elasticnet', 'l1_ratio': 0.06864603397729613}. Best is trial 33 with value: 0.9249974849094567.\n",
      "[I 2025-12-30 17:12:54,253] Trial 38 finished with value: 0.922252263581489 and parameters: {'C': 1.234560756552504, 'solver': 'liblinear', 'penalty_lib': 'l2'}. Best is trial 33 with value: 0.9249974849094567.\n",
      "[I 2025-12-30 17:12:54,327] Trial 39 finished with value: 0.7764785588531187 and parameters: {'C': 0.010173510806623421, 'solver': 'saga', 'penalty_saga': 'l1'}. Best is trial 33 with value: 0.9249974849094567.\n",
      "[I 2025-12-30 17:12:54,793] Trial 40 finished with value: 0.9212305080482898 and parameters: {'C': 19.736071286831535, 'solver': 'saga', 'penalty_saga': 'l1'}. Best is trial 33 with value: 0.9249974849094567.\n",
      "[I 2025-12-30 17:12:54,914] Trial 41 finished with value: 0.9247315140845072 and parameters: {'C': 0.38075980275278726, 'solver': 'saga', 'penalty_saga': 'l1'}. Best is trial 33 with value: 0.9249974849094567.\n",
      "[I 2025-12-30 17:12:55,044] Trial 42 finished with value: 0.9199496981891349 and parameters: {'C': 0.07205900695300363, 'solver': 'saga', 'penalty_saga': 'l1'}. Best is trial 33 with value: 0.9249974849094567.\n",
      "[I 2025-12-30 17:12:55,165] Trial 43 finished with value: 0.9249528420523138 and parameters: {'C': 0.22261948801850637, 'solver': 'saga', 'penalty_saga': 'l1'}. Best is trial 33 with value: 0.9249974849094567.\n",
      "[I 2025-12-30 17:12:55,282] Trial 44 finished with value: 0.9249534708249497 and parameters: {'C': 0.21764828034832123, 'solver': 'saga', 'penalty_saga': 'l1'}. Best is trial 33 with value: 0.9249974849094567.\n",
      "[I 2025-12-30 17:12:55,354] Trial 45 finished with value: 0.9207092555331992 and parameters: {'C': 0.030291245855878952, 'solver': 'liblinear', 'penalty_lib': 'l2'}. Best is trial 33 with value: 0.9249974849094567.\n",
      "[I 2025-12-30 17:12:55,536] Trial 46 finished with value: 0.9218083501006035 and parameters: {'C': 3.4859696158157485, 'solver': 'saga', 'penalty_saga': 'l1'}. Best is trial 33 with value: 0.9249974849094567.\n",
      "[I 2025-12-30 17:12:55,802] Trial 47 finished with value: 0.9226986921529174 and parameters: {'C': 1.042000316686548, 'solver': 'saga', 'penalty_saga': 'elasticnet', 'l1_ratio': 0.2528556954325763}. Best is trial 33 with value: 0.9249974849094567.\n",
      "C:\\Users\\APUESTAS\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\APUESTAS\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\APUESTAS\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\APUESTAS\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\APUESTAS\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "[I 2025-12-30 17:12:55,881] Trial 48 finished with value: 0.9210525653923541 and parameters: {'C': 0.20293190977701484, 'solver': 'saga', 'penalty_saga': None}. Best is trial 33 with value: 0.9249974849094567.\n",
      "[I 2025-12-30 17:12:55,999] Trial 49 finished with value: 0.9212883551307847 and parameters: {'C': 0.07861781477050675, 'solver': 'saga', 'penalty_saga': 'l1'}. Best is trial 33 with value: 0.9249974849094567.\n",
      "[I 2025-12-30 17:12:56,087] Trial 50 finished with value: 0.9216750503018108 and parameters: {'C': 3.203778747480129, 'solver': 'liblinear', 'penalty_lib': 'l2'}. Best is trial 33 with value: 0.9249974849094567.\n",
      "[I 2025-12-30 17:12:56,245] Trial 51 finished with value: 0.9244265593561367 and parameters: {'C': 0.61615092907351, 'solver': 'saga', 'penalty_saga': 'l1'}. Best is trial 33 with value: 0.9249974849094567.\n",
      "[I 2025-12-30 17:12:56,404] Trial 52 finished with value: 0.9249069416498994 and parameters: {'C': 0.2797391407371832, 'solver': 'saga', 'penalty_saga': 'l1'}. Best is trial 33 with value: 0.9249974849094567.\n",
      "[I 2025-12-30 17:12:56,531] Trial 53 finished with value: 0.9249528420523138 and parameters: {'C': 0.22247864928177283, 'solver': 'saga', 'penalty_saga': 'l1'}. Best is trial 33 with value: 0.9249974849094567.\n",
      "[I 2025-12-30 17:12:56,656] Trial 54 finished with value: 0.9234330985915493 and parameters: {'C': 0.12303566331111404, 'solver': 'saga', 'penalty_saga': 'l1'}. Best is trial 33 with value: 0.9249974849094567.\n",
      "[I 2025-12-30 17:12:56,955] Trial 55 finished with value: 0.9227414486921528 and parameters: {'C': 1.5189378512649996, 'solver': 'saga', 'penalty_saga': 'elasticnet', 'l1_ratio': 0.9591742361419666}. Best is trial 33 with value: 0.9249974849094567.\n",
      "[I 2025-12-30 17:12:57,033] Trial 56 finished with value: 0.8665980256539235 and parameters: {'C': 0.01978433133131532, 'solver': 'saga', 'penalty_saga': 'l1'}. Best is trial 33 with value: 0.9249974849094567.\n",
      "[I 2025-12-30 17:12:57,111] Trial 57 finished with value: 0.5 and parameters: {'C': 0.0001084224900396612, 'solver': 'saga', 'penalty_saga': 'l1'}. Best is trial 33 with value: 0.9249974849094567.\n",
      "[I 2025-12-30 17:12:57,234] Trial 58 finished with value: 0.9249534708249497 and parameters: {'C': 0.21471772410664505, 'solver': 'saga', 'penalty_saga': 'l1'}. Best is trial 33 with value: 0.9249974849094567.\n",
      "C:\\Users\\APUESTAS\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\APUESTAS\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\APUESTAS\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\APUESTAS\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\APUESTAS\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "[I 2025-12-30 17:12:57,337] Trial 59 finished with value: 0.9210525653923541 and parameters: {'C': 0.14740663438494095, 'solver': 'saga', 'penalty_saga': None}. Best is trial 33 with value: 0.9249974849094567.\n",
      "[I 2025-12-30 17:12:57,447] Trial 60 finished with value: 0.9103137575452717 and parameters: {'C': 0.049679692452777216, 'solver': 'saga', 'penalty_saga': 'l1'}. Best is trial 33 with value: 0.9249974849094567.\n",
      "[I 2025-12-30 17:12:57,576] Trial 61 finished with value: 0.9249962273641851 and parameters: {'C': 0.24901191444275703, 'solver': 'saga', 'penalty_saga': 'l1'}. Best is trial 33 with value: 0.9249974849094567.\n",
      "[I 2025-12-30 17:12:57,714] Trial 62 finished with value: 0.9242473591549295 and parameters: {'C': 0.6553551440805127, 'solver': 'saga', 'penalty_saga': 'l1'}. Best is trial 33 with value: 0.9249974849094567.\n",
      "[I 2025-12-30 17:12:57,832] Trial 63 finished with value: 0.9234475603621732 and parameters: {'C': 0.22315916123149707, 'solver': 'saga', 'penalty_saga': 'l2'}. Best is trial 33 with value: 0.9249974849094567.\n",
      "[I 2025-12-30 17:12:57,950] Trial 64 finished with value: 0.9225792253521128 and parameters: {'C': 0.08750651460008162, 'solver': 'saga', 'penalty_saga': 'l1'}. Best is trial 33 with value: 0.9249974849094567.\n",
      "[I 2025-12-30 17:12:58,020] Trial 65 finished with value: 0.7764785588531187 and parameters: {'C': 0.008624967478271895, 'solver': 'saga', 'penalty_saga': 'l1'}. Best is trial 33 with value: 0.9249974849094567.\n",
      "[I 2025-12-30 17:12:58,185] Trial 66 finished with value: 0.9221189637826962 and parameters: {'C': 2.1331661606072627, 'solver': 'saga', 'penalty_saga': 'l1'}. Best is trial 33 with value: 0.9249974849094567.\n",
      "[I 2025-12-30 17:12:58,253] Trial 67 finished with value: 0.9234066901408451 and parameters: {'C': 0.8289295936068197, 'solver': 'liblinear', 'penalty_lib': 'l1'}. Best is trial 33 with value: 0.9249974849094567.\n",
      "[I 2025-12-30 17:12:58,388] Trial 68 finished with value: 0.9249528420523138 and parameters: {'C': 0.22122780228773997, 'solver': 'saga', 'penalty_saga': 'l1'}. Best is trial 33 with value: 0.9249974849094567.\n",
      "C:\\Users\\APUESTAS\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\APUESTAS\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\APUESTAS\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\APUESTAS\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\APUESTAS\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "[I 2025-12-30 17:12:58,484] Trial 69 finished with value: 0.921097208249497 and parameters: {'C': 1.1925674663477984e-05, 'solver': 'lbfgs', 'penalty_lbfgs': None}. Best is trial 33 with value: 0.9249974849094567.\n",
      "[I 2025-12-30 17:12:58,560] Trial 70 finished with value: 0.9221353118712272 and parameters: {'C': 0.04379801018523002, 'solver': 'saga', 'penalty_saga': 'l2'}. Best is trial 33 with value: 0.9249974849094567.\n",
      "[I 2025-12-30 17:12:58,693] Trial 71 finished with value: 0.9251747987927563 and parameters: {'C': 0.22610171388072564, 'solver': 'saga', 'penalty_saga': 'l1'}. Best is trial 71 with value: 0.9251747987927563.\n",
      "[I 2025-12-30 17:12:58,811] Trial 72 finished with value: 0.9241039989939637 and parameters: {'C': 0.1600309523275779, 'solver': 'saga', 'penalty_saga': 'l1'}. Best is trial 71 with value: 0.9251747987927563.\n",
      "[I 2025-12-30 17:12:58,938] Trial 73 finished with value: 0.924864185110664 and parameters: {'C': 0.39184344037345836, 'solver': 'saga', 'penalty_saga': 'l1'}. Best is trial 71 with value: 0.9251747987927563.\n",
      "[I 2025-12-30 17:12:59,063] Trial 74 finished with value: 0.923298541247485 and parameters: {'C': 0.11073606408523003, 'solver': 'saga', 'penalty_saga': 'l1'}. Best is trial 71 with value: 0.9251747987927563.\n",
      "[I 2025-12-30 17:12:59,204] Trial 75 finished with value: 0.9244705734406438 and parameters: {'C': 0.58022184570555, 'solver': 'saga', 'penalty_saga': 'l1'}. Best is trial 71 with value: 0.9251747987927563.\n",
      "[I 2025-12-30 17:12:59,277] Trial 76 finished with value: 0.5 and parameters: {'C': 0.0013298749677491295, 'solver': 'saga', 'penalty_saga': 'l1'}. Best is trial 71 with value: 0.9251747987927563.\n",
      "[I 2025-12-30 17:12:59,411] Trial 77 finished with value: 0.9251747987927563 and parameters: {'C': 0.2273892690742643, 'solver': 'saga', 'penalty_saga': 'l1'}. Best is trial 71 with value: 0.9251747987927563.\n",
      "[I 2025-12-30 17:12:59,739] Trial 78 finished with value: 0.9227867203219315 and parameters: {'C': 1.0817722305469686, 'solver': 'saga', 'penalty_saga': 'elasticnet', 'l1_ratio': 0.5568092913994019}. Best is trial 71 with value: 0.9251747987927563.\n",
      "C:\\Users\\APUESTAS\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\APUESTAS\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\APUESTAS\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\APUESTAS\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\APUESTAS\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "[I 2025-12-30 17:12:59,819] Trial 79 finished with value: 0.921097208249497 and parameters: {'C': 0.06431467655461075, 'solver': 'lbfgs', 'penalty_lbfgs': None}. Best is trial 71 with value: 0.9251747987927563.\n",
      "[I 2025-12-30 17:13:00,027] Trial 80 finished with value: 0.9216750503018108 and parameters: {'C': 5.507051887225799, 'solver': 'saga', 'penalty_saga': 'l1'}. Best is trial 71 with value: 0.9251747987927563.\n",
      "[I 2025-12-30 17:13:00,148] Trial 81 finished with value: 0.9247730130784708 and parameters: {'C': 0.18533609217828628, 'solver': 'saga', 'penalty_saga': 'l1'}. Best is trial 71 with value: 0.9251747987927563.\n",
      "[I 2025-12-30 17:13:00,274] Trial 82 finished with value: 0.9248182847082494 and parameters: {'C': 0.2742534655477903, 'solver': 'saga', 'penalty_saga': 'l1'}. Best is trial 71 with value: 0.9251747987927563.\n",
      "[I 2025-12-30 17:13:00,418] Trial 83 finished with value: 0.9247793008048291 and parameters: {'C': 0.4893234448639307, 'solver': 'saga', 'penalty_saga': 'l1'}. Best is trial 71 with value: 0.9251747987927563.\n",
      "[I 2025-12-30 17:13:00,543] Trial 84 finished with value: 0.9230281690140846 and parameters: {'C': 0.1017048761986549, 'solver': 'saga', 'penalty_saga': 'l1'}. Best is trial 71 with value: 0.9251747987927563.\n",
      "C:\\Users\\APUESTAS\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\APUESTAS\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\APUESTAS\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\APUESTAS\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\APUESTAS\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "[I 2025-12-30 17:13:00,622] Trial 85 finished with value: 0.9210525653923541 and parameters: {'C': 0.20900170755316239, 'solver': 'saga', 'penalty_saga': None}. Best is trial 71 with value: 0.9251747987927563.\n",
      "[I 2025-12-30 17:13:00,702] Trial 86 finished with value: 0.9184368712273642 and parameters: {'C': 0.021049194021759414, 'solver': 'liblinear', 'penalty_lib': 'l2'}. Best is trial 71 with value: 0.9251747987927563.\n",
      "[I 2025-12-30 17:13:00,812] Trial 87 finished with value: 0.9036553697183098 and parameters: {'C': 0.03755673797919569, 'solver': 'saga', 'penalty_saga': 'l1'}. Best is trial 71 with value: 0.9251747987927563.\n",
      "[I 2025-12-30 17:13:00,952] Trial 88 finished with value: 0.9248207997987927 and parameters: {'C': 0.4183125242146887, 'solver': 'saga', 'penalty_saga': 'l1'}. Best is trial 71 with value: 0.9251747987927563.\n",
      "[I 2025-12-30 17:13:01,110] Trial 89 finished with value: 0.9226534205231388 and parameters: {'C': 0.7880827704237, 'solver': 'saga', 'penalty_saga': 'l2'}. Best is trial 71 with value: 0.9251747987927563.\n",
      "[I 2025-12-30 17:13:01,267] Trial 90 finished with value: 0.9226521629778672 and parameters: {'C': 1.641146251360742, 'solver': 'saga', 'penalty_saga': 'l1'}. Best is trial 71 with value: 0.9251747987927563.\n",
      "[I 2025-12-30 17:13:01,393] Trial 91 finished with value: 0.9249075704225351 and parameters: {'C': 0.2704475309415221, 'solver': 'saga', 'penalty_saga': 'l1'}. Best is trial 71 with value: 0.9251747987927563.\n",
      "[I 2025-12-30 17:13:01,535] Trial 92 finished with value: 0.925040241448692 and parameters: {'C': 0.2532345921218102, 'solver': 'saga', 'penalty_saga': 'l1'}. Best is trial 71 with value: 0.9251747987927563.\n",
      "[I 2025-12-30 17:13:01,651] Trial 93 finished with value: 0.9241486418511066 and parameters: {'C': 0.15819843815481238, 'solver': 'saga', 'penalty_saga': 'l1'}. Best is trial 71 with value: 0.9251747987927563.\n",
      "[I 2025-12-30 17:13:01,778] Trial 94 finished with value: 0.9226270120724347 and parameters: {'C': 0.09460674445756069, 'solver': 'saga', 'penalty_saga': 'l1'}. Best is trial 71 with value: 0.9251747987927563.\n",
      "[I 2025-12-30 17:13:01,888] Trial 95 finished with value: 0.9144611418511067 and parameters: {'C': 0.056138597494773644, 'solver': 'saga', 'penalty_saga': 'l1'}. Best is trial 71 with value: 0.9251747987927563.\n",
      "[I 2025-12-30 17:13:02,021] Trial 96 finished with value: 0.9252194416498994 and parameters: {'C': 0.3470274894684798, 'solver': 'saga', 'penalty_saga': 'l1'}. Best is trial 96 with value: 0.9252194416498994.\n",
      "[I 2025-12-30 17:13:02,162] Trial 97 finished with value: 0.9248220573440644 and parameters: {'C': 0.46525086212349803, 'solver': 'saga', 'penalty_saga': 'l1'}. Best is trial 96 with value: 0.9252194416498994.\n",
      "C:\\Users\\APUESTAS\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\APUESTAS\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\APUESTAS\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\APUESTAS\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\APUESTAS\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "[I 2025-12-30 17:13:02,252] Trial 98 finished with value: 0.921097208249497 and parameters: {'C': 0.13393455663751855, 'solver': 'lbfgs', 'penalty_lbfgs': None}. Best is trial 96 with value: 0.9252194416498994.\n",
      "[I 2025-12-30 17:13:02,574] Trial 99 finished with value: 0.9227867203219317 and parameters: {'C': 1.1030219264485595, 'solver': 'saga', 'penalty_saga': 'elasticnet', 'l1_ratio': 0.5104767348821087}. Best is trial 96 with value: 0.9252194416498994.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[34  5]\n",
      " [ 2 34]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.87      0.91        39\n",
      "           1       0.87      0.94      0.91        36\n",
      "\n",
      "    accuracy                           0.91        75\n",
      "   macro avg       0.91      0.91      0.91        75\n",
      "weighted avg       0.91      0.91      0.91        75\n",
      "\n",
      "ROC-AUC Score in test: 0.9558\n",
      "ROC-AUC Score in train: 0.9314\n",
      "score in training 0.8703427719821163\n",
      "score in testing 0.9066666666666666\n"
     ]
    }
   ],
   "source": [
    "# Optimize Logistic Regression hyperparameters via Optuna\n",
    "params_finales_lr = logistic_regression_optuna(df, \"HeartDisease\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6aee6eb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-30 17:13:02,641] A new study created in memory with name: no-name-1c3d9def-cefb-4ad7-8379-f15e8b2bc504\n",
      "[I 2025-12-30 17:13:03,020] Trial 0 finished with value: 0.9189716423541249 and parameters: {'n_estimators': 25, 'max_depth': 18, 'min_samples_split': 17, 'min_samples_leaf': 14, 'max_features': None, 'criterion': 'gini'}. Best is trial 0 with value: 0.9189716423541249.\n",
      "[I 2025-12-30 17:13:06,304] Trial 1 finished with value: 0.9228175301810866 and parameters: {'n_estimators': 444, 'max_depth': 9, 'min_samples_split': 6, 'min_samples_leaf': 16, 'max_features': None, 'criterion': 'entropy'}. Best is trial 1 with value: 0.9228175301810866.\n",
      "[I 2025-12-30 17:13:08,906] Trial 2 finished with value: 0.9275785965794767 and parameters: {'n_estimators': 369, 'max_depth': 29, 'min_samples_split': 4, 'min_samples_leaf': 3, 'max_features': None, 'criterion': 'entropy'}. Best is trial 2 with value: 0.9275785965794767.\n",
      "[I 2025-12-30 17:13:11,637] Trial 3 finished with value: 0.9269636569416498 and parameters: {'n_estimators': 408, 'max_depth': 4, 'min_samples_split': 9, 'min_samples_leaf': 19, 'max_features': 'log2', 'criterion': 'gini'}. Best is trial 2 with value: 0.9275785965794767.\n",
      "[I 2025-12-30 17:13:13,471] Trial 4 finished with value: 0.9268749999999999 and parameters: {'n_estimators': 257, 'max_depth': 6, 'min_samples_split': 17, 'min_samples_leaf': 2, 'max_features': None, 'criterion': 'gini'}. Best is trial 2 with value: 0.9275785965794767.\n",
      "[I 2025-12-30 17:13:13,890] Trial 5 finished with value: 0.9278282193158953 and parameters: {'n_estimators': 37, 'max_depth': 22, 'min_samples_split': 12, 'min_samples_leaf': 20, 'max_features': 'log2', 'criterion': 'entropy'}. Best is trial 5 with value: 0.9278282193158953.\n",
      "[I 2025-12-30 17:13:16,017] Trial 6 finished with value: 0.9280250251509055 and parameters: {'n_estimators': 309, 'max_depth': 19, 'min_samples_split': 14, 'min_samples_leaf': 9, 'max_features': None, 'criterion': 'entropy'}. Best is trial 6 with value: 0.9280250251509055.\n",
      "[I 2025-12-30 17:13:18,168] Trial 7 finished with value: 0.9223239436619719 and parameters: {'n_estimators': 314, 'max_depth': 15, 'min_samples_split': 10, 'min_samples_leaf': 16, 'max_features': None, 'criterion': 'gini'}. Best is trial 6 with value: 0.9280250251509055.\n",
      "[I 2025-12-30 17:13:20,904] Trial 8 finished with value: 0.9209475603621732 and parameters: {'n_estimators': 416, 'max_depth': 10, 'min_samples_split': 17, 'min_samples_leaf': 20, 'max_features': None, 'criterion': 'entropy'}. Best is trial 6 with value: 0.9280250251509055.\n",
      "[I 2025-12-30 17:13:21,825] Trial 9 finished with value: 0.9291957997987929 and parameters: {'n_estimators': 116, 'max_depth': 27, 'min_samples_split': 2, 'min_samples_leaf': 8, 'max_features': 'sqrt', 'criterion': 'gini'}. Best is trial 9 with value: 0.9291957997987929.\n",
      "[I 2025-12-30 17:13:22,838] Trial 10 finished with value: 0.9300440140845071 and parameters: {'n_estimators': 133, 'max_depth': 30, 'min_samples_split': 2, 'min_samples_leaf': 7, 'max_features': 'sqrt', 'criterion': 'gini'}. Best is trial 10 with value: 0.9300440140845071.\n",
      "[I 2025-12-30 17:13:23,934] Trial 11 finished with value: 0.930132671026157 and parameters: {'n_estimators': 142, 'max_depth': 30, 'min_samples_split': 2, 'min_samples_leaf': 7, 'max_features': 'sqrt', 'criterion': 'gini'}. Best is trial 11 with value: 0.930132671026157.\n",
      "[I 2025-12-30 17:13:25,022] Trial 12 finished with value: 0.9303445674044264 and parameters: {'n_estimators': 141, 'max_depth': 25, 'min_samples_split': 6, 'min_samples_leaf': 6, 'max_features': 'sqrt', 'criterion': 'gini'}. Best is trial 12 with value: 0.9303445674044264.\n",
      "[I 2025-12-30 17:13:26,354] Trial 13 finished with value: 0.932618838028169 and parameters: {'n_estimators': 183, 'max_depth': 24, 'min_samples_split': 7, 'min_samples_leaf': 5, 'max_features': 'sqrt', 'criterion': 'gini'}. Best is trial 13 with value: 0.932618838028169.\n",
      "[I 2025-12-30 17:13:27,788] Trial 14 finished with value: 0.9318265845070423 and parameters: {'n_estimators': 207, 'max_depth': 24, 'min_samples_split': 7, 'min_samples_leaf': 4, 'max_features': 'sqrt', 'criterion': 'gini'}. Best is trial 13 with value: 0.932618838028169.\n",
      "[I 2025-12-30 17:13:29,271] Trial 15 finished with value: 0.9314247987927565 and parameters: {'n_estimators': 211, 'max_depth': 23, 'min_samples_split': 8, 'min_samples_leaf': 4, 'max_features': 'sqrt', 'criterion': 'gini'}. Best is trial 13 with value: 0.932618838028169.\n",
      "[I 2025-12-30 17:13:30,722] Trial 16 finished with value: 0.9310978370221328 and parameters: {'n_estimators': 202, 'max_depth': 14, 'min_samples_split': 13, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'criterion': 'gini'}. Best is trial 13 with value: 0.932618838028169.\n",
      "[I 2025-12-30 17:13:33,975] Trial 17 finished with value: 0.9292398138832999 and parameters: {'n_estimators': 493, 'max_depth': 21, 'min_samples_split': 7, 'min_samples_leaf': 11, 'max_features': 'sqrt', 'criterion': 'gini'}. Best is trial 13 with value: 0.932618838028169.\n",
      "[I 2025-12-30 17:13:35,488] Trial 18 finished with value: 0.932838908450704 and parameters: {'n_estimators': 213, 'max_depth': 25, 'min_samples_split': 5, 'min_samples_leaf': 5, 'max_features': 'sqrt', 'criterion': 'gini'}. Best is trial 18 with value: 0.932838908450704.\n",
      "[I 2025-12-30 17:13:36,204] Trial 19 finished with value: 0.9282683601609658 and parameters: {'n_estimators': 79, 'max_depth': 26, 'min_samples_split': 4, 'min_samples_leaf': 11, 'max_features': 'log2', 'criterion': 'gini'}. Best is trial 18 with value: 0.932838908450704.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[34  5]\n",
      " [ 2 34]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.87      0.91        39\n",
      "           1       0.87      0.94      0.91        36\n",
      "\n",
      "    accuracy                           0.91        75\n",
      "   macro avg       0.91      0.91      0.91        75\n",
      "weighted avg       0.91      0.91      0.91        75\n",
      "\n",
      "ROC-AUC Score in test: 0.9608\n",
      "ROC-AUC Score in train: 0.9720\n",
      "score in training 0.9001490312965723\n",
      "score in testing 0.9066666666666666\n"
     ]
    }
   ],
   "source": [
    "# Optimize Random Forest hyperparameters via Optuna\n",
    "params_finales_rf = random_forest_optuna(df, \"HeartDisease\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f3735473",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-30 17:13:36,688] A new study created in memory with name: no-name-968c32f4-6f0a-41ac-bfcc-796a71d62f54\n",
      "[I 2025-12-30 17:13:36,971] Trial 0 finished with value: 0.9073019366197184 and parameters: {'C': 10.5353203302454, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 0 with value: 0.9073019366197184.\n",
      "[I 2025-12-30 17:13:37,222] Trial 1 finished with value: 0.9222925050301811 and parameters: {'C': 0.5008130425326398, 'kernel': 'rbf', 'gamma': 'auto'}. Best is trial 1 with value: 0.9222925050301811.\n",
      "[I 2025-12-30 17:13:37,557] Trial 2 finished with value: 0.8715492957746479 and parameters: {'C': 476.23452732137963, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 1 with value: 0.9222925050301811.\n",
      "[I 2025-12-30 17:13:37,704] Trial 3 finished with value: 0.9231187122736418 and parameters: {'C': 0.019096526260908537, 'kernel': 'linear', 'gamma': 'auto'}. Best is trial 3 with value: 0.9231187122736418.\n",
      "[I 2025-12-30 17:13:38,005] Trial 4 finished with value: 0.9017152917505029 and parameters: {'C': 0.010151540289935018, 'kernel': 'sigmoid', 'gamma': 'auto'}. Best is trial 3 with value: 0.9231187122736418.\n",
      "[I 2025-12-30 17:13:38,338] Trial 5 finished with value: 0.900138958752515 and parameters: {'C': 53.22893748426388, 'kernel': 'rbf', 'gamma': 'auto'}. Best is trial 3 with value: 0.9231187122736418.\n",
      "[I 2025-12-30 17:13:38,571] Trial 6 finished with value: 0.8968705985915493 and parameters: {'C': 0.0012220031238285166, 'kernel': 'poly', 'gamma': 'auto'}. Best is trial 3 with value: 0.9231187122736418.\n",
      "[I 2025-12-30 17:13:38,807] Trial 7 finished with value: 0.9027948943661972 and parameters: {'C': 0.15600002523034806, 'kernel': 'poly', 'gamma': 'auto'}. Best is trial 3 with value: 0.9231187122736418.\n",
      "[I 2025-12-30 17:13:38,992] Trial 8 finished with value: 0.921270749496982 and parameters: {'C': 0.9357601775958598, 'kernel': 'linear', 'gamma': 'scale'}. Best is trial 3 with value: 0.9231187122736418.\n",
      "[I 2025-12-30 17:13:47,388] Trial 9 finished with value: 0.9196686368209257 and parameters: {'C': 170.7816609866202, 'kernel': 'linear', 'gamma': 'scale'}. Best is trial 3 with value: 0.9231187122736418.\n",
      "[I 2025-12-30 17:13:47,538] Trial 10 finished with value: 0.9229935865191147 and parameters: {'C': 0.03547950834684513, 'kernel': 'linear', 'gamma': 'auto'}. Best is trial 3 with value: 0.9231187122736418.\n",
      "[I 2025-12-30 17:13:47,690] Trial 11 finished with value: 0.9229495724346076 and parameters: {'C': 0.03252439294885902, 'kernel': 'linear', 'gamma': 'auto'}. Best is trial 3 with value: 0.9231187122736418.\n",
      "[I 2025-12-30 17:13:47,870] Trial 12 finished with value: 0.9182985412474849 and parameters: {'C': 0.0053777341224336365, 'kernel': 'linear', 'gamma': 'auto'}. Best is trial 3 with value: 0.9231187122736418.\n",
      "[I 2025-12-30 17:13:48,022] Trial 13 finished with value: 0.9239813883299798 and parameters: {'C': 0.0709877694297548, 'kernel': 'linear', 'gamma': 'auto'}. Best is trial 13 with value: 0.9239813883299798.\n",
      "[I 2025-12-30 17:13:48,188] Trial 14 finished with value: 0.8831922786720323 and parameters: {'C': 10.204237306466055, 'kernel': 'sigmoid', 'gamma': 'auto'}. Best is trial 13 with value: 0.9239813883299798.\n",
      "[I 2025-12-30 17:13:48,354] Trial 15 finished with value: 0.9231853621730381 and parameters: {'C': 0.1436324246756122, 'kernel': 'linear', 'gamma': 'auto'}. Best is trial 13 with value: 0.9239813883299798.\n",
      "[I 2025-12-30 17:13:48,504] Trial 16 finished with value: 0.9227012072434608 and parameters: {'C': 0.19050981216791257, 'kernel': 'linear', 'gamma': 'auto'}. Best is trial 13 with value: 0.9239813883299798.\n",
      "[I 2025-12-30 17:13:48,807] Trial 17 finished with value: 0.9194014084507043 and parameters: {'C': 2.337134673002164, 'kernel': 'linear', 'gamma': 'auto'}. Best is trial 13 with value: 0.9239813883299798.\n",
      "[I 2025-12-30 17:13:49,004] Trial 18 finished with value: 0.9179885563380281 and parameters: {'C': 0.09651014354691125, 'kernel': 'poly', 'gamma': 'scale'}. Best is trial 13 with value: 0.9239813883299798.\n",
      "[I 2025-12-30 17:13:49,307] Trial 19 finished with value: 0.9017152917505029 and parameters: {'C': 0.001951141053989306, 'kernel': 'sigmoid', 'gamma': 'auto'}. Best is trial 13 with value: 0.9239813883299798.\n",
      "[I 2025-12-30 17:13:49,627] Trial 20 finished with value: 0.9193121227364186 and parameters: {'C': 3.351184605962313, 'kernel': 'linear', 'gamma': 'auto'}. Best is trial 13 with value: 0.9239813883299798.\n",
      "[I 2025-12-30 17:13:49,771] Trial 21 finished with value: 0.9230772132796782 and parameters: {'C': 0.020939973006325257, 'kernel': 'linear', 'gamma': 'auto'}. Best is trial 13 with value: 0.9239813883299798.\n",
      "[I 2025-12-30 17:13:49,926] Trial 22 finished with value: 0.9248289738430582 and parameters: {'C': 0.0945890181074395, 'kernel': 'linear', 'gamma': 'auto'}. Best is trial 22 with value: 0.9248289738430582.\n",
      "[I 2025-12-30 17:13:50,071] Trial 23 finished with value: 0.9217630784708248 and parameters: {'C': 0.24445220887894475, 'kernel': 'linear', 'gamma': 'auto'}. Best is trial 22 with value: 0.9248289738430582.\n",
      "[I 2025-12-30 17:13:50,233] Trial 24 finished with value: 0.9236248742454729 and parameters: {'C': 0.06465175666222761, 'kernel': 'linear', 'gamma': 'auto'}. Best is trial 22 with value: 0.9248289738430582.\n",
      "[I 2025-12-30 17:13:50,373] Trial 25 finished with value: 0.923311745472837 and parameters: {'C': 0.05487732789729316, 'kernel': 'linear', 'gamma': 'auto'}. Best is trial 22 with value: 0.9248289738430582.\n",
      "[I 2025-12-30 17:13:50,538] Trial 26 finished with value: 0.9182985412474849 and parameters: {'C': 0.005334010969567762, 'kernel': 'linear', 'gamma': 'scale'}. Best is trial 22 with value: 0.9248289738430582.\n",
      "[I 2025-12-30 17:13:50,737] Trial 27 finished with value: 0.923756916498994 and parameters: {'C': 0.6145506130462606, 'kernel': 'sigmoid', 'gamma': 'auto'}. Best is trial 22 with value: 0.9248289738430582.\n",
      "[I 2025-12-30 17:13:50,927] Trial 28 finished with value: 0.9241536720321932 and parameters: {'C': 0.5926866326324863, 'kernel': 'sigmoid', 'gamma': 'auto'}. Best is trial 22 with value: 0.9248289738430582.\n",
      "[I 2025-12-30 17:13:51,088] Trial 29 finished with value: 0.8278728621730382 and parameters: {'C': 3.5188886142231772, 'kernel': 'sigmoid', 'gamma': 'scale'}. Best is trial 22 with value: 0.9248289738430582.\n",
      "[I 2025-12-30 17:13:51,253] Trial 30 finished with value: 0.8753734909456741 and parameters: {'C': 35.22216364254509, 'kernel': 'sigmoid', 'gamma': 'auto'}. Best is trial 22 with value: 0.9248289738430582.\n",
      "[I 2025-12-30 17:13:51,439] Trial 31 finished with value: 0.9236141851106641 and parameters: {'C': 0.5401852255832609, 'kernel': 'sigmoid', 'gamma': 'auto'}. Best is trial 22 with value: 0.9248289738430582.\n",
      "[I 2025-12-30 17:13:51,637] Trial 32 finished with value: 0.9235274144869215 and parameters: {'C': 0.4227854431511271, 'kernel': 'sigmoid', 'gamma': 'auto'}. Best is trial 22 with value: 0.9248289738430582.\n",
      "[I 2025-12-30 17:13:51,823] Trial 33 finished with value: 0.9218536217303821 and parameters: {'C': 1.6388097375125366, 'kernel': 'sigmoid', 'gamma': 'auto'}. Best is trial 22 with value: 0.9248289738430582.\n",
      "[I 2025-12-30 17:13:52,071] Trial 34 finished with value: 0.9202735160965796 and parameters: {'C': 8.463736840305751, 'kernel': 'rbf', 'gamma': 'auto'}. Best is trial 22 with value: 0.9248289738430582.\n",
      "[I 2025-12-30 17:13:52,254] Trial 35 finished with value: 0.9234029175050301 and parameters: {'C': 0.8324028122286644, 'kernel': 'sigmoid', 'gamma': 'auto'}. Best is trial 22 with value: 0.9248289738430582.\n",
      "[I 2025-12-30 17:13:52,504] Trial 36 finished with value: 0.9217913732394365 and parameters: {'C': 0.3399546415103737, 'kernel': 'rbf', 'gamma': 'auto'}. Best is trial 22 with value: 0.9248289738430582.\n",
      "[I 2025-12-30 17:13:52,845] Trial 37 finished with value: 0.9044818913480885 and parameters: {'C': 0.012436908808090166, 'kernel': 'sigmoid', 'gamma': 'scale'}. Best is trial 22 with value: 0.9248289738430582.\n",
      "[I 2025-12-30 17:13:53,045] Trial 38 finished with value: 0.9203873239436622 and parameters: {'C': 1.3476312136556636, 'kernel': 'poly', 'gamma': 'auto'}. Best is trial 22 with value: 0.9248289738430582.\n",
      "[I 2025-12-30 17:13:53,288] Trial 39 finished with value: 0.9158456991951711 and parameters: {'C': 0.07079385245009542, 'kernel': 'sigmoid', 'gamma': 'auto'}. Best is trial 22 with value: 0.9248289738430582.\n",
      "[I 2025-12-30 17:13:53,488] Trial 40 finished with value: 0.914618963782696 and parameters: {'C': 23.81381003792552, 'kernel': 'poly', 'gamma': 'auto'}. Best is trial 22 with value: 0.9248289738430582.\n",
      "[I 2025-12-30 17:13:53,807] Trial 41 finished with value: 0.9152295020120725 and parameters: {'C': 0.07121397143756097, 'kernel': 'rbf', 'gamma': 'auto'}. Best is trial 22 with value: 0.9248289738430582.\n",
      "[I 2025-12-30 17:13:53,957] Trial 42 finished with value: 0.9236745472837022 and parameters: {'C': 0.12870392730561359, 'kernel': 'linear', 'gamma': 'auto'}. Best is trial 22 with value: 0.9248289738430582.\n",
      "[I 2025-12-30 17:13:54,153] Trial 43 finished with value: 0.9217171780684105 and parameters: {'C': 0.7395644585728312, 'kernel': 'linear', 'gamma': 'auto'}. Best is trial 22 with value: 0.9248289738430582.\n",
      "[I 2025-12-30 17:13:54,374] Trial 44 finished with value: 0.9199899396378269 and parameters: {'C': 0.14497497701215814, 'kernel': 'sigmoid', 'gamma': 'auto'}. Best is trial 22 with value: 0.9248289738430582.\n",
      "[I 2025-12-30 17:13:54,525] Trial 45 finished with value: 0.9228615442655936 and parameters: {'C': 0.03709848431038484, 'kernel': 'linear', 'gamma': 'auto'}. Best is trial 22 with value: 0.9248289738430582.\n",
      "[I 2025-12-30 17:13:54,690] Trial 46 finished with value: 0.9216750503018108 and parameters: {'C': 0.34396820330805145, 'kernel': 'linear', 'gamma': 'scale'}. Best is trial 22 with value: 0.9248289738430582.\n",
      "[I 2025-12-30 17:13:55,071] Trial 47 finished with value: 0.905027665995976 and parameters: {'C': 0.012182104178382096, 'kernel': 'rbf', 'gamma': 'auto'}. Best is trial 22 with value: 0.9248289738430582.\n",
      "[I 2025-12-30 17:13:55,288] Trial 48 finished with value: 0.918699069416499 and parameters: {'C': 0.12214497992407093, 'kernel': 'sigmoid', 'gamma': 'auto'}. Best is trial 22 with value: 0.9248289738430582.\n",
      "[I 2025-12-30 17:13:55,757] Trial 49 finished with value: 0.9195799798792755 and parameters: {'C': 5.81168930861372, 'kernel': 'linear', 'gamma': 'auto'}. Best is trial 22 with value: 0.9248289738430582.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- SVC OPTIMIZADO ---\n",
      "[[34  5]\n",
      " [ 2 34]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.87      0.91        39\n",
      "           1       0.87      0.94      0.91        36\n",
      "\n",
      "    accuracy                           0.91        75\n",
      "   macro avg       0.91      0.91      0.91        75\n",
      "weighted avg       0.91      0.91      0.91        75\n",
      "\n",
      "ROC-AUC Score in test: 0.9487\n",
      "ROC-AUC Score in train: 0.9295\n",
      "score in training 0.8628912071535022\n",
      "score in testing 0.9066666666666666\n"
     ]
    }
   ],
   "source": [
    "# Optimize SVC hyperparameters via Optuna\n",
    "params_finales_svc = svc_optuna(df, \"HeartDisease\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9ce6c45a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- RESULTADOS DEL ENSAMBLE TRIPLE ---\n",
      "[[34  5]\n",
      " [ 2 34]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.87      0.91        39\n",
      "           1       0.87      0.94      0.91        36\n",
      "\n",
      "    accuracy                           0.91        75\n",
      "   macro avg       0.91      0.91      0.91        75\n",
      "weighted avg       0.91      0.91      0.91        75\n",
      "\n",
      "ROC-AUC Score in test: 0.9587\n",
      "ROC-AUC Score in train: 0.9581\n",
      "Score in testing: 0.9067\n",
      "Score in training: 0.8852\n"
     ]
    }
   ],
   "source": [
    "# Build a stacked ensemble from the tuned base models\n",
    "modelo_ensamble_final = create_triple_stacking(\n",
    "    df=df, \n",
    "    target=\"HeartDisease\", \n",
    "    params_lr=params_finales_lr, \n",
    "    params_rf=params_finales_rf, \n",
    "    params_svc=params_finales_svc\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3da766fb",
   "metadata": {},
   "source": [
    "## Findings\n",
    "- Baseline logistic regression gives a reasonable starting point but is outperformed by tree-based models in AUC/recall in our experiments (see prior cells).\n",
    "- Random forest and XGBoost capture non-linear interactions and generally provide better discrimination on this dataset.\n",
    "- A stacked ensemble combining linear and tree-based learners tends to stabilize performance and can slightly improve overall AUC.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dd289e50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../model/modelo_heart_disease_stacking.pkl']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save final ensemble model to disk \n",
    "joblib.dump(modelo_ensamble_final, '../model/modelo_heart_disease_stacking.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4478b84c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA44AAAIjCAYAAABMAkUQAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjcsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvTLEjVAAAAAlwSFlzAAAPYQAAD2EBqD+naQAAb/VJREFUeJzt3Qm8jPX///+X/cianezZ1ywRKvkgS6QSJRTtlmSpUCIKqdAmUdZS2lVaKJFCUUKyJHtZU/bs878939//Nb+ZMedycDbnPO632+Scua659jnNc17v9/tKEwgEAgYAAAAAQCzSxjYBAAAAAAAhOAIAAAAAfBEcAQAAAAC+CI4AAAAAAF8ERwAAAACAL4IjAAAAAMAXwREAAAAA4IvgCAAAAADwRXAEAAAAAPgiOAJAPJg3b56lSZPG/Xu2OnXqZFmzZo3TvFrHE088cQ5biNRo06ZN7pqZPHnyOb2e6+3sFC9e3Fq0aJGgfy/8LF682DJmzGibN2+O1+WmNrfeequ1bds2qTcDSHYIjgBSpOuvv94uuugiO3DgQKzztG/f3n3I2rNnj6VWcf2gm1ytWrXKBRsFpJRIgU8B40wPnccLgbYztn1o2rRpUm/eBe+xxx6zdu3aWbFixcKeX716tTu++oIqV65c1rFjR9u9e3eclnnw4EHr2bOnFS5c2DJlymTly5e3sWPHntW1umPHjrPaj1q1arnXRVuP6D2v6X///XfU6ZUqVbJrrrnmtOf3799vgwcPtqpVq7pjkTlzZjdv3759bdu2bcH59PsHH3xgy5cvP6vtBlK69Em9AQCQEBQKP/30U/voo4/s9ttvP2364cOH7eOPP3YfpnLnzn3e67v66qvtv//+c0EUiRsc9UFQHxIvlPB0ttfVG2+8Efbc3Xff7T5Y33vvvcHnYqtYK0DousyQIYMlF5dddpn16dPntOcLFSqUJNuTUixbtsy+/vprW7hwYdjzf/75p7uOcuTIYcOGDXNB8LnnnrNff/01WKGMzcmTJ61Jkyb2008/Wbdu3ax06dI2a9Ys69q1q/3777/26KOPnvaaIUOGWIkSJcKey5kzZ5z3Y926dbZkyRL3fp42bZp16dLF4sOGDRusUaNGtmXLFmvTpo17/2jfV6xYYRMmTHD/r/j999/dvNWqVbOaNWvayJEjberUqfGyfiAlIDgCSLEVx2zZstlbb70VNTgqNB46dMgFzPNx5MgR9+Ejbdq0FhMTc17Lwtkf95SuZMmS7hHq/vvvd8916NAh1tedOHHCTp065Y5RcrsuL7nkEt9tx7mZNGmSFS1a1K644oqw5xUW9bfu559/dtNFXzw0btzYVQlDv4CI9OGHH7ogqmB15513uucU5G6++WZ78skn3ZcY+fLlC3tNs2bNXOg6V2+++aZbpkKb1qPWBOf7pZDeDzfddJPt3LnTNQ++8sorw6YPHTrURowYEfacmqoOGjTIXnnllTh3JQBSOpqqAkiR1ARJHxTmzJlju3btOm26AqWCpQLmP//8Yw899JBVrlzZfUDInj27+/AT2UzJ65c0ffp0GzBggPsArOawav4Urc/Sd999577Z1oc1NfEqUqSI9erVy1WAYvtGXN/uZ8mSxVVf9M19IBA4477+9ddf7kNd/vz53XoqVqxoEydOPK8+capIjBkzxgUU7eO1115rW7duddujD4xqtqZj3KpVK3f8ojV/nT17tqsuKbhUqFDBfQiNts86Rmo+p/XoQ+9nn30Wp+P+4osvutdKgwYNgs3ivHOgLweuu+46dyx1XC699FK37aqihFK1Us3VVL3UcrRsreOZZ56JGljVTK5MmTJuvwoWLOius/Xr1wfnUWB7/vnn3XnQPDov9913n6vQhNq3b5+tWbPG/Xs+Qs+Z1qv91P5qf6L1cfT61CaH6y023jZqXTfccIP7OW/evO59Gnn+dF3UqFHDvZ/13tX7+IUXXgibZ+/eva65pd6D2uZSpUq5oKBzFZ/Xvicu1340P/74o2sFoeqg1l2/fn1bsGBBnF47Y8YM+9///uf2IZSaXOr96IVGUeVN1/C7777ru0z9DfP6/IXS73ov6D0WjboIRJ6nuNLfZgVGbbOOg34/X16zUzXljQyNoutG4TGUgrUC91dffXXe6wdSCiqOAFIsVROnTJniPhx17949+Lw+7Km5lfoC6QPgb7/95j50KYSoiZW+lR43bpz70KYP35FN6PThUZUcfYg9evRorJWv9957zzWJ1Tf0ag6rZmEvvfSSazqmaaH0IUsfGBWcFFi+/PJL9223vinXB/rYaFv1Gn1Y1D7qw/UXX3xhd911lwu0+rB8LtRE7NixY/bAAw+446Vt0jfw+mCqYKY+QH/88YfbHx2HyOCg5ma33HKLq47dcccdrhqi46v90gcyb9vr1q3rjlGPHj3cMdL5Uph///337cYbb/Q97vpAr9cpQKrJnPpeifevwpICR+/evd2/33zzjQ0cONAdl2effTZs2Qp1Ov4KgdpPrV/7qBCiLxG8c6QPs/oyQh+cH3zwQfcBWR8sV65c6QKbKCRq3Z07d3bbt3HjRnv55Zftl19+cSHAazaqpnGaR8dGQel8aTn6MK8KksKRwnhoMEou19vx48ej9k1TgNX7MXQbFWxr167twpyaYaoKpePsNV/Usdf7uGHDhsGKkfrz6Tjr/IiuL72XFUJ1bhSgVEXr37+/bd++3YXtxL72o9H1qWtNIVjnQq0Y9FqtVwFOVcLYaN/UBLN69eqnPa8vzqJVALW8zz//3PzofZYuXbrT/sYp1IqqmPfcc0/YNH35ouaweo3On86ZmrjGNTjr2Gq/9Xq9H3U+ojWJPRuffPKJ+1d9O+NKgV/Xo66lyL9FQKoVAIAU6sSJE4GCBQsG6tSpE/b8q6++qrJKYNasWe73I0eOBE6ePBk2z8aNGwOZMmUKDBkyJPjc3Llz3etKliwZOHz4cNj83jT964mcR4YPHx5IkyZNYPPmzcHn7rjjDvfaBx54IPjcqVOnAtddd10gY8aMgd27dwef13yDBg0K/n7XXXe5ffz777/D1nPrrbcGcuTIEXUbQhUrVsytJ3S/tY68efMG9u7dG3y+f//+7vmqVasGjh8/Hny+Xbt2bht1DEOXqXk/+OCD4HP79u1z21mtWrXgcz179nTzfffdd8HnDhw4EChRokSgePHiwXPid9zfe++90467J9q+33fffYGLLroobHvr16/vljF16tTgc0ePHg0UKFAg0Lp16+BzEydOdPONGjXqtOXqfIn2RfNMmzYtbPqXX3552vOTJk1yz+nfs5ElSxZ3zUSes+zZswd27doVNq83LXQdSX29aZnRHnpvRG5j6PtPdP3UqFEj+PuDDz7o9lvv9dg8+eST7pj9/vvvYc/369cvkC5dusCWLVsS/dqP/Huh41+6dOlAkyZNgteS6Hjq/dC4cWPf4/r111+75X366adhzy9ZsuS0a9vz8MMPu2mh2x9p5MiRp71HvWOn51u0aBF87p133gl06tQpMGXKlMBHH30UGDBggHuv5cmTJ3iMz6R79+6BIkWKBI/B7Nmz3Xp++eWXsPl0Ter50Gs1VMWKFd372qNjr+vzbJUpUybQrFmzs34dkFLRVBVAiqVvylUZWrRoUdiom2r6pGZ2qlKIqjP6dt+rcmiUVVWoypYta0uXLj1tuaoihFZGYhM6j5o8qcqiCps+j6v6FCm0KupVdFT5UKUlGi1HTbBatmzpftbyvYe+6VcTyGjbHxeqkKiZmEdVH1HftPTp04c9r21UZSOUqrSh39KrKZj6mmq/vREWVe1Q1SO06ZiOuypmOl+q9p7LcfeEzqvKoI7LVVdd5SpQaiIaSusN7Xenaoe2Tc05PTrWefLkcZWoSF7zQFWSddxUWQo9H6oiaR1z584NvkZVRp23+Kg2SuvWrV0FMK6S6nrTNaNKYeRDlcNIqtqF0vkLPScadOVMzQl1TvS6iy++OGyb1VxT7/f58+cn+rUfbWAbVSpvu+029/fH20btm/5OaRtjqx6LNzK09jGU1yxef+MieX1fY2s6L9oeHQs1TdYx1vty/Pjxrt9f5GtVlVWlUPuq5sVqIaCWHdq2yGag0aja/c4777hqrfd+UrVV/R1VdTwfqoarKfPZ8q4ZAP+HpqoAUnxz1dGjR7uwqOZOaiaqZl9qQqhgKfpApj5R+jCkZoWhfXOijbgaOWJgbNR0TE0j1UwqWv+2UAqukYOgqA+SxHarCQ2nr75b+iCnRzTR+nfGRWh/KPE+SKuPWLTnI/dPfcgi+1qF7k+BAgXcvea8D+WhvKammq6+h2d73D1qgqw+kWoCqA+Ofsdf/dYit1cfGjXiokf9GPVlQmh4iKQP/1p25IAh53s+4uJsjk9SXm8K3wptZ6JgExmEdU5CrzWN7qmm6GriqX6par6sABN6aw+dE53H2EJ15DYnxrUfSdvofTkSG11XkcEwUmQfVe/LEzU5jaRmzaHzRKNt1d8vNfHUsfWCsJrpalvPNGiMvhTSezy2LyMi+4XqGtMXNmquGtr09e2333ZNkb0v+OIi9Bxom0O/cIgrHc/IcwmkZgRHACmaKj3lypVzHzwUHPWvPgyEjqaqUQcff/xx9626viVX3zB9QFF/rWjf8sel6qXwqaqT+kipT5S2QX24VJ1QhcmvehBX3jJUCYntA2eVKlXOadleqI7r83EZVOV8nU21UQFH/dr0gVF99tQvTkFEFTGdj8jjH1/7peX6VUjOpiKYkMcnuV1v0cR2TkLpWKtap8qW+lrq4VW91F/W2269Fx955JGoy/BCXVJe+96xVd9bDaoTjV9I877gigyxGrxJ1Jczkp7T37po1chQupWHQpdu36EKqO6B6N3zMPLYRaPAvXbt2jPO571nFPyj+fbbb12IjEu1VK0KQkcT1t9fVXw1yFHkFwB+dDzj2j8TSA0IjgBSPIVEBUNVHVR51AeByy+/PDhdA6HoA4mGnI8MH6qOnAt9yNI9wfThNfR2ILE1qdMHR304C/0g5t1TLLah6BVC1PxKITUuFZzEpIpB5Lf1kfujewxG+0DpNSONvIl5NLFVAzSIiZrIaTRLffD1qKJ8rhQ+NXiHBneJ7b6ImkfVlXr16iV4kDsfKel6U7NiNZ/VQ/ulKqQGt9J7XtU/nRMN1pJY2xyXaz+SN7CSvug4l+1UMIp2fasKq/Om+zBG0mBdsYXUaKE5dF6vghiXbdV1dqYvTBRINUKrmqlqRNVIaiGiYOkFR+9vg/5+RAZBhUYFRK9CKro29KWhbvWhQZHiQk1ntRwN1gXg/9DHEUCK51UX1WxU1YnIezfqQ1Fk1UD9oiL7Lp0NrzoRulz9HHmbgFAaeTN0Xv2ugOL1xYy2DvVrU78zjeoZSc2+kooqEho11KOmorqRtj58ek31mjdv7j68qg9q6AdINYPUB2yNangmquJ6If9Mx1/90by+WedCx1r9nULPk8dbj6olClaqXEf7IBq6nfF1O45zlRKuN69vn0ctBbyqp9c8U+dE15iqkpF0PnReEvvaj9YyQuFRo8cq5J7tsVVAVICKFhB1zmbOnOlCkEcjAyvMerezEX0housxWnUyclvUbFTHOTQ4RttG9WPWyKuhTYej0fHSe79bt24uOEY+NJqxrjvvnOoa1RcGY8eOPa31gP5+6Jx6oyGLlqERktXXMvTvTWgfaN2qI5T6WKs5r/qlA/g/VBwBpHjq+6X/+Xv3HIsMjvpQouaMujWC5lO1UN9uR/YBO9sKgD4Iarh+BVBVEvTBJ7IpmUfNqjRcv5oAqk+QmtzpfoZqXuv3bf3TTz/tBlzRazQsvsKWmseqSaaqArHdZy6hqZKlWzQsWbLEDUSkWxboVg5qRujp16+fqwLoA54qCmo2pwqtqiY6VnHpz6QP4wo0+iCrAKZmdxpQQ+dR/cF0PLVsVX/eeOON82pWqMqxAoBu76HAqwFX9GFXx1lVLt3XT81jdcuH4cOHuy8pVPVQGFMfNn0ZoS8OvIpKfN+O42wk5fWm94MqP9GaYmpQlbOhG9BrnTrn6qeqfrHqf6frwusr+/DDD7t+enqf6zgrpOm86X2u1gbqd3iuLQvO9dqPpGv99ddfd+8F3RdT14XCoI6Vjrf+fnz66ae+69X1p2sqstqpc6prT9U63aJEwVRNYhWktB6P1qVjpmsi9L6fuqbr1Knjqrca3EfBTMtQGA19j+o9V61aNXfrD/X/1DWhfVegPdPtNPT3Vs1tYwtpqvq99tpr7hrVLTrURFlfBKoPs1oUaLpuEaLbrOhvit53qjJ69B5U6wMFXc2vLxPUKkDPqy+0WqLo70XoID5qHaJl+t1CBUh1knpYVwBIDGPGjHHDt9eqVeu0aRqOvk+fPm7I/MyZMwfq1asXWLRokRvOPXRId28Ifd0CIlK023GsWrUq0KhRo0DWrFndkPT33HNPYPny5VFvj6DbBaxfvz5w7bXXuiHs8+fP74acj7xNSOTtEWTnzp2Bbt26uWHsM2TI4G4j0bBhw8D48ePPeFxiux3Hs88+G3X/Ivfdu6WEhv2PXKZud1KlShV3W5Ny5cpFPW7a55tvvjmQM2fOQExMjDs/M2fOjNO6Pa+99pq7VYdurRB6DhYsWBC44oor3DktVKhQ4JFHHnHbFHmedI41fH8knRftSyjdHuGxxx5zt0jwjrW2X/sRSsdet43QurNlyxaoXLmyW/+2bdsS7HYckecsdFpyut5iux1H6LH2tjGSdxsGz/vvv+/2IV++fO7WGEWLFnW3XNm+fXvY63SbF91Wo1SpUm4+vR/r1q0beO655wLHjh1L9Gs/2t8L0W0nbrrppkDu3Lnda7W8tm3bBubMmXPGY7t06dKot86QlStXBs+13mvt27cP7NixI2web/9Dry3p1auXe39pe3Srkttuu+206130vrjsssvcbS90XehcdOnS5bT1RNL1lD59+kDHjh1jnUfvO237jTfeGPb8m2++6d7jula8Yz148OBYbzHy77//BgYOHOjej1qe/uZUqlTJXRuR10zt2rUDHTp08N12ILVJo/8kdXgFAKQcamaq0VBVkUDyo6qbKm3RmkTiwqYmnLodiKrrOHdqLVC9enVXNY1rP1AgNaCPIwAAQAqgEaJ1L0Q12cW5U5NsNSknNALh6OMIAACQAqjvqQaBwvmZPn16Um8CkCxRcQQAAAAA+KKPIwAAAADAFxVHAAAAAIAvgiMAAAAAwBeD46RCp06dsm3btlm2bNnCbhIMAAAAIHUJBAJ24MABdzuftGljrysSHFMhhcYiRYok9WYAAAAASCa2bt1qhQsXjnU6wTEVUqXRuziyZ8+e1JsDAAAAIIns37/fFZW8jBAbgmMq5DVPVWgkOAIAAABIc4YubAyOAwAAAADwRXAEAAAAAPgiOAIAAAAAfBEcAQAAAAC+CI4AAAAAAF8ERwAAAACAL4IjAAAAAMAX93FMxUYt32MxWY8l9WYAAAAAqUa/annsQkTFEQAAAADgi+AIAAAAAPBFcAQAAAAA+CI4AgAAAAB8ERwBAAAAAL4IjgnommuusZ49eyb1ZgAAAADAeUnRwXH37t3WpUsXK1q0qGXKlMkKFChgTZo0saFDh1qaNGl8H/PmzfNd9smTJ+3pp5+2cuXKWebMmS1XrlxWu3Zte/311xNt/wAAAAAgMaTo+zi2bt3ajh07ZlOmTLGSJUvazp07bc6cOVaxYkXbvn17cL4HH3zQ9u/fb5MmTQo+pyDoZ/DgwTZu3Dh7+eWXrWbNmu71P/30k/37778Juk8AAAAAkNhSbMVx79699t1339mIESOsQYMGVqxYMatVq5b179/frr/+eld99B6qGHoVSe+RMWNG3+V/8skn1rVrV2vTpo2VKFHCqlatanfddZc99NBDsb5GofL222+3iy++2C666CJr1qyZrVu3Ljh98uTJljNnTpsxY4aVLl3aYmJiXIV069atYcv5+OOPrXr16m66ArFC7IkTJ+LhqAEAAABAKgqOWbNmdQ+FsKNHj8b78hUuv/nmG9ccNq46derkqpIKnYsWLbJAIGDNmze348ePB+c5fPiwa0o7depUW7BggQvAt956a3C6wrDCp6qkq1atclVPBU69Jjbaf1VEQx8AAAAAYKk9OKZPn94FKjVTVRWvXr169uijj9qKFSviZfmjRo1yoVEBskqVKnb//ffbF198Eev8qiwqMKoP5FVXXeUqlNOmTbO//vrLhVuPQqSav9apU8dq1Kjhtn/hwoW2ePFiN13VxX79+tkdd9zhqo2NGze2J5980gXI2AwfPtxy5MgRfBQpUiRejgEAAACA1CHFBkevj+O2bdtcYGvatKkb8EZNPBUoz1eFChVs5cqV9sMPP9idd95pu3btspYtW9rdd98ddf7Vq1e7MKsBdDy5c+e2smXLumkezXP55ZcHf9fgOwq+3jzLly+3IUOGBCuqetxzzz2uz6aqldGoee6+ffuCj8imrwAAAACQaoOjqB+gqnKPP/64q9ypueigQYPiZdlp06Z1IU+33Pjwww9dIJ0wYYJt3LjREsrBgwdd1XHZsmXBx6+//uoqmtrXaNR/M3v27GEPAAAAAIirFB8co1UKDx06lGDLlmjLL1++vBvA5scffww+t2fPHlu7dm3wdaJ51A/So+nq56jXiyqmeq5UqVKnPRRkAQAAACC+pdjbcSiUacRTNSNVH8Rs2bK5QPbMM89Yq1atznv5N998s+s3WbduXdfPUVVGNQktU6aMa14aSaOkar1qVqr+iNoe9VW85JJLwrYnQ4YM9sADD9iLL77omq12797drrjiCjcirAwcONBatGjh7k2pbVBYVPNVNZt96qmnznu/AAAAACBSii1Rqe+f+hOOHj3arr76aqtUqZJrrqrgpsFnzpduk/Hpp5+6fo0KixqsRoFx9uzZLvBFo/tEasAbBT8NfqNRVT///HMXFj26TUffvn3ttttuc8FU+/HOO++ErXfmzJluPWomq1CpfdTtRgAAAAAgIaQJKL0gWVAfSfWXVNPUhKTbcWh01UHzN1hM1mwJui4AAAAA/0+/anksOfGygQbR9BsLJcVWHAEAAAAA8YPgGIuKFSuG3fIi9KH7LwIAAABAapFiB8c5X+p7ePz48ajT8ufPnyDr1K1C9AAAAACA5ITgGIvUMNhM76q5uacjAAAAgDOiqSoAAAAAwBfBEQAAAADgi+AIAAAAAPBFcAQAAAAA+CI4AgAAAAB8ERwBAAAAAL4IjgAAAAAAXwRHAAAAAIAvgiMAAAAAwBfBEQAAAADgi+AIAAAAAPBFcAQAAAAA+CI4AgAAAAB8ERwBAAAAAL4IjgAAAAAAXwRHAAAAAIAvgiMAAAAAwBfBEQAAAADgi+AIAAAAAPBFcAQAAAAA+ErvPxkp2ajleywm67Gk3gwkc/2q5UnqTQAAAEASo+IIAAAAAPBFcAQAAAAA+CI4AgAAAAB8ERwBAAAAAL4IjgAAAAAAXwRHAAAAAIAvgmMS2L17t3Xp0sWKFi1qmTJlsgIFCliTJk1swYIFSb1pAAAAAHAa7uOYBFq3bm3Hjh2zKVOmWMmSJW3nzp02Z84c27NnT1JvGgAAAACchopjItu7d6999913NmLECGvQoIEVK1bMatWqZf3797frr78+OM/dd99tefPmtezZs9v//vc/W758ebBaqQrlsGHDgstcuHChZcyY0YVPAAAAAIhvBMdEljVrVveYMWOGHT16NOo8bdq0sV27dtkXX3xhP//8s1WvXt0aNmxo//zzjwuTEydOtCeeeMJ++uknO3DggHXs2NG6d+/u5olG69m/f3/YAwAAAADiiuCYyNKnT2+TJ092zVRz5sxp9erVs0cffdRWrFjhpn///fe2ePFie++996xmzZpWunRpe+6559y877//vpunefPmds8991j79u3t/vvvtyxZstjw4cNjXaem5ciRI/goUqRIou0vAAAAgAsfwTGJ+jhu27bNPvnkE2vatKnNmzfPVRUVKNUk9eDBg5Y7d+5gdVKPjRs32vr164PLUJg8ceKEC5jTpk1zg+zERs1g9+3bF3xs3bo1kfYUAAAAQErA4DhJJCYmxho3buwejz/+uOvTOGjQIOvatasVLFjQhclIqjp6FCIVPk+dOmWbNm2yypUrx7ouhUq/YAkAAAAAfgiOyUSFChVcv0dVHnfs2OGatBYvXjzqvBqRtUOHDnbLLbdY2bJlXej89ddfLV++fIm+3QAAAABSPpqqJjLdckOjpL755puuX6OaoKq56TPPPGOtWrWyRo0aWZ06deyGG26w2bNnu2qiRk197LHH3GA4op/V5PTFF1+0vn37WpkyZezOO+9M6l0DAAAAkEJRcUxk6q9Yu3ZtGz16tGtuevz4cTdYjQa70SA5adKksc8//9yFw86dOwdvv3H11Vdb/vz5XRPW559/3ubOnetu1SFvvPGGVa1a1caOHWtdunRJ6l0EAAAAkMKkCQQCgaTeCCQu3Y5Do6sOmr/BYrJmS+rNQTLXr1qepN4EAAAAJHA2UItGrzAVDU1VAQAAAAC+CI4AAAAAAF8ERwAAAACALwbHScV6V83t244ZAAAAAISKIwAAAADAF8ERAAAAAOCL4AgAAAAA8EVwBAAAAAD4IjgCAAAAAHwRHAEAAAAAvgiOAAAAAABfBEcAAAAAgC+CIwAAAADAF8ERAAAAAOCL4AgAAAAA8EVwBAAAAAD4IjgCAAAAAHwRHAEAAAAAvgiOAAAAAABfBEcAAAAAgC+CIwAAAADAF8ERAAAAAOCL4AgAAAAA8EVwBAAAAAD4Sp/UG4CkM2r5HovJeiypNwPJWL9qeZJ6EwAAAJAMUHEEAAAAAPgiOAIAAAAAfBEcAQAAAAC+CI4AAAAAAF8ERwAAAABA8giOadKksRkzZtiF5pprrrGePXsm9WYAAAAAwIUfHHfs2GEPPPCAlSxZ0jJlymRFihSxli1b2pw5cywxdOrUyW644YaogdV75MiRw+rVq2fffPNNnJf74Ycf2pNPPhmneSdPnhy2vmiPTZs2ndV+AQAAAECKCI4KQzVq1HCB7Nlnn7Vff/3VvvzyS2vQoIF169bNktqkSZNs+/bttmDBAsuTJ4+1aNHCNmzYEKfX5sqVy7JlyxaneW+55Ra3Hu9Rp04du+eee8KeU6AGAAAAgFQXHLt27eqqaYsXL7bWrVtbmTJlrGLFita7d2/74YcfgvP9/fffduONN9pFF11kpUuXtk8++SRsOStXrrRmzZpZ1qxZLX/+/NaxY0f3Gs/7779vlStXtsyZM1vu3LmtUaNGdujQIXviiSdsypQp9vHHHwcre/PmzQu+LmfOnFagQAGrVKmSjR071v777z/76quvbM+ePdauXTu75JJL3DZp2W+//bZvU9XixYvbsGHD7M4773SBsmjRojZ+/Hg3Tdul9XiPjBkzuuXq59mzZ7tjcuLEibDlq0qq/RTtx2WXXWbjxo1zAVOvbdu2re3bty/sNa+//rqVL1/eYmJirFy5cvbKK6+c5xkEAAAAgAQMjv/884+rLqqymCVLltOmK7R5Bg8e7ILQihUrrHnz5ta+fXv3etm7d6/973//s2rVqtlPP/3klrlz5043v6hap5CnwLZ69WoXDG+66SYLBAL20EMPufmaNm0arOzVrVs36vYq3MmxY8fsyJEjrlL62WefudB67733uhCnAOxn5MiRVrNmTfvll19caO7SpYutXbvW9zVt2rSxkydPhoXlXbt2uXVrnzx//PGHvfvuu/bpp5+6Y+CtwzNt2jQbOHCgDR061B0HhdjHH3/cBefYHD161Pbv3x/2AAAAAIBEC44KOgpvqnzFpR+iwl+pUqVc4Dl48GAwpL388ssuNOp5LUs/T5w40ebOnWu///67C4Oq1iksquqn6qAClaqTeigQqm9laLUv0uHDh23AgAGWLl06q1+/vqs0KnSqyqe+meqjqfCp4OZHoVfr1n707dvXNX/VdvrR9t12222u2aznzTffdBVLVTU9CrNTp05123T11VfbSy+9ZNOnT3d9SGXQoEEuuOo4lChRwv3bq1cvV6WMzfDhw13/Tu9Bc1kAAAAAZyO9nSeFxriqUqVK8GdVJ7Nnz+6qbrJ8+XIXvhQCI61fv96uvfZaa9iwoQuMTZo0cb/ffPPNdvHFF59xvQqrCotqopo3b16bMGGC2xZVABVUFRT/+usvV4VUdU5NROO6H2oWq6Dq7Ycf9Xe8/PLL3boUWjWYjsK0luFRkNQ0j/pJnjp1ylU01TRWx+Kuu+5yy/IoUCsQxqZ///6u2bBHFUfCIwAAAIBEC47qq6jgs2bNmjPOmyFDhrDf9TqFIlH1UaOwjhgx4rTXFSxY0AU/9UtcuHCh6y+oStxjjz1mP/74o6u8+Rk9erTrD6lwpeDo0UA+L7zwgj3//PMukCrMqj+jAuS57ocfVVGrVq3qKooKvr/99ptrqhpXOkby2muvWe3atcOm6fjERpVYPQAAAAAgSYKjRh1VBXDMmDHWo0eP0/o5qu9iaD/H2FSvXt0++OAD1ww1ffrom6WApttp6KF+fsWKFbOPPvrIVdPUNFUVxGhUEVSz0kgaZbVVq1bWoUMH97vCn5rFVqhQwRLK3Xff7YKqqo4Ks5GVvy1btti2bdusUKFC7ncNLpQ2bVorW7asGzBIz2tEWPUPBQAAAIALZlRVhUaFtlq1arnwt27dOjdwy4svvuiaWsaFBtfRQDlqVrpkyRLXJHPWrFnWuXNnt2xVFtWsVAPnKFzp/oq7d+92o4uKAqcG3VGTTo3Eevz48ThVS70qprb3vvvucwPyJCT1c/zzzz9d1TB0UByPRkq94447XNPd7777zoVxDfyj8OsNMKQ+izq2Crm69Yn6TY4aNSpBtxsAAABA6hUvwVEDyyxdutTdt7FPnz7utheNGze2OXPmuNtfxIUqaaoAKiSqGaeajqrZqKqVqripP+T8+fPdwDS63YcGudEgMbp9h6jPn6pyGu1UzVG1rDPRMlTpVMVUA9QonOn2GAlJzWV1yxL15Yy2LlVGNeCN9lPHQf0pQ2+3oYqlbsehsKhjpEF+1FfyTM11AQAAAOBcpQmczeg2iBca5Ef3dFTVMJTu4zhjxgxbtmxZgq5fg+MowA6av8FismZL0HXhwtavWp6k3gQAAAAkQjbQveNVrEuwPo6Iu3///dfdf1KP0CoiAAAAACRnBMdEpFFVFR41cqya1QIAAADAhYCmqqkQTVURVzRVBQAASNloqooz6l01t+/FAQAAAADxNqoqAAAAACDlIjgCAAAAAHwRHAEAAAAAvgiOAAAAAABfBEcAAAAAgC+CIwAAAADAF8ERAAAAAOCL4AgAAAAA8EVwBAAAAAD4IjgCAAAAAHwRHAEAAAAAvgiOAAAAAABfBEcAAAAAgC+CIwAAAADAF8ERAAAAAOCL4AgAAAAA8EVwBAAAAAD4IjgCAAAAAHwRHAEAAAAAvgiOAAAAAABf6f0nIyUbtXyPxWQ9ltSbkeL1q5YnqTcBAAAAOC9UHAEAAAAAvgiOAAAAAABfBEcAAAAAgC+CIwAAAADAF8ERAAAAAOCL4BiL4sWL2/PPP+87T5o0aWzGjBmWmDZt2uTWu2zZskRdLwAAAIDUK1UGx61bt9qdd95phQoVsowZM1qxYsXswQcftD179iT1pgEAAABAspPqguOGDRusZs2atm7dOnv77bftjz/+sFdffdXmzJljderUsX/++SepNxEAAAAAkpVUFxy7devmqoyzZ8+2+vXrW9GiRa1Zs2b29ddf219//WWPPfZY1NcpaF599dUWExNjFSpUsK+++ipqE9Lp06db3bp13XyVKlWyb7/9Nmy+lStXuvVlzZrV8ufPbx07drS///47OP3LL7+0K6+80nLmzGm5c+e2Fi1a2Pr162Pdn5MnT7rqably5WzLli3nfXwAAAAAIFUHR1UTZ82aZV27drXMmTOHTStQoIC1b9/e3nnnHQsEAmHTTp06ZTfddJMLnD/++KOrUPbt2zfqOh5++GHr06eP/fLLL66C2bJly2AT2L1799r//vc/q1atmv30008uJO7cudPatm0bfP2hQ4esd+/ebrqqoGnTprUbb7zRbUOko0ePWps2bVx/x++++86F4Gg03/79+8MeAAAAABBX6S0VUdVQobB8+fJRp+v5f//913bv3h32vKqRa9ascaFT/SJl2LBhrnIYqXv37ta6dWv389ixY104nDBhgj3yyCP28ssvu9Co13omTpxoRYoUsd9//93KlCkTfG3o9Lx589qqVatcBdNz8OBBu+6661wonDt3ruXIkSPW/R4+fLgNHjw4zscJAAAAAFJtxdETWVE8k9WrV7tw54VGUTUxmtDn06dP7/pT6vWyfPlyF/LUTNV7qImpeM1RFW7btWtnJUuWtOzZs7vRXSWyGarmUXVSTW79QqP079/f9u3bF3xocCAAAAAAiKtUVXEsVaqU64eoIKfmn5H0/MUXX+wqfAlBVUI1XR0xYsRp0woWLOj+1XSN8vraa6+5oKomqqo0Hjt2LGz+5s2b25tvvmmLFi1yzV/9ZMqUyT0AAAAA4FykqoqjBptp3LixvfLKK/bff/+FTduxY4dNmzbNbrnlFhcuI5uwqkq3ffv24HM//PBD1HWEPn/ixAn7+eefg01jq1evbr/99purIirEhj6yZMni+kKuXbvWBgwYYA0bNgw2nY2mS5cu9vTTT9v1119/2gA8AAAAABCfUlVwFPUzVL/AJk2a2Pz5810gVD9EBcpLLrnEhg4detprGjVq5Pof3nHHHa65qQaiiW301TFjxthHH33k+kRqBFcFP416KvpdA/SomemSJUtc81T1m+zcubMbHVXVToXb8ePHu9uEfPPNN26gnNg88MAD9tRTT7mRV7///vt4PEoAAAAAkIqDY+nSpd2IpepDqNFML730Urv33nutQYMGrtlnrly5TnuNRjZVGFSVslatWnb33XdHDZiiKqAeVatWdWHuk08+sTx58rhpanq6YMECFxKvvfZaq1y5svXs2dPdekPr0EO381CVUs1Te/XqZc8++6zv/uj1GvhGTVcXLlwYT0cJAAAAAP6fNIGzHSkGUek+jiVKlHC34bjsssssOdPtODSgzqD5Gywma7ak3pwUr1+1//viAAAAAEiu2UCDaGpwztikuoojAAAAAODsEBwBAAAAAL5S1e04EpJGSqXVLwAAAICUiOCYivWumtu3HTMAAAAACE1VAQAAAAC+CI4AAAAAAF8ERwAAAACAL4IjAAAAAMAXwREAAAAA4IvgCAAAAADwRXAEAAAAAPgiOAIAAAAAfBEcAQAAAAC+CI4AAAAAAF8ERwAAAACAL4IjAAAAAMAXwREAAAAA4IvgCAAAAADwRXAEAAAAAPgiOAIAAAAAfBEcAQAAAAC+CI4AAAAAAF8ERwAAAACAL4IjAAAAAMBXev/JSMlGLd9jMVmPJfVmpEj9quVJ6k0AAAAA4g0VRwAAAACAL4IjAAAAAMAXwREAAAAA4IvgCAAAAADwRXAEAAAAAKTs4PjEE0/YZZddZhei4sWL2/PPP5/UmwEAAAAA8RccO3XqZGnSpDnt0bRpU0sqDz30kM2ZMyfelzt8+HBLly6dPfvss5ZQlixZYvfee2+CLR8AAAAAkqTiqJC4ffv2sMfbb79tCeHYsTPfYzBr1qyWO3fueF/3xIkT7ZFHHnH/JpS8efPaRRddlGDLBwAAAIAkCY6ZMmWyAgUKhD0uvvhimzdvnmXMmNG+++674LzPPPOM5cuXz3bu3Ol+37p1q7Vt29Zy5sxpuXLlslatWtmmTZvCKpo33HCDDR061AoVKmRly5Z1z//555/Wrl0795osWbJYzZo17ccff4zaVFXbUatWLTef1lOvXj3bvHlzcPrHH39s1atXt5iYGCtZsqQNHjzYTpw4EbaP3377rf333382ZMgQ279/vy1cuDBsurfON954wzU3zZEjh91666124MCB4Dz6uX379m47ChYsaKNHj7ZrrrnGevbsGWtTVVVvX3/9dbvxxhtdoCxdurR98sknweknT560u+66y0qUKGGZM2d2x+eFF14421MIAAAAAEnTx9ELRR07drR9+/bZL7/8Yo8//rgLQvnz57fjx49bkyZNLFu2bC5cLliwwFULVcEMrSyq2enatWvtq6++spkzZ9rBgwetfv369tdff7kQtXz5clcJPHXq1GnboACo4Kn5V6xYYYsWLXJNQRXIROu9/fbb7cEHH7RVq1bZuHHjbPLkyS6ohpowYYILqhkyZHD/6vdI69evtxkzZrht1ENh8+mnnw5O7927t9tHbbP2ReteunTpGY+jgqzCtba/efPmLnz+888/bpr2uXDhwvbee++57R84cKA9+uij9u677/ou8+jRoy4Ahz4AAAAAIK7S21lSSFLgC6XwosdTTz3lQpLC2sqVK+2OO+6w66+/3s3zzjvvuOCjIOkFuUmTJrmqoKqE1157rXtOFTrNo+qljB8/3nbv3u36A6riKKVKlYq6bQpECq0tWrSwSy+91D1Xvnz5sFDWr18/t12iiuOTTz7pguigQYOCy3j//fdd6JQOHTrYVVdd5Sp7ofutfVHoVBAWBWaFXoVQVRunTJlib731ljVs2DC4r6qinomqrgqrMmzYMHvxxRdt8eLFLmAryGofPKo8ajsVHBU2/fprhr4OAAAAABI0ODZo0MDGjh0b9pwX6BT2pk2bZlWqVLFixYq55pkeVQr/+OOPYNDyHDlyxFXvPJUrVw6GRlm2bJlVq1YtuA4/mkfBS5XNxo0bW6NGjVygUlNRbxtUBQytMKr5p7bh8OHDrnmo+msqdFatWtVNV5NU7YuCr5qJhjYzDd0XrWPXrl3u5w0bNrgKq5rMetSc1Wt660fHzqMQnT179uByZcyYMa7f5ZYtW1xzWlVrzzSqbP/+/V0F1KNwXKRIkTNuCwAAAACcU3BUmImt4idef0A1r9RD84uanNaoUcMFy2iDxIQuP5T68p0NVfZ69OhhX375pQt7AwYMcFXQK664wm2DKm833XTTaa9Tn0dRs9TffvvN0qdPH1ZdVFgLDY6q/oVSFTVa89mz5bfc6dOnu1FkR44caXXq1HHBVaO+ev09/fql6gEAAAAAiRIc/ahy2KtXL3vttddcaFOT0K+//trSpk3rBqTRcxosR1W0uFIFTk1XFULjUnUUVSj1UKVNAUtNRhUctQ3qPxlb8P3111/tp59+ck1nQ9eldasP55o1a6xcuXJnXL+awCoAqnlt0aJF3XNqQvv777/b1VdfbedK1dK6deta165dg8+FVmsBAAAAIFkMjqOBVnbs2BH2+Pvvv12TT/UHVDPRzp07u8qfBnhRdUw0yEuePHncSKoaKGbjxo0uoKk6qFFTY6P+fhq5VYPeKDipGegHH3wQ7IMYSstUWNQ0jaQ6e/ZsW7duXbCfowaTmTp1qqs6qqq4evVqV8VTVdKrNqp5qcJdpUqVgg/9fvnll0cdJCcaVQIVmh9++GGbO3euW5eqlQrQXv/Oc6FRVhVsZ82a5UKoBh9SOAUAAACAZBUc1QRU/flCH1deeaXrN6iwppFKRc9rYBuFMvUtVP/B+fPnuwqcmooqzClMqX+hXwVS/R0VAFWp1Cij6gOp0UvTpUt32rxah6qCrVu3tjJlyrhBerp162b33Xefm65Qq8F9tDwFQVUh1Q9TfRjVV/DNN990r41Gzyt0qu9iXIwaNcpVOzVQj/pa6rYg2mevSey50H7o2N1yyy1Wu3Zt27NnT1j1EQAAAAASQppAIBBIkCUjzKFDh+ySSy5xFdjQvpJJQYPjaLCeQfM3WEzW8MGKED/6VcuT1JsAAAAAxDkbqGudX0EvXvs44v/RfSxV/VTTV52EIUOGuOfVVBcAAAAALiQExwT03HPPucF41NxWI8qqb6f6eQIAAADAhYTgmEA0quvPP/+c1JsBAAAAAOeN4JiK9a6a+6xujQIAAAAgdTrrUVUBAAAAAKkLwREAAAAA4IvgCAAAAADwRXAEAAAAAPgiOAIAAAAAfBEcAQAAAAC+CI4AAAAAAF8ERwAAAACAL4IjAAAAAMAXwREAAAAA4IvgCAAAAADwRXAEAAAAAPgiOAIAAAAAfBEcAQAAAAC+CI4AAAAAAF8ERwAAAACAL4IjAAAAAMAXwREAAAAA4IvgCAAAAADwRXAEAAAAAPhK7z8ZKdmo5XssJusxu9D0q5YnqTcBAAAASFWoOAIAAAAAfBEcAQAAAAC+CI4AAAAAAF8ERwAAAACAL4IjAAAAAMAXwREAAAAA4IvgmMgWLVpk6dKls+uuuy6pNwUAAAAA4oTgmMgmTJhgDzzwgM2fP9+2bduW1JsDAAAAAGdEcExEBw8etHfeece6dOniKo6TJ08Om/7JJ59Y6dKlLSYmxho0aGBTpkyxNGnS2N69e4PzfP/993bVVVdZ5syZrUiRItajRw87dOhQEuwNAAAAgNSC4JiI3n33XStXrpyVLVvWOnToYBMnTrRAIOCmbdy40W6++Wa74YYbbPny5XbffffZY489Fvb69evXW9OmTa1169a2YsUKF0IVJLt37+673qNHj9r+/fvDHgAAAAAQVwTHRG6mqsAoCoD79u2zb7/91v0+btw4FyifffZZ9++tt95qnTp1Cnv98OHDrX379tazZ09Xmaxbt669+OKLNnXqVDty5Eis69XrcuTIEXyoUgkAAAAAcUVwTCRr1661xYsXW7t27dzv6dOnt1tuucWFSW/65ZdfHvaaWrVqhf2uSqSat2bNmjX4aNKkiZ06dcpVLGPTv39/F1K9x9atWxNkHwEAAACkTOmTegNSCwXEEydOWKFChYLPqZlqpkyZ7OWXX45zH0k1YVW/xkhFixaN9XVahx4AAAAAcC4IjolAgVHNSUeOHGnXXntt2DT1aXz77bdd89TPP/88bNqSJUvCfq9evbqtWrXKSpUqlSjbDQAAAABCcEwEM2fOtH///dfuuusu18cwlAa6UTVSA+eMGjXK+vbt6+ZbtmxZcNRVjawqmnbFFVe4wXDuvvtuy5IliwuSX331VZyrlgAAAABwtujjmAgUDBs1anRaaPSC408//WQHDhyw999/3z788EOrUqWKjR07NjiqqtfMVM9rMJ3ff//d3ZKjWrVqNnDgwLDmrwAAAAAQ39IEvPtBINkZOnSovfrqq/E+mI1ux6EQO2j+BovJms0uNP2q5UnqTQAAAABSBC8baBDN7NmzxzofTVWTkVdeecWNrJo7d25bsGCBuzXHme7RCAAAAAAJjeCYjKxbt86eeuop++eff9woqX369HG30gAAAACApERwTEZGjx7tHgAAAACQnBAcU7HeVXP7tmMGAAAAAGFUVQAAAACAL4IjAAAAAMAXwREAAAAA4IvgCAAAAADwRXAEAAAAAPgiOAIAAAAAfBEcAQAAAAC+CI4AAAAAAF8ERwAAAACAL4IjAAAAAMAXwREAAAAA4IvgCAAAAADwRXAEAAAAAPgiOAIAAAAAfBEcAQAAAAC+CI4AAAAAAF8ERwAAAACAL4IjAAAAAMAXwREAAAAA4IvgCAAAAADwld5/MlKyUcv3WEzWY5Yc9KuWJ6k3AQAAAEAsqDgCAAAAAHwRHAEAAAAAvgiOAAAAAABfBEcAAAAAgC+CIwAAAADAF8ERAAAAAOCL4BhFp06dLE2aNHb//fefNq1bt25umuaJL9dcc4317NnztOcnT55sOXPmDPtd69Yjbdq0VrBgQbvllltsy5Yt8bYtAAAAABCJ4BiLIkWK2PTp0+2///4LPnfkyBF76623rGjRokm2XdmzZ7ft27fbX3/9ZR988IGtXbvW2rRpk2TbAwAAACDlIzjGonr16i48fvjhh8Hn9LNCY7Vq1YLPffnll3bllVe6ymDu3LmtRYsWtn79+uD0qVOnWtasWW3dunXB57p27WrlypWzw4cPn/V2qdpYoEABV22sW7eu3XXXXbZ48WLbv3//ee0vAAAAAMSG4OjjzjvvtEmTJgV/nzhxonXu3DlsnkOHDlnv3r3tp59+sjlz5rgmpDfeeKOdOnXKTb/99tutefPm1r59eztx4oR99tln9vrrr9u0adPsoosuOq/t27Vrl3300UeWLl0694jN0aNHXbAMfQAAAABAXKWP85ypUIcOHax///62efNm9/uCBQtc89V58+YF52ndunXYaxQu8+bNa6tWrbJKlSq558aNG2dVqlSxHj16uKrlE088YTVq1Ah73SuvvOICZSgFzZiYmLDn9u3b5yqYgUAgWLHUcrNkyRLrfgwfPtwGDx58zscBAAAAQOpGxdGHAuB1113nBqVR5VE/58mTJ2weNUFt166dlSxZ0vU/LF68uHs+dMCaiy++2CZMmGBjx461Sy+91Pr163faulSRXLZsWdhjyJAhp82XLVs2N00VzpEjR7omtUOHDvXdD4VfBU7vsXXr1vM4KgAAAABSGyqOcWiu2r17d/fzmDFjTpvesmVLK1asmL322mtWqFAh10RVlcZjx46FzTd//nzXnFQD26h5qwJgqBw5clipUqXCnsuXL99p61NTWG++8uXLu/6UXbp0sTfeeCPWfciUKZN7AAAAAMC5oOJ4Bk2bNnUh8Pjx49akSZOwaXv27HGjmg4YMMAaNmzogty///572jIWLlxoI0aMsE8//dQ1M/WCaHxQ9fKdd96xpUuXxtsyAQAAACAUFcczUJVw9erVwZ9DqQmqRlIdP368G+VUzVMjm6EeOHDAOnbs6PohNmvWzAoXLmyXX365q1TefPPN5719GvlVg/EMHDjQZs6ced7LAwAAAIBIVBzjQH0X9YjWbFSD5fz888+ueWqvXr3s2WefDZvnwQcfdAPXDBs2zP1euXJl9/N9993n7sUYH7Rejdaq23IAAAAAQHxLE9DwnEhVdDsO9akcNH+DxWQN72uZVPpVCx90CAAAAEDiZQMNohmtWOah4ggAAAAA8EVwBAAAAAD4IjgCAAAAAHwxqmoq1rtqbt92zAAAAAAgVBwBAAAAAL4IjgAAAAAAXwRHAAAAAIAvgiMAAAAAwBfBEQAAAADgi+AIAAAAAPBFcAQAAAAA+CI4AgAAAAB8ERwBAAAAAL4IjgAAAAAAXwRHAAAAAIAvgiMAAAAAwBfBEQAAAADgi+AIAAAAAPBFcAQAAAAA+CI4AgAAAAB8ERwBAAAAAL4IjgAAAAAAXwRHAAAAAIAvgiMAAAAAwFd6/8lIyUYt32MxWY8l2fr7VcuTZOsGAAAAEHdUHAEAAAAAvgiOAAAAAABfBEcAAAAAgC+CIwAAAADAF8ERAAAAAOCL4HgOOnXqZDfccENSbwYAAAAAJIq0KSHEpUmTxj0yZMhgJUqUsEceecSOHDly3svetGmTW+6yZcvCnn/hhRds8uTJFt+8/dAjffr0VrRoUevdu7cdPXo0OI/W682TNm1aK1y4sHXu3Nl27doV79sDAAAAACnmPo5Nmza1SZMm2fHjx+3nn3+2O+64wwWrESNGJMj6cuTIYQlF+6H90b4sX77chcIsWbLYk08+GZwne/bstnbtWjt16lRwnm3bttmsWbMSbLsAAAAApF4XfMVRMmXKZAUKFLAiRYq4JqSNGjWyr776yk1TuBo+fLirRGbOnNmqVq1q77//fvC1//77r7Vv397y5s3rppcuXdqFN9FrpFq1ai6IXnPNNVGbqur5Hj16uEpnrly53LY88cQTYdu4Zs0au/LKKy0mJsYqVKhgX3/9tVvmjBkzwubLmTNncF9atGhhrVq1sqVLl4bNo9dpnkKFClmzZs3curW8//77L96PLQAAAACkiIpjqJUrV9rChQutWLFi7neFxjfffNNeffVVFwrnz59vHTp0cEGxfv369vjjj9uqVavsiy++sDx58tgff/wRDGCLFy+2WrVquVBWsWJFy5gxY6zrnTJlimtW+uOPP9qiRYtcuKxXr541btzYTp486YKmmp5q+oEDB6xPnz5n3Jfff//dvvnmG7csPwq8CsgnTpyIOl1NXUObu+7fv/+M6wYAAACAFBUcZ86caVmzZnXBSQFJff9efvll9/OwYcNc8KtTp46bt2TJkvb999/buHHjXHDcsmWLqyjWrFnTTS9evHhwuQqXkjt3blfh81OlShUbNGiQ+1kBVeufM2eOC46qfq5fv97mzZsXXM7QoUPdtEjt2rWzdOnSBfdFVcf+/fvHut5169a5UKztz5YtW9R5FJ4HDx4chyMJAAAAACm0qWqDBg3cADaq5ql/o/r8tW7d2lUPDx8+7AKagqX3mDp1qgty0qVLF5s+fbpddtllrqmpqpXnQsExVMGCBYMD1qg/opqehoZPVTKjGT16tNsX9V1UIFbVsWPHjmHz7Nu3z+3HRRddZGXLlrX8+fPbtGnTYt02BU+9xnts3br1nPYRAAAAQOqUIiqOGjymVKlS7ueJEye6fowTJkywSpUquec+++wzu+SSS07rFynqI7h582b7/PPPXWWwYcOG1q1bN3vuuefOahs0omtkP0Q1Hz1bCpfevigUqlmrqpBPPfVU8HlVFtXvUZVVBVQ1VfWjffX2FwAAAABSZXAMpTD16KOPuv6GqtYpMKk5qpqlxkZNUlWp1OOqq66yhx9+2AVHr0+j+iieDwVAVfl27tzpqoOyZMmSOL1WzVYldOAb7aMXIgEAAAAgoaW44Cht2rRx4U/9GB966CHr1auXq/5pVFM11VywYIG7pYWC4sCBA61GjRpu8Bv1KVTz0PLly7vl5MuXz1XzvvzyS3e/RI2Iei634lBT2UsvvdSt75lnnnFVxAEDBgQrk6H27t1rO3bscNur/otDhgyxMmXKBLcJAAAAABJbiujjGCl9+vTWvXt3F9LUv08jp2qAGIUv3SNRTVe9W22oqqh51Efx6quvdhU+9Xn0lvPiiy+6AKpbX+jWGOdCy9RtNw4ePGiXX3653X333fbYY4+5aQqjodQ/U81PFVTVRFWBViO+alsAAAAAICmkCQQCgSRZcyqnqqcqoBrAR9XIxKTbcahyOmj+BovJGn0k1sTQr1qeJFs3AAAAAAtmA7XMVKvM2FDGSiQfffSRGwlVt+pQWHzwwQfdfR4TOzQCAAAAwNkiOCYS9Wvs27evG6gnT5481qhRIxs5cmRSbxYAAAAAnBHBMZHcfvvt7gEAAAAAFxqCYyrWu2pu33bMAAAAAJBiR1UFAAAAAMQfgiMAAAAAwBfBEQAAAADgi+AIAAAAAPBFcAQAAAAA+CI4AgAAAAB8ERwBAAAAAL4IjgAAAAAAXwRHAAAAAIAvgiMAAAAAwBfBEQAAAADgi+AIAAAAAPBFcAQAAAAA+CI4AgAAAAB8ERwBAAAAAL4IjgAAAAAAXwRHAAAAAIAvgiMAAAAAwBfBEQAAAADgi+AIAAAAAPCV3n8yUrJRy/dYTNZjibKuftXyJMp6AAAAAMQ/Ko4AAAAAAF8ERwAAAACAL4IjAAAAAMAXwREAAAAA4IvgCAAAAADwRXD8/3Xq1MluuOGGpN4MAAAAAEh20ibXEJcmTRr3yJAhg5UoUcIeeeQRO3LkyHkve9OmTW65y5YtC3v+hRdesMmTJ1t88/Yj8jF9+vTgPIFAwMaPH2+1a9e2rFmzWs6cOa1mzZr2/PPP2+HDh4Pz7d+/3x5//HGrWLGiZc6c2XLnzm2XX365PfPMM/bvv//G+7YDAAAAQLK+j2PTpk1t0qRJdvz4cfv555/tjjvucIFrxIgRCbK+HDlyWELRfmh/Qikcejp27GgffvihDRgwwF5++WXLmzevLV++3AXH4sWLu0roP//8Y1deeaULj08++aTVqFHDbfPatWvd8t966y3r1q1bgu0DAAAAgNQrWVYcJVOmTFagQAErUqSIC06NGjWyr776yk07deqUDR8+3FUiVXmrWrWqvf/++8HXqvrWvn17F8A0vXTp0i5ciV4j1apVc0H0mmuuidpUVc/36NHDVTpz5crltuWJJ54I28Y1a9a4MBcTE2MVKlSwr7/+2i1zxowZp4VEvT70odfIu+++a9OmTbO3337bHn30UVdBVFhs1aqVffPNN9agQQM3n6Zt2bLFFi9ebJ07d7YqVapYsWLF7Nprr3Wv7dq1awKdCQAAAACpXbKtOIZauXKlLVy40AUlUWh888037dVXX3WhcP78+dahQwcXFOvXr++ac65atcq++OILy5Mnj/3xxx/233//udcqeNWqVcuFPDX5zJgxY6zrnTJlivXu3dt+/PFHW7RokQuX9erVs8aNG9vJkydd0CxatKibfuDAAevTp89Z75tCY9myZV1QjKQQqqqigvI777zj9rFQoUJRl6N5Y3P06FH38KhqCQAAAAAXfHCcOXOm6+934sQJF3rSpk3rmnHq52HDhrngV6dOHTdvyZIl7fvvv7dx48a54KjKnCqK6icoquB5FC5F/QNV+fOjqt6gQYPczwqoWv+cOXNccFT1c/369TZv3rzgcoYOHeqmRWrXrp2lS5cu7DkFW4XOdevWueDoZ/fu3bZ3797T5lNzVTVVlZYtW7rKYzQK2oMHD/ZdBwAAAABccMFRTTTHjh1rhw4dstGjR1v69OmtdevW9ttvv7kBYyID2rFjx1xYlC5durh5ly5d6ppyqjJYt27ds94GBcdQBQsWtF27drmfFdjUjDY0fKqSGY22X01tQ3mVQw2Mc64++ugjt999+/YNVlSj6d+/v6uchlYcte0AAAAAcEEHxyxZslipUqXczxMnTnT9GCdMmGCVKlVyz3322Wd2ySWXnNYvUpo1a2abN2+2zz//3FUGGzZs6AaOee65585qGzSia2RzUDUbPVsKl96+RCpTpozrK+lHVVL1k/Sqix5VLCVbtmyuIhkbHRfv2AAAAABAihkcJ5SaqWpwGI06qkFoFILUHFVhLPQRWkVT2NJIrOoLqdFJdbsL8fo0qo/i+VCz0a1bt9rOnTuDzy1ZsuSsl3PbbbfZ77//bh9//PFp01SN3Ldvn9v/tm3bun3Ztm3beW03AAAAAKTI4Cht2rRx/QTVj/Ghhx6yXr16ucFr1M9QTVJfeukl97sMHDjQBTENiqOmreovWb58eTctX758bqTVL7/80oU+BbNzoaayl156qQunK1assAULFrhgG22gGlUDd+zYEfZQE1xRILzllltcP0j13fzpp59ctVTbrOatc+fOdfNpmiqsag6rCqzWqX1Xc1UN3BPZhxIAAAAAUnxT1Ujq49i9e3d3s/uNGze6iqIGfdmwYYNrxlm9enVXlfSqiurXt2nTJhcSr7rqKps+fXpwOS+++KINGTLEBUxN0wA3Z0tBTbfduPvuu90tNDRAz7PPPusGqfFuteHR7TMiadv79evnQqbuwaiKqAKhBtjRNmownttvv92aNGkSHMxHI8LqPpZaj46BKpGaT8GzZ8+e53hkAQAAAMBfmsD5jM6CMKo66r6OqnSqGplcaXAc3eZj0PwNFpM1W6Kss1+1PImyHgAAAABnnw3UEjN79uwXfsUxOVIzUd0yRFU/hcUHH3zQ3ecxOYdGAAAAADhbBMfzcODAAXcrDA3UkydPHtcnceTIkUm9WQAAAAAQrwiO50F9EPUAAAAAgJSM4JiK9a6a27cdMwAAAABcULfjAAAAAAAkDYIjAAAAAMAXwREAAAAA4IvgCAAAAADwRXAEAAAAAPgiOAIAAAAAfBEcAQAAAAC+CI4AAAAAAF8ERwAAAACAL4IjAAAAAMAXwREAAAAA4IvgCAAAAADwRXAEAAAAAPgiOAIAAAAAfBEcAQAAAAC+CI4AAAAAAF8ERwAAAACAL4IjAAAAAMAXwREAAAAA4IvgCAAAAADwld5/MlKyUcv3WEzWYwm6jn7V8iTo8gEAAAAkPCqOAAAAAABfBEcAAAAAgC+CIwAAAADAF8ERAAAAAOCL4AgAAAAASNnBMU2aNDZjxozzWsY111xjPXv2tAvRvHnz3DHYu3dvUm8KAAAAgBQq2QfHHTt22AMPPGAlS5a0TJkyWZEiRaxly5Y2Z84cS44IcgAAAABSmmR9H8dNmzZZvXr1LGfOnPbss89a5cqV7fjx4zZr1izr1q2brVmzxlKqQCBgJ0+etPTpk/UpAgAAAJAKJOuKY9euXV31bvHixda6dWsrU6aMVaxY0Xr37m0//PBDcL6///7bbrzxRrvooousdOnS9sknn4Qt59tvv7VatWq5imXBggWtX79+duLEiVjXe/ToUXvooYfskksusSxZsljt2rVdJdGzefNmV/W8+OKL3XRt0+eff+6CboMGDdw8mqZt79Spk/v91KlTNnz4cCtRooRlzpzZqlatau+///5plcovvvjCatSo4bb1+++/d9vSo0cPy5cvn8XExNiVV15pS5YsidfjDAAAAAAXZHD8559/7Msvv3SVRYWzSKpCegYPHmxt27a1FStWWPPmza19+/bu9fLXX3+55y6//HJbvny5jR071iZMmGBPPfVUrOvu3r27LVq0yKZPn+6W2aZNG2vatKmtW7fOTdc2KdDNnz/ffv31VxsxYoRlzZrVNaP94IMP3Dxr16617du32wsvvOB+V2icOnWqvfrqq/bbb79Zr169rEOHDi7UhlKoffrpp2316tVWpUoVe+SRR9wyp0yZYkuXLrVSpUpZkyZNgvsXF9rW/fv3hz0AAAAAIK6SbTvIP/74wzXXLFeu3BnnVVWvXbt27udhw4bZiy++6KqUCnuvvPKKC3Qvv/yyq+hpedu2bbO+ffvawIEDLW3a8Oy8ZcsWmzRpkvu3UKFC7jlVHxVi9byWr2mqgKrprKj/pSdXrlzuX1UIvXCr4KbXff3111anTp3ga1RRHDdunNWvXz/4+iFDhljjxo3dz4cOHXJBd/LkydasWTP33GuvvWZfffWVC78PP/xwnI6lQqvCNQAAAACkqOCo0BhXqsx5VJ3Mnj277dq1y/2uyp3CmkKjR/0mDx48aH/++acVLVo0bFmqIKpvoZrFhlL4y507t/tZTUe7dOlis2fPtkaNGrkQGboN0ULw4cOHg4HQc+zYMatWrVrYczVr1gz+vH79etenU9vryZAhg2t2q/2Kq/79+7vmvR5VHBWmAQAAAOCCDo7qq6iwF5cBcBSmQul16lN4LhQo06VLZz///LP7N5Sao8rdd9/tmot+9tlnLjyqojdy5Eg3+mtsyxTNr36TodSXMVS0ZrnnS+uIXA8AAAAAXPB9HNXkU+FszJgxrslmpLje7qJ8+fKuv2JoBXPBggWWLVs2K1y48GnzqwKoiqMqlupPGPooUKBAcD5V7O6//3778MMPrU+fPq4JqWTMmNH9q2V4KlSo4IKbmrhGLtOv8nfppZe65Wl7PapAanAcLRMAAAAAUnVwFIVGBTA1zdQAMRqcRk001YfR6ysYl5FZt27d6qqBql5+/PHHNmjQINd0M7J/o6iJqgbXuf32210o3Lhxo+svqaqiKobSs2dPd0sQTdOANXPnznUBVYoVK+YqnjNnzrTdu3e7aqNCqvpJakAcDXKjJqh63UsvveR+j42qj2oSq76M6mO5atUqu+eee1yz17vuuuucjysAAAAApIimqt4AMgpYQ4cOdVU9jVKaN29ed7sKDRoTF2oaqltlKHzpFhiqZCp0DRgwINbXaBAcjbqqdWpU1jx58tgVV1xhLVq0cNMVZjWyqvpIqj+lBuEZPXp0cH0aiEajo3bu3NkFUA1u8+STT7ptVwDdsGGDGzinevXq9uijj/puv0ZYVbPbjh072oEDB1wfSIVW3e4DAAAAABJDmsDZjEKDFEGD4+TIkcMGzd9gMVmzJei6+lXLk6DLBwAAAHD+2WDfvn2uKHZBNlUFAAAAACQ9giMAAAAAwBfBEQAAAABw4Q6Og4TVu2pu33bMAAAAACBUHAEAAAAAvgiOAAAAAABfBEcAAAAAgC+CIwAAAADAF8ERAAAAAOCL4AgAAAAA8EVwBAAAAAD4IjgCAAAAAHwRHAEAAAAAvgiOAAAAAABfBEcAAAAAgC+CIwAAAADAF8ERAAAAAOCL4AgAAAAA8EVwBAAAAAD4IjgCAAAAAHwRHAEAAAAAvgiOAAAAAABfBEcAAAAAgC+CIwAAAADAF8ExFRu1fI89/cvfSb0ZAAAAAJI5giMAAAAAwBfBEQAAAADgi+AIAAAAAPBFcAQAAAAA+CI4AgAAAAB8ERzPwTXXXGM9e/ZM6s0AAAAAgESRYoJjp06dLE2aNKc9/vjjj3Ne5rx589wy9u7dG/b8hx9+aE8++aTFp02bNoVtd8aMGa1UqVL21FNPWSAQCM63ceNGu+2226xQoUIWExNjhQsXtlatWtmaNWvidXsAAAAAwJPeUpCmTZvapEmTwp7LmzdvvK8nV65cllC+/vprq1ixoh09etS+//57u/vuu61gwYJ211132fHjx61x48ZWtmxZF171/J9//mlffPHFaeEWAAAAAOJLiqk4SqZMmaxAgQJhjxdeeMEqV65sWbJksSJFiljXrl3t4MGDwdds3rzZWrZsaRdffLGbR6Ht888/dxXABg0auHk0TVVAVTWjNVUtXry4DRs2zO68807Lli2bFS1a1MaPHx+2bQsXLrTLLrvMVQlr1qxpM2bMcMtctmxZ2Hy5c+d2212sWDFr37691atXz5YuXeqm/fbbb7Z+/Xp75ZVX7IorrnDzaLqqkvodAAAAABJCigqO0aRNm9ZefPFFF7qmTJli33zzjT3yyCPB6d26dXPVvfnz59uvv/5qI0aMsKxZs7qQ+cEHH7h51q5da9u3b3chNDYjR450gfCXX35x4bRLly7udbJ//34XThVgFQLVzLVv375n3PaffvrJfv75Z6tdu3aweqr9ef/99+3kyZNxPgbaP21D6AMAAAAAUmVT1ZkzZ7rQ52nWrJm99957YZVBVefuv/9+V7WTLVu2WOvWrV2ok5IlS57WJDVfvnyWM2dO33U3b97cBUZRKBw9erTNnTvXNSt96623XHXxtddecxXHChUq2F9//WX33HPPacupW7euC4fHjh1zTVPvvfdeu/322920Sy65xIVgBd/Bgwe7oKqqqCqTodsdafjw4W5+AAAAALDUXnFUiFLTT++hkKU+gw0bNnShS81IO3bsaHv27LHDhw+71/To0cOFSTX5HDRokK1YseKc1l2lSpXgzwqJam66a9cu97sqj5qu0OipVatW1OW88847btuXL19u7777rn388cfWr1+/sArpjh07bNq0aVanTh0XjNW89quvvop12/r372/79u0LPrZu3XpO+wgAAAAgdUpRwVF9FDUSqfdQE80WLVq40KZmp2r2OWbMGDevKnqiwWc2bNjgAqWaqqqK99JLL531ujNkyBD2u8LjqVOnzno5aiKrbS9fvry1adPG9aVUM9gjR44E51EAVtPXoUOHuoB51VVXufDr1/cze/bsYQ8AAAAASJXBMZKCosKbgpcGjylTpoxt27YtalhT81WNVNqnTx/XpFR0Sww5m/6E0ai5qkKpgqxnyZIlcXptunTp7MSJE8GgG0kBtVy5cnbo0KHz2kYAAAAASJXBUZU79RNUBVFVxTfeeMNeffXVsHlU0Zs1a5a7P6IGrlG/RFX7RKOWKpip7+Tu3bvDRmM9G7rvogKs+iuuXr3are+5555z07T8UGpGq6ao3m02NCCPmuCqSqgmrLpnowbHWbVqlbtH5YQJE2zixInueQAAAABICCk6OFatWtVGjRrlRkqtVKmS6xeogWJCqZqofoMKi7oPpKqS3sA56hepQWXUxzB//vzWvXv3c9oOhb5PP/3UBT/dkuOxxx6zgQMHummh/R6lUaNG7v6MGshHQVOD7qjfoxQuXNg9r23SSKvVq1d3wVK/a5kAAAAAkBDSBAKBQIIsGb4UYjt37uwGq8mcOXOirlu348iRI4cNmr/BYrJms37V8iTq+gEAAAAkD142UC7xGwslRd2OIzmbOnWqu2WGqpga0Ea37Gjbtm2ih0YAAAAAOFsEx0Sifotqnqp/1RRVI6ZqVFQAAAAASO4IjonkkUcecQ8AAAAAuNAQHFOx3lVzc09HAAAAAKl7VFUAAAAAwPkjOAIAAAAAfBEcAQAAAAC+CI4AAAAAAF8ERwAAAACAL4IjAAAAAMAXwREAAAAA4IvgCAAAAADwRXAEAAAAAPhK7z8ZKVEgEHD/7t+/P6k3BQAAAEAS8jKBlxFiQ3BMhfbs2eP+LVKkSFJvCgAAAIBk4MCBA5YjR45YpxMcU6FcuXK5f7ds2eJ7ceDC//ZIXw5s3brVsmfPntSbgwTCeU4dOM+pA+c5deA8px77L5BzrUqjQmOhQoV85yM4pkJp0/5f11aFxuR8ESN+6BxznlM+znPqwHlOHTjPqQPnOfXIfgGc67gUkxgcBwAAAADgi+AIAAAAAPBFcEyFMmXKZIMGDXL/IuXiPKcOnOfUgfOcOnCeUwfOc+qRKYWd6zSBM427CgAAAABI1ag4AgAAAAB8ERwBAAAAAL4IjgAAAAAAXwRHAAAAAIAvgmMKMGbMGCtevLjFxMRY7dq1bfHixb7zv/fee1auXDk3f+XKle3zzz8Pm67xkgYOHGgFCxa0zJkzW6NGjWzdunUJvBdI7HN9/Phx69u3r3s+S5YsVqhQIbv99ttt27ZtibAnSMz3dKj777/f0qRJY88//3wCbDmS+jyvXr3arr/+encjZ72vL7/8ctuyZUsC7gUS+zwfPHjQunfvboULF3b/j65QoYK9+uqrCbwXiM/z/Ntvv1nr1q3d/H5/j8/22sGFd56HDx/u/k5ny5bN8uXLZzfccIOtXbvWki2NqooL1/Tp0wMZM2YMTJw4MfDbb78F7rnnnkDOnDkDO3fujDr/ggULAunSpQs888wzgVWrVgUGDBgQyJAhQ+DXX38NzvP0008HcuTIEZgxY0Zg+fLlgeuvvz5QokSJwH///ZeIe4aEPtd79+4NNGrUKPDOO+8E1qxZE1i0aFGgVq1agRo1aiTyniGh39OeDz/8MFC1atVAoUKFAqNHj06EvUFinuc//vgjkCtXrsDDDz8cWLp0qfv9448/jnWZuDDPs5Zx6aWXBubOnRvYuHFjYNy4ce41Ote4MM7z4sWLAw899FDg7bffDhQoUCDq3+OzXSYuzPPcpEmTwKRJkwIrV64MLFu2LNC8efNA0aJFAwcPHgwkRwTHC5w+6Hfr1i34+8mTJ92HwuHDh0edv23btoHrrrsu7LnatWsH7rvvPvfzqVOn3MX97LPPBqcrYGTKlMld+Eg55zq2P3L6Pmnz5s3xuOVIDuf5zz//DFxyySXuf07FihUjOKbA83zLLbcEOnTokIBbjeRwnitWrBgYMmRI2DzVq1cPPPbYY/G+/UiY8xwqtr/H57NMXDjnOdKuXbvc57Bvv/02kBzRVPUCduzYMfv5559dU1JP2rRp3e+LFi2K+ho9Hzq/NGnSJDj/xo0bbceOHWHzqMmTyvGxLRMX5rmOZt++fa45Rc6cOeNx65HU5/nUqVPWsWNHe/jhh61ixYoJuAdIqvOsc/zZZ59ZmTJl3PNq8qS/2zNmzEjgvUFiv5/r1q1rn3zyif3111+ua8ncuXPt999/t2uvvTYB9wbxeZ6TYpk4P4l1Tvbt2+f+zZUrlyVHBMcL2N9//20nT560/Pnzhz2v3xX+otHzfvN7/57NMnFhnutIR44ccX0e27VrZ9mzZ4/HrUdSn+cRI0ZY+vTprUePHgm05Ujq87xr1y7X9+3pp5+2pk2b2uzZs+3GG2+0m266yb799tsE3Bsk9vv5pZdecv0a1ccxY8aM7nyr39XVV1+dQHuC+D7PSbFMnJ/EOCenTp2ynj17Wr169axSpUqWHKVP6g0AkPQ0UE7btm3dt9djx45N6s1BPNI3pC+88IItXbrUVZORMukDh7Rq1cp69erlfr7sssts4cKFbuCU+vXrJ/EWIr4oOP7www+u6lisWDGbP3++devWzQ1wFlmtBHDh6Natm61cudK+//57S66oOF7A8uTJY+nSpbOdO3eGPa/fCxQoEPU1et5vfu/fs1kmLsxzHRkaN2/ebF999RXVxhR2nr/77jtXjSpatKirOuqhc92nTx830htSxnnWMnVuVYkKVb58eUZVTUHn+b///rNHH33URo0aZS1btrQqVaq4EVZvueUWe+655xJwbxCf5zkplonzk9DnpHv37jZz5kzX9FytCZIrguMFTE1UatSoYXPmzAn71lm/16lTJ+pr9Hzo/KKw4M1fokQJ9wYInWf//v32448/xrpMXJjnOjQ06nYrX3/9teXOnTsB9wJJcZ7Vt3HFihW2bNmy4EOVCfV3nDVrVgLvERLrPGuZGtI9chh39X1TVQop4zzrb7Ye6lsVSh9ovaozkv95Topl4vwk1DkJBAIuNH700Uf2zTffuM/hyVpSj86D8x8aWCOeTp482Q3dfe+997qhgXfs2OGmd+zYMdCvX7+wob7Tp08feO655wKrV68ODBo0KOrtOLQMDe29YsWKQKtWrbgdRwo818eOHXO3WilcuLAbAnr79u3Bx9GjR5NsP1O7hHhPR2JU1ZR5nnW7FT03fvz4wLp16wIvvfSSu03Dd999lyT7iIQ5z/Xr13cjq+p2HBs2bHBD+cfExAReeeWVJNlHnP151v9jf/nlF/coWLCgu2WDftb7Nq7LRMo4z126dHG3wJs3b17Y57DDhw8HkiOCYwqgDwe654vuLaOhgn/44Yew/8HccccdYfO/++67gTJlyrj59T+fzz77LGy6bsnx+OOPB/Lnz+/eIA0bNgysXbs20fYHiXOudf8vfXcU7aEPJEg57+lIBMeUe54nTJgQKFWqlAsSumen7seLlHWe9aGyU6dO7jYAOs9ly5YNjBw50v2/GxfGeY7t/7+aL67LRMo4zxbL5zB9IZQcpdF/krrqCQAAAABIvujjCAAAAADwRXAEAAAAAPgiOAIAAAAAfBEcAQAAAAC+CI4AAAAAAF8ERwAAAACAL4IjAAAAAMAXwREAAAAA4IvgCABIEvPmzbM0adLY3r17k3pTUq2kPAeHDx+21q1bW/bs2VPUdbBp0ya3P8uWLUvqTbkgderUyW644Yak3gwAURAcASCRPgzpw6QeGTJksPz581vjxo1t4sSJdurUKUuN6tata9u3b7ccOXKc94d075ErVy6rX7++fffdd6fN+88//1jPnj2tWLFiljFjRitUqJDdeeedtmXLltPm3bFjhz3wwANWsmRJy5QpkxUpUsRatmxpc+bMidN2lStXzr1Oy4lUvHhxe/755097/oknnrDLLrssXrcjOZsyZYo7TwsXLjzv6yDUNddc485zUtE50v5UqlTJUgvCHpA6EBwBIJE0bdrUfaBU2Pniiy+sQYMG9uCDD1qLFi3sxIkTCbbeY8eOWXKk8FagQAEX+M7X119/7Y7t/PnzXSDUMd25c2dYaLziiivcfK+++qr98ccfNn36dPfv5Zdfbhs2bAjOq/NTo0YN++abb+zZZ5+1X3/91b788kt3vrp163bGbfn+++/tv//+s5tvvtmFo3N1vtuR3K1fv97Kly/vAlZ8XQfJ4X2TLl06tz/p06e35OLkyZOp9gsqAPEoAABIcHfccUegVatWpz0/Z86cgP4Uv/baa8Hn/v3338Bdd90VyJMnTyBbtmyBBg0aBJYtWxb2uk8++SRQs2bNQKZMmQK5c+cO3HDDDcFpxYoVCwwZMiTQsWNH93qtW7777rvAlVdeGYiJiQkULlw48MADDwQOHjwYfN3UqVMDNWrUCGTNmjWQP3/+QLt27QI7d+4MTv/nn38Ct912m9suLaNUqVKBiRMnBqdv2bIl0KZNm0COHDkCF198ceD6668PbNy4MdZjMnfuXLfv2l+ZNGmSe+2XX34ZKFeuXCBLliyBJk2aBLZt2xbrMrR8LeOXX34JPrdixQr33Mcffxx87v7773fL2759e9jrDx8+HLjkkksCTZs2DT7XrFkz91zosQk9N2fSqVOnQL9+/QJffPFFoEyZMqdN1/kZPXr0ac8PGjQoULVq1fPajl9//TWQJk2awK5du9zve/bscb/fcsstwXmefPLJQL169cLOwddff+3OfebMmQN16tQJrFmzJmy5M2bMCFSrVs1dbyVKlAg88cQTgePHjwene9ewrkMtQ9dG6PGPVL9+ffca76Hf5ciRI4E+ffoEChUqFLjooosCtWrVctvo+fvvvwO33nqrm671VKpUKfDWW28Fp+taD12uHrpGvGsr1EcffeSmRx5/7Ufx4sXdcYvr+9HvmjzT+ybasenWrZt7ZM+e3b2/BwwYEDh16lRwnjMdJ29/dQ7Kly8fSJcundsuXXs6//rboPdD0aJF3Ty6XvR+1XOVK1cOLFmy5LTjEkrXr5blTY885t62nOlvwokTJwK9evVy03PlyhV4+OGHA7fffnvUv5UAkh4VRwBIQv/73/+satWq9uGHHwafa9Omje3atctVJX/++WerXr26NWzY0FXN5LPPPrMbb7zRmjdvbr/88otrtlirVq2w5T733HNuuZr++OOPu+qOKp7qU7ZixQp75513XGWse/fuwdccP37cnnzySVu+fLnNmDHDVbzUBM2j5axatcpt1+rVq23s2LGWJ0+e4GubNGli2bJlc80PFyxYYFmzZnXrPJvKjfq9advfeOMNVz1UM9KHHnoozq9XpW/q1KnBiqao0qLqYvv27V0lKFTmzJmta9euNmvWLHd89VBVTxW9LFmynLb8nDlz+q7/wIED9t5771mHDh1cU+R9+/ZFbTZ7Jue6HRUrVrTcuXPbt99+637XukN/F/2s5pyhHnvsMRs5cqT99NNPrlKmJrweLeP222931XGd/3HjxtnkyZNt6NChYcsYPHiwtW3b1l1fujZ1vL1rNpKu93vuucfq1KnjKsXe9a/rcdGiRe58aTl6L+gaWrdunZt+5MgRV4XVe2DlypV27733WseOHW3x4sVu+gsvvOCWqWVruXqo6WhcqQL9wQcfuO3x+iie6f14Jn7vm9ioUq3zoP3SPo0aNcpef/314PQzHSfvvTRixAj3ut9++83y5cvnnh89erTVq1fP/W247rrr3PHT+dU1u3TpUrv00kvd7//3fcCZ6f2p8+61qNBDzdDj8jdB15yuJTXZ198jHdOPPvooTusFkASSOrkCQGquOIqqQaoKeFVBVRlUUQh16aWXBsaNG+d+VkWoffv2sa5LlYDQCqSoYnLvvfeGPad1pU2bNvDff/9FXY6qDvrfxIEDB9zvLVu2DHTu3DnqvG+88UagbNmyYVWRo0ePuqrQrFmz4lxx1O9//PFHcJ4xY8a46ueZqjtaj6olqhLpd1XPjh075ubZsWOHey5alU8+/PBDN/3HH390D/2s587F+PHjA5dddlnw9wcffDBY8T2biuP5bMdNN93kqlXSs2dPV8VRtWf16tXumKhCNXv27NMqjp7PPvvMPeddFw0bNgwMGzbstPNdsGDB4O+aX1Uxj6qkek5V19jo2HiVRtm8ebOrjP31119h82n9/fv3j3U51113nau+ebRMLTtUXCuOGTJkCFZr4/p+PFPF0e99E422X38PQt9Lffv2Df6NiMtx8t5LkZVRXXsdOnQI/q4KvOZ7/PHHg88tWrTIPedV589UcYzt71tc/iboGnrmmWeC01XFVmsIKo5A8pR8GuADQCqlz91e/y5V+w4ePOiqRJGVNFUNRZUQVVT81KxZM+x3LVeViWnTpoWtV9W4jRs3ur5mqqZogBbN+++//wb7RKnqV6FCBevSpYurWKoqce2117rBMFRZ8Javao2qC6FUIfK2Oy4uuugiV/HwFCxY0FV7zkQVVA1IoyrUI4884qoYGoQoVFwqKHGtstx///325ptvBn/XORNVTlS58ehnDdbz0ksvnXZs4mM7otH6xo8fH6wuDhs2zH7//Xc3gqoqOqoEqeIUqkqVKmHHXHTcixYt6s6tqkWhFUb1mdO5VVVL5yxyGaqSarTUuJw7j/pwarllypQJe/7o0aPB94Oma3/effdd++uvv1zlStO9bThfGjgpb968wd/j8n48E7/3TWzUHze0z6eqqKrOaf/jcpy8invoOfGEPqdBuqRy5cqnPadzF1mhPxtn+pugaryqk7Vr1w5OU5VVf7vO5/oHkHAIjgCQxNR8rUSJEu5nfUjVB3d9yI+teaKaV55JZPNGLfe+++6zHj16nDavwsGhQ4dcszI9FC714VmBUb97zcqaNWtmmzdvts8//9y++uor11xPTSnVtFTLVxPC0GDqCf0gfiaRYU8fnuPyIVLNEUuXLu0eGmhITXkVIjUSqdavY6fjHI2e13pKlSoVXOeaNWt81zdkyJDTmtCqOeIPP/zgmhf27ds3+Lw+5KtJoRf2Faj0oTmSbkfhjSyq/YjLdviNKqpmi9qmK6+80i1H15S+ENAH88igFXrcvcDifXGgc6tmqDfddNNp64qJiYm6DG85ZzMgi9ajgWX0BYb+DaUmjqJBgtR0U6PSKuzoOte+nqk5dNq0aU+7jhSg4/K+OdP78Uz83jfnIi7Hyfs7EW3AoWjn2u/8x/XYRdvO+PibACD5IDgCQBLSiJmqIPTq1cv9rv5TugWDvnnXbRuiUcVA/Ro7d+4c5/VouQoRXjiKpG3Ys2ePPf3008E+YervFu0D3x133OEeV111lT388MPuA7CWr6qf+lEpGCUljWY6cOBAe+WVV9xx1Qdf9cHSB1gFvtAqiipHmk8BWbfyEP08ZswYF7Ijg4TCnQKD9tPrM+aZMGGCXX311e61oSZNmuSmecGxbNmy7kN/JFWkNE20LXHZjmgUqC6++GJ76qmn3O09FCYUJtXfTcExsn/jmejcrl27NtZrJ75Uq1bNhWxVunRtRaPKZ6tWrYJVXYUbVVNVEQ+ttGk5kdet+p/qCxLvWMblPotxeT/GRWzvm9j8+OOPYb/rCwl9maCgGJfjFJ+07ToGoS0jIo9dtGMel78JCuXaV71vRF/6eP1IASQ/DI4DAIlETcn0AUxN7BQS1OROH4J16wgNRiGNGjVyzdLUnG327NlugBrd506Dl3hBbtCgQfb222+7f1UtU+hTKPCjCpiWo0E19KFP1aiPP/44ODiOqo768Kcmlbo1xSeffOIGygmlMKbXqPmZBtuYOXOma+IqGghFA35ofzQQhpq/qkqj0PPnn39aYtKHW61XIVhNKUXHWoFRA9ZokJKtW7e6wXcUzlQ9CQ17+lkfgjXgkAZK0bHScX7xxRfduYlGy9CAPu3atXO3lwh93H333e7DsY6ZKMxqcBc1/dRyVRnV+dVgJxqA5ny2w9t/fRBXUPZCor5s0PWnLxzUlPVs6LxrwCFVHbUP2gZVUAcMGGDxSU0vdR3pvaDBaXQNqXo7fPhwd7xE4UlVO13L2g5V0UNvuyIKeDreeu/8/fffLlyqOaSqrI8++qhrJvnWW2+55sxnEpf345n4vW9io2p/7969XWDXe13vS+/aiMtxik+6hnbv3m3PPPOMO3a6LvUeijzmagqv7dUx1/shLn8TtE96n2owLlXFNVCVvhQBkEwldSdLAEgNQm8TkD59+kDevHkDjRo1csPynzx5Mmze/fv3u1tlaKh9DdZRpEgRNxiOhrb3fPDBB24QlowZM7ph/jUgypkGX1m8eHGgcePG7nYbGkimSpUqgaFDhwan67YGug2BbrmgAXh0y4/QQT40jL8G6NDgFho6XwNYbNiwIfh6DaahofS1PVpGyZIlA/fcc09g3759Z3U7Dr8BTOJyOw45dOiQGxBmxIgRwed2797tjquOp46rBt3RrTM02Egk3QJEA8zoWOoY67YYupVA6C0PQr3//vtuoCENxBONjptuO+DR4CC6JYa2UbdbuOaaawLffvvteW+HR+c/cnAanS9de95gR9HOgehYerex8OgWKXXr1nXnXoPF6PYPGgjIo/l1rkLpXOqcxnVwHNHgPQMHDnTXoc6RBk+58cYb3S1WvNuLaD90DefLl88NyBN5+4a1a9cGrrjiCretofuh7dOtMPR8ixYt3PZHux1HpLi8H/2uyTO9byLpmHTt2tXdQkbHWtfIo48+GjbIzJmOU7T3Umx/GyLPXbT31NixY91+6++Gjrf+boQOjqMBhby/LaG34zjT3wQNhqPrQPuZM2fOQO/evbkdB5CMuZsUJXV4BQAAwP9V+NTEWP04ASA5oakqAAAAAMAXwREAAAAA4IumqgAAAAAAX1QcAQAAAAC+CI4AAAAAAF8ERwAAAACAL4IjAAAAAMAXwREAAAAA4IvgCAAAAADwRXAEAAAAAPgiOAIAAAAAzM//B39A8qcja/0XAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize feature importance for the ensemble\n",
    "plot_ensemble_importance(modelo_ensamble_final, df.drop(columns=[\"HeartDisease\"]), df[\"HeartDisease\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aed1bc10",
   "metadata": {},
   "source": [
    "#### Run this code in terminal to try the model \n",
    "#####  -python -m streamlit run app.py "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f08181eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
