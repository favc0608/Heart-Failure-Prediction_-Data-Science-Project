{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d990593a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "78a59258",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.linear_model import LogisticRegression # Cambiado por clasificación\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.metrics import classification_report, roc_auc_score, confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import optuna\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e5f6a1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>ChestPainType</th>\n",
       "      <th>RestingBP</th>\n",
       "      <th>Cholesterol</th>\n",
       "      <th>FastingBS</th>\n",
       "      <th>RestingECG</th>\n",
       "      <th>MaxHR</th>\n",
       "      <th>ExerciseAngina</th>\n",
       "      <th>Oldpeak</th>\n",
       "      <th>ST_Slope</th>\n",
       "      <th>HeartDisease</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40</td>\n",
       "      <td>M</td>\n",
       "      <td>ATA</td>\n",
       "      <td>140</td>\n",
       "      <td>289</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>172</td>\n",
       "      <td>N</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Up</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>49</td>\n",
       "      <td>F</td>\n",
       "      <td>NAP</td>\n",
       "      <td>160</td>\n",
       "      <td>180</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>156</td>\n",
       "      <td>N</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Flat</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37</td>\n",
       "      <td>M</td>\n",
       "      <td>ATA</td>\n",
       "      <td>130</td>\n",
       "      <td>283</td>\n",
       "      <td>0</td>\n",
       "      <td>ST</td>\n",
       "      <td>98</td>\n",
       "      <td>N</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Up</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>48</td>\n",
       "      <td>F</td>\n",
       "      <td>ASY</td>\n",
       "      <td>138</td>\n",
       "      <td>214</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>108</td>\n",
       "      <td>Y</td>\n",
       "      <td>1.5</td>\n",
       "      <td>Flat</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>54</td>\n",
       "      <td>M</td>\n",
       "      <td>NAP</td>\n",
       "      <td>150</td>\n",
       "      <td>195</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>122</td>\n",
       "      <td>N</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Up</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age Sex ChestPainType  RestingBP  Cholesterol  FastingBS RestingECG  MaxHR  \\\n",
       "0   40   M           ATA        140          289          0     Normal    172   \n",
       "1   49   F           NAP        160          180          0     Normal    156   \n",
       "2   37   M           ATA        130          283          0         ST     98   \n",
       "3   48   F           ASY        138          214          0     Normal    108   \n",
       "4   54   M           NAP        150          195          0     Normal    122   \n",
       "\n",
       "  ExerciseAngina  Oldpeak ST_Slope  HeartDisease  \n",
       "0              N      0.0       Up             0  \n",
       "1              N      1.0     Flat             1  \n",
       "2              N      0.0       Up             0  \n",
       "3              Y      1.5     Flat             1  \n",
       "4              N      0.0       Up             0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ROOT = Path.cwd().parent\n",
    "path_raw = ROOT / \"data\" / \"processed\" / \"heart_clean.csv\"\n",
    "df = pd.read_csv(path_raw)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20103f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "root = Path.cwd().parent\n",
    "if str(root) not in sys.path:\n",
    "    sys.path.append(str(root))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc16797b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models import baseline\n",
    "from src.models import randomforest_basemodel\n",
    "from src.models import svc_basemodel\n",
    "from src.models import decisiontree_basemodel\n",
    "from src.models import xgboost_basemodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6d242a12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[98 13]\n",
      " [15 98]]\n",
      "Score in Training set: 0.8601532567049809\n",
      "Score in Test set: 0.875\n",
      "\n",
      "--- Informe de Clasificación (Test Set) ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.88      0.88       111\n",
      "           1       0.88      0.87      0.88       113\n",
      "\n",
      "    accuracy                           0.88       224\n",
      "   macro avg       0.88      0.88      0.88       224\n",
      "weighted avg       0.88      0.88      0.88       224\n",
      "\n",
      "ROC-AUC Score: 0.9380\n"
     ]
    }
   ],
   "source": [
    "from src.models import baseline\n",
    "# Just using a simple train test split and a baseline model as Logistic Regresion with default parameters\n",
    "baseline(df, \"HeartDisease\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "59ce634b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[67  4]\n",
      " [ 9 70]]\n",
      "Score in Training set: 1.0\n",
      "Score in Test set: 0.9133333333333333\n",
      "\n",
      "--- Informe de Clasificación (Test Set) ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.94      0.91        71\n",
      "           1       0.95      0.89      0.92        79\n",
      "\n",
      "    accuracy                           0.91       150\n",
      "   macro avg       0.91      0.91      0.91       150\n",
      "weighted avg       0.92      0.91      0.91       150\n",
      "\n",
      "ROC-AUC Score: 0.9583\n"
     ]
    }
   ],
   "source": [
    "randomforest_basemodel(df, \"HeartDisease\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cfbd663c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[66  5]\n",
      " [10 69]]\n",
      "Score in Training set: 0.9010067114093959\n",
      "Score in Test set: 0.9\n",
      "\n",
      "--- Informe de Clasificación (Test Set) ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.93      0.90        71\n",
      "           1       0.93      0.87      0.90        79\n",
      "\n",
      "    accuracy                           0.90       150\n",
      "   macro avg       0.90      0.90      0.90       150\n",
      "weighted avg       0.90      0.90      0.90       150\n",
      "\n",
      "ROC-AUC Score: 0.9551\n"
     ]
    }
   ],
   "source": [
    "svc_basemodel(df, \"HeartDisease\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "736080e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[64  7]\n",
      " [14 65]]\n",
      "Score in Training set: 1.0\n",
      "Score in Test set: 0.86\n",
      "\n",
      "--- Informe de Clasificación (Test Set) ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.90      0.86        71\n",
      "           1       0.90      0.82      0.86        79\n",
      "\n",
      "    accuracy                           0.86       150\n",
      "   macro avg       0.86      0.86      0.86       150\n",
      "weighted avg       0.86      0.86      0.86       150\n",
      "\n",
      "ROC-AUC Score: 0.8621\n"
     ]
    }
   ],
   "source": [
    "decisiontree_basemodel(df, \"HeartDisease\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a47bc2ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[67  4]\n",
      " [13 66]]\n",
      "Score in Training set: 1.0\n",
      "Score in Test set: 0.8866666666666667\n",
      "\n",
      "--- Informe de Clasificación (Test Set) ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.94      0.89        71\n",
      "           1       0.94      0.84      0.89        79\n",
      "\n",
      "    accuracy                           0.89       150\n",
      "   macro avg       0.89      0.89      0.89       150\n",
      "weighted avg       0.89      0.89      0.89       150\n",
      "\n",
      "ROC-AUC Score: 0.9472\n"
     ]
    }
   ],
   "source": [
    "xgboost_basemodel(df, \"HeartDisease\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3e81c35",
   "metadata": {},
   "source": [
    "### WE OBSERVED THAT THERE ARE THRE BASICS MODELS , CONSIDERING THAT THEY ARE CALCULATED EACH ONE DIFERENTLY, THERE IS NO CORRELATION .\n",
    "WE ARE GOING TO USE A OPTUNA SEARCH TO DETERMINE THE BEST HIPER PARAMETERES , THEN CALCULATED "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1d4566ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, cross_val_score # <--- Falta esta\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "6d7a0912",
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_regression_optuna(df,target):\n",
    "    X= df.drop(columns=[target])\n",
    "    y= df[target]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42, stratify=y)\n",
    "    col_num=X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "    col_cat=X.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "    preprocessor=  ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', StandardScaler(), col_num),\n",
    "            ('cat', OneHotEncoder(handle_unknown='ignore'), col_cat)\n",
    "        ])\n",
    "    \n",
    "    def objective(trial):\n",
    "        C= trial.suggest_float('C', 1e-5, 1e2, log=True)\n",
    "        solver = trial.suggest_categorical('solver', ['lbfgs', 'liblinear', 'saga'])\n",
    "        if solver == 'liblinear':\n",
    "            penalty = trial.suggest_categorical('penalty_lib', ['l1', 'l2'])\n",
    "        elif solver == 'saga':\n",
    "            penalty = trial.suggest_categorical('penalty_saga', ['l1', 'l2', 'elasticnet', None])\n",
    "        else: # lbfgs\n",
    "            penalty = trial.suggest_categorical('penalty_lbfgs', ['l2', None])\n",
    "        l1_ratio = None\n",
    "        if penalty == 'elasticnet':\n",
    "            l1_ratio = trial.suggest_float('l1_ratio', 0, 1)    \n",
    "        \n",
    "        model= LogisticRegression(\n",
    "            C=C,\n",
    "            solver=solver,\n",
    "            penalty=penalty,\n",
    "            l1_ratio=l1_ratio,\n",
    "            max_iter=1000,\n",
    "            random_state=42\n",
    "        )\n",
    "        pipe=Pipeline(steps=[('preprocessor', preprocessor), ('model', model)])\n",
    "        score = cross_val_score(pipe, X_train, y_train, cv=5, scoring='roc_auc').mean()\n",
    "        return score\n",
    "\n",
    "    study= optuna.create_study(direction='maximize')\n",
    "    study.optimize(lambda trial: objective(trial), n_trials=100)\n",
    "        \n",
    "\n",
    "    best_model= LogisticRegression(\n",
    "        C=study.best_params['C'],\n",
    "        solver=study.best_params['solver'],\n",
    "        penalty=study.best_params.get('penalty_lib') or study.best_params.get('penalty_saga') or study.best_params.get('penalty_lbfgs'),\n",
    "        l1_ratio=study.best_params.get('l1_ratio', None),\n",
    "        max_iter=1000,\n",
    "        random_state=42 \n",
    "    )\n",
    "    best_pipe= Pipeline(steps=[('preprocessor', preprocessor), ('model', best_model)])\n",
    "    best_pipe.fit(X_train, y_train)\n",
    "\n",
    "    y_pred= best_pipe.predict(X_test)\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    y_proba= best_pipe.predict_proba(X_test)[:, 1]\n",
    "    roc_auc= roc_auc_score(y_test, y_proba)\n",
    "    print(f\"ROC-AUC Score: {roc_auc:.4f}\")\n",
    "\n",
    "    print(\"score in training\", best_pipe.score(X_train, y_train))\n",
    "    print(\"score in testing\", best_pipe.score(X_test, y_test))\n",
    "    \n",
    "    return study.best_params\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7b39bf49",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-23 17:38:52,977] A new study created in memory with name: no-name-73543e27-2c46-4172-af71-6cb8e5dc5084\n",
      "C:\\Users\\APUESTAS\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\APUESTAS\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\APUESTAS\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\APUESTAS\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\APUESTAS\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "[I 2025-12-23 17:38:53,069] Trial 0 finished with value: 0.9246755521676697 and parameters: {'C': 0.5157537647310466, 'solver': 'lbfgs', 'penalty_lbfgs': None}. Best is trial 0 with value: 0.9246755521676697.\n",
      "C:\\Users\\APUESTAS\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\APUESTAS\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\APUESTAS\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\APUESTAS\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\APUESTAS\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "[I 2025-12-23 17:38:53,154] Trial 1 finished with value: 0.9247887383589543 and parameters: {'C': 0.928143464533077, 'solver': 'saga', 'penalty_saga': None}. Best is trial 1 with value: 0.9247887383589543.\n",
      "[I 2025-12-23 17:38:53,228] Trial 2 finished with value: 0.918302989937722 and parameters: {'C': 0.010248234363712264, 'solver': 'lbfgs', 'penalty_lbfgs': 'l2'}. Best is trial 1 with value: 0.9247887383589543.\n",
      "[I 2025-12-23 17:38:53,330] Trial 3 finished with value: 0.928420994883522 and parameters: {'C': 0.19960040691713093, 'solver': 'lbfgs', 'penalty_lbfgs': 'l2'}. Best is trial 3 with value: 0.928420994883522.\n",
      "[I 2025-12-23 17:38:53,618] Trial 4 finished with value: 0.924903015346867 and parameters: {'C': 8.063867165793846, 'solver': 'saga', 'penalty_saga': 'l2'}. Best is trial 3 with value: 0.928420994883522.\n",
      "C:\\Users\\APUESTAS\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\APUESTAS\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\APUESTAS\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\APUESTAS\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\APUESTAS\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "[I 2025-12-23 17:38:53,726] Trial 5 finished with value: 0.9246755521676697 and parameters: {'C': 0.4104232762234959, 'solver': 'lbfgs', 'penalty_lbfgs': None}. Best is trial 3 with value: 0.928420994883522.\n",
      "[I 2025-12-23 17:38:53,811] Trial 6 finished with value: 0.9251328846950967 and parameters: {'C': 4.129797118485159, 'solver': 'liblinear', 'penalty_lib': 'l1'}. Best is trial 3 with value: 0.928420994883522.\n",
      "[I 2025-12-23 17:38:53,903] Trial 7 finished with value: 0.9247887383589543 and parameters: {'C': 93.50443079766465, 'solver': 'saga', 'penalty_saga': 'l2'}. Best is trial 3 with value: 0.928420994883522.\n",
      "[I 2025-12-23 17:38:53,976] Trial 8 finished with value: 0.8973622612599087 and parameters: {'C': 1.5771562329209044e-05, 'solver': 'liblinear', 'penalty_lib': 'l2'}. Best is trial 3 with value: 0.928420994883522.\n",
      "[I 2025-12-23 17:38:54,051] Trial 9 finished with value: 0.9248474168010914 and parameters: {'C': 5.713000809663858, 'solver': 'liblinear', 'penalty_lib': 'l2'}. Best is trial 3 with value: 0.928420994883522.\n",
      "[I 2025-12-23 17:38:54,128] Trial 10 finished with value: 0.9096181634321339 and parameters: {'C': 0.003460704752754547, 'solver': 'lbfgs', 'penalty_lbfgs': 'l2'}. Best is trial 3 with value: 0.928420994883522.\n",
      "[I 2025-12-23 17:38:54,198] Trial 11 finished with value: 0.9114340510775145 and parameters: {'C': 0.05283756996961745, 'solver': 'liblinear', 'penalty_lib': 'l1'}. Best is trial 3 with value: 0.928420994883522.\n",
      "[I 2025-12-23 17:38:54,268] Trial 12 finished with value: 0.5 and parameters: {'C': 0.0003361047100519771, 'solver': 'liblinear', 'penalty_lib': 'l1'}. Best is trial 3 with value: 0.928420994883522.\n",
      "[I 2025-12-23 17:38:54,364] Trial 13 finished with value: 0.9249028228533442 and parameters: {'C': 18.994424687072893, 'solver': 'liblinear', 'penalty_lib': 'l1'}. Best is trial 3 with value: 0.928420994883522.\n",
      "[I 2025-12-23 17:38:54,453] Trial 14 finished with value: 0.9235375946266074 and parameters: {'C': 0.02918553462472066, 'solver': 'lbfgs', 'penalty_lbfgs': 'l2'}. Best is trial 3 with value: 0.928420994883522.\n",
      "[I 2025-12-23 17:38:54,553] Trial 15 finished with value: 0.9285342773215681 and parameters: {'C': 0.18865163972987647, 'solver': 'lbfgs', 'penalty_lbfgs': 'l2'}. Best is trial 15 with value: 0.9285342773215681.\n",
      "[I 2025-12-23 17:38:54,649] Trial 16 finished with value: 0.9276325734972352 and parameters: {'C': 0.12033257008215872, 'solver': 'lbfgs', 'penalty_lbfgs': 'l2'}. Best is trial 15 with value: 0.9285342773215681.\n",
      "[I 2025-12-23 17:38:54,728] Trial 17 finished with value: 0.9031790946901304 and parameters: {'C': 0.0011504727550775066, 'solver': 'lbfgs', 'penalty_lbfgs': 'l2'}. Best is trial 15 with value: 0.9285342773215681.\n",
      "[I 2025-12-23 17:38:54,803] Trial 18 finished with value: 0.8984379150641582 and parameters: {'C': 5.586935983648337e-05, 'solver': 'lbfgs', 'penalty_lbfgs': 'l2'}. Best is trial 15 with value: 0.9285342773215681.\n",
      "[I 2025-12-23 17:38:54,920] Trial 19 finished with value: 0.9288155424403302 and parameters: {'C': 0.17332638111966156, 'solver': 'lbfgs', 'penalty_lbfgs': 'l2'}. Best is trial 19 with value: 0.9288155424403302.\n",
      "C:\\Users\\APUESTAS\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\APUESTAS\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\APUESTAS\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\APUESTAS\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\APUESTAS\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "[I 2025-12-23 17:38:55,021] Trial 20 finished with value: 0.9246755521676697 and parameters: {'C': 0.008640220796631922, 'solver': 'lbfgs', 'penalty_lbfgs': None}. Best is trial 19 with value: 0.9288155424403302.\n",
      "[I 2025-12-23 17:38:55,114] Trial 21 finished with value: 0.9284776842259257 and parameters: {'C': 0.1931066516504457, 'solver': 'lbfgs', 'penalty_lbfgs': 'l2'}. Best is trial 19 with value: 0.9288155424403302.\n",
      "[I 2025-12-23 17:38:55,200] Trial 22 finished with value: 0.9254494723752547 and parameters: {'C': 0.041704063417445786, 'solver': 'lbfgs', 'penalty_lbfgs': 'l2'}. Best is trial 19 with value: 0.9288155424403302.\n",
      "[I 2025-12-23 17:38:55,287] Trial 23 finished with value: 0.9264371887219328 and parameters: {'C': 0.5458666532622277, 'solver': 'lbfgs', 'penalty_lbfgs': 'l2'}. Best is trial 19 with value: 0.9288155424403302.\n",
      "[I 2025-12-23 17:38:55,387] Trial 24 finished with value: 0.9247925240648985 and parameters: {'C': 2.652762510898838, 'solver': 'lbfgs', 'penalty_lbfgs': 'l2'}. Best is trial 19 with value: 0.9288155424403302.\n",
      "[I 2025-12-23 17:38:55,747] Trial 25 finished with value: 0.9251903760938445 and parameters: {'C': 1.8323609581652422, 'solver': 'saga', 'penalty_saga': 'elasticnet', 'l1_ratio': 0.4696603581392509}. Best is trial 19 with value: 0.9288155424403302.\n",
      "[I 2025-12-23 17:38:55,837] Trial 26 finished with value: 0.9271249359959037 and parameters: {'C': 0.11293506931390812, 'solver': 'lbfgs', 'penalty_lbfgs': 'l2'}. Best is trial 19 with value: 0.9288155424403302.\n",
      "[I 2025-12-23 17:38:55,918] Trial 27 finished with value: 0.9205592065160341 and parameters: {'C': 0.014240774387544971, 'solver': 'lbfgs', 'penalty_lbfgs': 'l2'}. Best is trial 19 with value: 0.9288155424403302.\n",
      "C:\\Users\\APUESTAS\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\APUESTAS\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\APUESTAS\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\APUESTAS\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\APUESTAS\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "[I 2025-12-23 17:38:56,003] Trial 28 finished with value: 0.9246755521676697 and parameters: {'C': 0.002270471458013818, 'solver': 'lbfgs', 'penalty_lbfgs': None}. Best is trial 19 with value: 0.9288155424403302.\n",
      "[I 2025-12-23 17:38:56,097] Trial 29 finished with value: 0.9283652038442239 and parameters: {'C': 0.22399284265217512, 'solver': 'lbfgs', 'penalty_lbfgs': 'l2'}. Best is trial 19 with value: 0.9288155424403302.\n",
      "[I 2025-12-23 17:38:56,238] Trial 30 finished with value: 0.9264383116008146 and parameters: {'C': 1.2077726446758714, 'solver': 'saga', 'penalty_saga': 'l1'}. Best is trial 19 with value: 0.9288155424403302.\n",
      "[I 2025-12-23 17:38:56,328] Trial 31 finished with value: 0.9285907741704491 and parameters: {'C': 0.20455628496998587, 'solver': 'lbfgs', 'penalty_lbfgs': 'l2'}. Best is trial 19 with value: 0.9288155424403302.\n",
      "[I 2025-12-23 17:38:56,421] Trial 32 finished with value: 0.9266628552949193 and parameters: {'C': 0.5164967985921153, 'solver': 'lbfgs', 'penalty_lbfgs': 'l2'}. Best is trial 19 with value: 0.9288155424403302.\n",
      "[I 2025-12-23 17:38:56,503] Trial 33 finished with value: 0.9258891596631106 and parameters: {'C': 0.06353670047046545, 'solver': 'lbfgs', 'penalty_lbfgs': 'l2'}. Best is trial 19 with value: 0.9288155424403302.\n",
      "[I 2025-12-23 17:38:56,586] Trial 34 finished with value: 0.9223039998870706 and parameters: {'C': 0.019335576466961258, 'solver': 'lbfgs', 'penalty_lbfgs': 'l2'}. Best is trial 19 with value: 0.9288155424403302.\n",
      "[I 2025-12-23 17:38:56,671] Trial 35 finished with value: 0.9280239449109203 and parameters: {'C': 0.13883973861042292, 'solver': 'lbfgs', 'penalty_lbfgs': 'l2'}. Best is trial 19 with value: 0.9288155424403302.\n",
      "[I 2025-12-23 17:38:56,764] Trial 36 finished with value: 0.924903015346867 and parameters: {'C': 15.276922271392584, 'solver': 'lbfgs', 'penalty_lbfgs': 'l2'}. Best is trial 19 with value: 0.9288155424403302.\n",
      "C:\\Users\\APUESTAS\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\APUESTAS\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\APUESTAS\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\APUESTAS\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\APUESTAS\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "[I 2025-12-23 17:38:56,850] Trial 37 finished with value: 0.9247887383589543 and parameters: {'C': 0.4047075232675713, 'solver': 'saga', 'penalty_saga': None}. Best is trial 19 with value: 0.9288155424403302.\n",
      "[I 2025-12-23 17:38:56,943] Trial 38 finished with value: 0.9256992006385651 and parameters: {'C': 0.8788216946281016, 'solver': 'lbfgs', 'penalty_lbfgs': 'l2'}. Best is trial 19 with value: 0.9288155424403302.\n",
      "C:\\Users\\APUESTAS\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\APUESTAS\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\APUESTAS\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\APUESTAS\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\APUESTAS\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "[I 2025-12-23 17:38:57,031] Trial 39 finished with value: 0.9246755521676697 and parameters: {'C': 0.23030729446084786, 'solver': 'lbfgs', 'penalty_lbfgs': None}. Best is trial 19 with value: 0.9288155424403302.\n",
      "[I 2025-12-23 17:38:57,105] Trial 40 finished with value: 0.5 and parameters: {'C': 0.007356707443247263, 'solver': 'saga', 'penalty_saga': 'elasticnet', 'l1_ratio': 0.9891138883512285}. Best is trial 19 with value: 0.9288155424403302.\n",
      "[I 2025-12-23 17:38:57,200] Trial 41 finished with value: 0.9281369386086824 and parameters: {'C': 0.24592962624925388, 'solver': 'lbfgs', 'penalty_lbfgs': 'l2'}. Best is trial 19 with value: 0.9288155424403302.\n",
      "[I 2025-12-23 17:38:57,286] Trial 42 finished with value: 0.9270155355105633 and parameters: {'C': 0.10423416793518454, 'solver': 'lbfgs', 'penalty_lbfgs': 'l2'}. Best is trial 19 with value: 0.9288155424403302.\n",
      "[I 2025-12-23 17:38:57,380] Trial 43 finished with value: 0.9256425112961615 and parameters: {'C': 0.9199739700795095, 'solver': 'lbfgs', 'penalty_lbfgs': 'l2'}. Best is trial 19 with value: 0.9288155424403302.\n",
      "[I 2025-12-23 17:38:57,464] Trial 44 finished with value: 0.9257256684979216 and parameters: {'C': 0.055706204257456086, 'solver': 'lbfgs', 'penalty_lbfgs': 'l2'}. Best is trial 19 with value: 0.9288155424403302.\n",
      "[I 2025-12-23 17:38:57,528] Trial 45 finished with value: 0.9247925240648985 and parameters: {'C': 3.475833726480393, 'solver': 'liblinear', 'penalty_lib': 'l2'}. Best is trial 19 with value: 0.9288155424403302.\n",
      "[I 2025-12-23 17:38:57,618] Trial 46 finished with value: 0.9225289927327278 and parameters: {'C': 0.02409197220998369, 'solver': 'lbfgs', 'penalty_lbfgs': 'l2'}. Best is trial 19 with value: 0.9288155424403302.\n",
      "C:\\Users\\APUESTAS\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\APUESTAS\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\APUESTAS\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\APUESTAS\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\APUESTAS\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "[I 2025-12-23 17:38:57,703] Trial 47 finished with value: 0.9246755521676697 and parameters: {'C': 0.3426372771470798, 'solver': 'lbfgs', 'penalty_lbfgs': None}. Best is trial 19 with value: 0.9288155424403302.\n",
      "[I 2025-12-23 17:38:57,774] Trial 48 finished with value: 0.9247887383589543 and parameters: {'C': 50.7242196157352, 'solver': 'liblinear', 'penalty_lib': 'l2'}. Best is trial 19 with value: 0.9288155424403302.\n",
      "[I 2025-12-23 17:38:57,864] Trial 49 finished with value: 0.9249587101394038 and parameters: {'C': 10.748573495619576, 'solver': 'lbfgs', 'penalty_lbfgs': 'l2'}. Best is trial 19 with value: 0.9288155424403302.\n",
      "[I 2025-12-23 17:38:57,953] Trial 50 finished with value: 0.9271827161349353 and parameters: {'C': 0.10644492774600532, 'solver': 'lbfgs', 'penalty_lbfgs': 'l2'}. Best is trial 19 with value: 0.9288155424403302.\n",
      "[I 2025-12-23 17:38:58,038] Trial 51 finished with value: 0.9284775879791646 and parameters: {'C': 0.18513183298480201, 'solver': 'lbfgs', 'penalty_lbfgs': 'l2'}. Best is trial 19 with value: 0.9288155424403302.\n",
      "[I 2025-12-23 17:38:58,137] Trial 52 finished with value: 0.925131184335647 and parameters: {'C': 1.7605478296142194, 'solver': 'lbfgs', 'penalty_lbfgs': 'l2'}. Best is trial 19 with value: 0.9288155424403302.\n",
      "[I 2025-12-23 17:38:58,230] Trial 53 finished with value: 0.9260390479527031 and parameters: {'C': 0.6909923975520289, 'solver': 'lbfgs', 'penalty_lbfgs': 'l2'}. Best is trial 19 with value: 0.9288155424403302.\n",
      "[I 2025-12-23 17:38:58,314] Trial 54 finished with value: 0.9258899617194547 and parameters: {'C': 0.062283199905191336, 'solver': 'lbfgs', 'penalty_lbfgs': 'l2'}. Best is trial 19 with value: 0.9288155424403302.\n",
      "[I 2025-12-23 17:38:58,403] Trial 55 finished with value: 0.9285342773215681 and parameters: {'C': 0.15894429775919533, 'solver': 'lbfgs', 'penalty_lbfgs': 'l2'}. Best is trial 19 with value: 0.9288155424403302.\n",
      "[I 2025-12-23 17:38:58,490] Trial 56 finished with value: 0.9240433392749667 and parameters: {'C': 0.03150307282494792, 'solver': 'lbfgs', 'penalty_lbfgs': 'l2'}. Best is trial 19 with value: 0.9288155424403302.\n",
      "[I 2025-12-23 17:38:58,614] Trial 57 finished with value: 0.9269098565666599 and parameters: {'C': 0.15814701002160644, 'solver': 'saga', 'penalty_saga': 'l1'}. Best is trial 19 with value: 0.9288155424403302.\n",
      "[I 2025-12-23 17:38:58,678] Trial 58 finished with value: 0.5 and parameters: {'C': 0.005516194601244737, 'solver': 'liblinear', 'penalty_lib': 'l1'}. Best is trial 19 with value: 0.9288155424403302.\n",
      "[I 2025-12-23 17:38:58,773] Trial 59 finished with value: 0.9273392775333109 and parameters: {'C': 0.36087995365221687, 'solver': 'lbfgs', 'penalty_lbfgs': 'l2'}. Best is trial 19 with value: 0.9288155424403302.\n",
      "C:\\Users\\APUESTAS\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\APUESTAS\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\APUESTAS\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\APUESTAS\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\APUESTAS\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "[I 2025-12-23 17:38:58,864] Trial 60 finished with value: 0.9246755521676697 and parameters: {'C': 5.512499990221383, 'solver': 'lbfgs', 'penalty_lbfgs': None}. Best is trial 19 with value: 0.9288155424403302.\n",
      "[I 2025-12-23 17:38:58,950] Trial 61 finished with value: 0.9263966046709194 and parameters: {'C': 0.0867147865147753, 'solver': 'lbfgs', 'penalty_lbfgs': 'l2'}. Best is trial 19 with value: 0.9288155424403302.\n",
      "[I 2025-12-23 17:38:59,038] Trial 62 finished with value: 0.9285341810748069 and parameters: {'C': 0.2037812296435228, 'solver': 'lbfgs', 'penalty_lbfgs': 'l2'}. Best is trial 19 with value: 0.9288155424403302.\n",
      "[I 2025-12-23 17:38:59,130] Trial 63 finished with value: 0.9283653000909853 and parameters: {'C': 0.21960322524475917, 'solver': 'lbfgs', 'penalty_lbfgs': 'l2'}. Best is trial 19 with value: 0.9288155424403302.\n",
      "[I 2025-12-23 17:38:59,212] Trial 64 finished with value: 0.9248870383844917 and parameters: {'C': 0.03684672053759678, 'solver': 'lbfgs', 'penalty_lbfgs': 'l2'}. Best is trial 19 with value: 0.9288155424403302.\n",
      "[I 2025-12-23 17:38:59,300] Trial 65 finished with value: 0.9288721355359725 and parameters: {'C': 0.17172904759495494, 'solver': 'lbfgs', 'penalty_lbfgs': 'l2'}. Best is trial 65 with value: 0.9288721355359725.\n",
      "[I 2025-12-23 17:38:59,378] Trial 66 finished with value: 0.9205592065160341 and parameters: {'C': 0.014339193169548065, 'solver': 'lbfgs', 'penalty_lbfgs': 'l2'}. Best is trial 65 with value: 0.9288721355359725.\n",
      "[I 2025-12-23 17:38:59,478] Trial 67 finished with value: 0.9249614050487202 and parameters: {'C': 2.0965315197989773, 'solver': 'lbfgs', 'penalty_lbfgs': 'l2'}. Best is trial 65 with value: 0.9288721355359725.\n",
      "[I 2025-12-23 17:38:59,574] Trial 68 finished with value: 0.9254152406104869 and parameters: {'C': 1.1487598781976116, 'solver': 'lbfgs', 'penalty_lbfgs': 'l2'}. Best is trial 65 with value: 0.9288721355359725.\n",
      "[I 2025-12-23 17:38:59,670] Trial 69 finished with value: 0.9266061659525157 and parameters: {'C': 0.5045171434562796, 'solver': 'lbfgs', 'penalty_lbfgs': 'l2'}. Best is trial 65 with value: 0.9288721355359725.\n",
      "[I 2025-12-23 17:38:59,778] Trial 70 finished with value: 0.9186967675204395 and parameters: {'C': 0.06603563923995996, 'solver': 'saga', 'penalty_saga': 'l1'}. Best is trial 65 with value: 0.9288721355359725.\n",
      "[I 2025-12-23 17:38:59,878] Trial 71 finished with value: 0.928589972114105 and parameters: {'C': 0.19115833717698572, 'solver': 'lbfgs', 'penalty_lbfgs': 'l2'}. Best is trial 65 with value: 0.9288721355359725.\n",
      "[I 2025-12-23 17:38:59,971] Trial 72 finished with value: 0.9275083510106551 and parameters: {'C': 0.3341107255343021, 'solver': 'lbfgs', 'penalty_lbfgs': 'l2'}. Best is trial 65 with value: 0.9288721355359725.\n",
      "[I 2025-12-23 17:39:00,064] Trial 73 finished with value: 0.927967351815278 and parameters: {'C': 0.1389749782704971, 'solver': 'lbfgs', 'penalty_lbfgs': 'l2'}. Best is trial 65 with value: 0.9288721355359725.\n",
      "[I 2025-12-23 17:39:00,164] Trial 74 finished with value: 0.9262089234863915 and parameters: {'C': 0.6358349099981174, 'solver': 'lbfgs', 'penalty_lbfgs': 'l2'}. Best is trial 65 with value: 0.9288721355359725.\n",
      "[I 2025-12-23 17:39:00,254] Trial 75 finished with value: 0.9278498986842425 and parameters: {'C': 0.29062248324598444, 'solver': 'lbfgs', 'penalty_lbfgs': 'l2'}. Best is trial 65 with value: 0.9288721355359725.\n",
      "C:\\Users\\APUESTAS\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\APUESTAS\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\APUESTAS\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\APUESTAS\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\APUESTAS\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "[I 2025-12-23 17:39:00,342] Trial 76 finished with value: 0.9246755521676697 and parameters: {'C': 0.04836289649553922, 'solver': 'lbfgs', 'penalty_lbfgs': None}. Best is trial 65 with value: 0.9288721355359725.\n",
      "[I 2025-12-23 17:39:00,412] Trial 77 finished with value: 0.926111553846213 and parameters: {'C': 0.0903095843139134, 'solver': 'liblinear', 'penalty_lib': 'l2'}. Best is trial 65 with value: 0.9288721355359725.\n",
      "[I 2025-12-23 17:39:00,508] Trial 78 finished with value: 0.9253009636225741 and parameters: {'C': 1.3907361037566421, 'solver': 'lbfgs', 'penalty_lbfgs': 'l2'}. Best is trial 65 with value: 0.9288721355359725.\n",
      "[I 2025-12-23 17:39:00,578] Trial 79 finished with value: 0.898833168430549 and parameters: {'C': 0.0001366043930048491, 'solver': 'lbfgs', 'penalty_lbfgs': 'l2'}. Best is trial 65 with value: 0.9288721355359725.\n",
      "[I 2025-12-23 17:39:00,671] Trial 80 finished with value: 0.9281372273489662 and parameters: {'C': 0.14370543688840592, 'solver': 'lbfgs', 'penalty_lbfgs': 'l2'}. Best is trial 65 with value: 0.9288721355359725.\n",
      "[I 2025-12-23 17:39:00,764] Trial 81 finished with value: 0.9283652038442239 and parameters: {'C': 0.22659831257720425, 'solver': 'lbfgs', 'penalty_lbfgs': 'l2'}. Best is trial 65 with value: 0.9288721355359725.\n",
      "[I 2025-12-23 17:39:00,853] Trial 82 finished with value: 0.9284785825290311 and parameters: {'C': 0.15607676317278768, 'solver': 'lbfgs', 'penalty_lbfgs': 'l2'}. Best is trial 65 with value: 0.9288721355359725.\n",
      "[I 2025-12-23 17:39:00,947] Trial 83 finished with value: 0.9260390479527031 and parameters: {'C': 0.7114256380814988, 'solver': 'lbfgs', 'penalty_lbfgs': 'l2'}. Best is trial 65 with value: 0.9288721355359725.\n",
      "[I 2025-12-23 17:39:01,037] Trial 84 finished with value: 0.9267193521438004 and parameters: {'C': 0.48908485255756884, 'solver': 'lbfgs', 'penalty_lbfgs': 'l2'}. Best is trial 65 with value: 0.9288721355359725.\n",
      "[I 2025-12-23 17:39:01,122] Trial 85 finished with value: 0.926225927080887 and parameters: {'C': 0.0740042657625564, 'solver': 'lbfgs', 'penalty_lbfgs': 'l2'}. Best is trial 65 with value: 0.9288721355359725.\n",
      "[I 2025-12-23 17:39:01,204] Trial 86 finished with value: 0.9221378138125651 and parameters: {'C': 0.018255517229534245, 'solver': 'lbfgs', 'penalty_lbfgs': 'l2'}. Best is trial 65 with value: 0.9288721355359725.\n",
      "[I 2025-12-23 17:39:01,321] Trial 87 finished with value: 0.9287589493446878 and parameters: {'C': 0.17069232401671444, 'solver': 'saga', 'penalty_saga': 'l2'}. Best is trial 65 with value: 0.9288721355359725.\n",
      "[I 2025-12-23 17:39:01,403] Trial 88 finished with value: 0.9249445297832395 and parameters: {'C': 0.03569786977509452, 'solver': 'saga', 'penalty_saga': 'l2'}. Best is trial 65 with value: 0.9288721355359725.\n",
      "[I 2025-12-23 17:39:01,512] Trial 89 finished with value: 0.9287597514010318 and parameters: {'C': 0.16601799201349202, 'solver': 'saga', 'penalty_saga': 'l2'}. Best is trial 65 with value: 0.9288721355359725.\n",
      "[I 2025-12-23 17:39:01,603] Trial 90 finished with value: 0.9269032476223842 and parameters: {'C': 0.09899066787234896, 'solver': 'saga', 'penalty_saga': 'l2'}. Best is trial 65 with value: 0.9288721355359725.\n",
      "[I 2025-12-23 17:39:01,721] Trial 91 finished with value: 0.9288155424403302 and parameters: {'C': 0.16884181646696128, 'solver': 'saga', 'penalty_saga': 'l2'}. Best is trial 65 with value: 0.9288721355359725.\n",
      "[I 2025-12-23 17:39:01,844] Trial 92 finished with value: 0.9277951984415724 and parameters: {'C': 0.26669329305035205, 'solver': 'saga', 'penalty_saga': 'l2'}. Best is trial 65 with value: 0.9288721355359725.\n",
      "[I 2025-12-23 17:39:01,976] Trial 93 finished with value: 0.9273384754769669 and parameters: {'C': 0.33730236804898084, 'solver': 'saga', 'penalty_saga': 'l2'}. Best is trial 65 with value: 0.9288721355359725.\n",
      "[I 2025-12-23 17:39:02,060] Trial 94 finished with value: 0.9263498608271832 and parameters: {'C': 0.048345968410602444, 'solver': 'saga', 'penalty_saga': 'l2'}. Best is trial 65 with value: 0.9288721355359725.\n",
      "[I 2025-12-23 17:39:02,171] Trial 95 finished with value: 0.9285332827717013 and parameters: {'C': 0.19248292011707796, 'solver': 'saga', 'penalty_saga': 'l2'}. Best is trial 65 with value: 0.9288721355359725.\n",
      "[I 2025-12-23 17:39:02,353] Trial 96 finished with value: 0.9256991043918038 and parameters: {'C': 0.9016421744121975, 'solver': 'saga', 'penalty_saga': 'l2'}. Best is trial 65 with value: 0.9288721355359725.\n",
      "[I 2025-12-23 17:39:02,438] Trial 97 finished with value: 0.8983256271759789 and parameters: {'C': 1.141494997280903e-05, 'solver': 'saga', 'penalty_saga': 'l2'}. Best is trial 65 with value: 0.9288721355359725.\n",
      "C:\\Users\\APUESTAS\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\APUESTAS\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\APUESTAS\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\APUESTAS\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\APUESTAS\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "[I 2025-12-23 17:39:02,528] Trial 98 finished with value: 0.9247887383589543 and parameters: {'C': 0.11555570741691863, 'solver': 'saga', 'penalty_saga': None}. Best is trial 65 with value: 0.9288721355359725.\n",
      "[I 2025-12-23 17:39:02,693] Trial 99 finished with value: 0.9273417799491048 and parameters: {'C': 0.4437404623586063, 'solver': 'saga', 'penalty_saga': 'elasticnet', 'l1_ratio': 0.12012266267302724}. Best is trial 65 with value: 0.9288721355359725.\n",
      "[I 2025-12-23 17:39:02,774] Trial 100 finished with value: 0.9228669471938936 and parameters: {'C': 0.025388502491816182, 'solver': 'saga', 'penalty_saga': 'l2'}. Best is trial 65 with value: 0.9288721355359725.\n",
      "[I 2025-12-23 17:39:02,888] Trial 101 finished with value: 0.9286457631534033 and parameters: {'C': 0.17947718282528027, 'solver': 'saga', 'penalty_saga': 'l2'}. Best is trial 65 with value: 0.9288721355359725.\n",
      "[I 2025-12-23 17:39:03,003] Trial 102 finished with value: 0.9285342773215681 and parameters: {'C': 0.1867308980574196, 'solver': 'saga', 'penalty_saga': 'l2'}. Best is trial 65 with value: 0.9288721355359725.\n",
      "[I 2025-12-23 17:39:03,094] Trial 103 finished with value: 0.926114441249052 and parameters: {'C': 0.0664811685228742, 'solver': 'saga', 'penalty_saga': 'l2'}. Best is trial 65 with value: 0.9288721355359725.\n",
      "[I 2025-12-23 17:39:03,197] Trial 104 finished with value: 0.9276861829432773 and parameters: {'C': 0.1286445985143197, 'solver': 'saga', 'penalty_saga': 'l2'}. Best is trial 65 with value: 0.9288721355359725.\n",
      "[I 2025-12-23 17:39:03,288] Trial 105 finished with value: 0.9263967009176808 and parameters: {'C': 0.08536551102935791, 'solver': 'saga', 'penalty_saga': 'l2'}. Best is trial 65 with value: 0.9288721355359725.\n",
      "[I 2025-12-23 17:39:03,421] Trial 106 finished with value: 0.9275083510106551 and parameters: {'C': 0.3224428749529101, 'solver': 'saga', 'penalty_saga': 'l2'}. Best is trial 65 with value: 0.9288721355359725.\n",
      "[I 2025-12-23 17:39:03,528] Trial 107 finished with value: 0.9287589493446878 and parameters: {'C': 0.17126606186044732, 'solver': 'saga', 'penalty_saga': 'l2'}. Best is trial 65 with value: 0.9288721355359725.\n",
      "[I 2025-12-23 17:39:03,688] Trial 108 finished with value: 0.9264361941720661 and parameters: {'C': 0.590542178383244, 'solver': 'saga', 'penalty_saga': 'l2'}. Best is trial 65 with value: 0.9288721355359725.\n",
      "C:\\Users\\APUESTAS\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\APUESTAS\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\APUESTAS\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\APUESTAS\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\APUESTAS\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "[I 2025-12-23 17:39:03,783] Trial 109 finished with value: 0.9247887383589543 and parameters: {'C': 0.2792882158335174, 'solver': 'saga', 'penalty_saga': None}. Best is trial 65 with value: 0.9288721355359725.\n",
      "[I 2025-12-23 17:39:03,864] Trial 110 finished with value: 0.9253927830328511 and parameters: {'C': 0.041359181801252934, 'solver': 'saga', 'penalty_saga': 'l2'}. Best is trial 65 with value: 0.9288721355359725.\n",
      "[I 2025-12-23 17:39:03,978] Trial 111 finished with value: 0.9286474635128528 and parameters: {'C': 0.16405140931864212, 'solver': 'saga', 'penalty_saga': 'l2'}. Best is trial 65 with value: 0.9288721355359725.\n",
      "[I 2025-12-23 17:39:04,093] Trial 112 finished with value: 0.9274079014741154 and parameters: {'C': 0.11646355640267528, 'solver': 'saga', 'penalty_saga': 'l2'}. Best is trial 65 with value: 0.9288721355359725.\n",
      "[I 2025-12-23 17:39:04,200] Trial 113 finished with value: 0.9284785825290311 and parameters: {'C': 0.15542031658473757, 'solver': 'saga', 'penalty_saga': 'l2'}. Best is trial 65 with value: 0.9288721355359725.\n",
      "[I 2025-12-23 17:39:04,364] Trial 114 finished with value: 0.9272825881909075 and parameters: {'C': 0.39562291482861744, 'solver': 'saga', 'penalty_saga': 'l2'}. Best is trial 65 with value: 0.9288721355359725.\n",
      "[I 2025-12-23 17:39:04,430] Trial 115 finished with value: 0.9280227578675311 and parameters: {'C': 0.2446734655163143, 'solver': 'liblinear', 'penalty_lib': 'l2'}. Best is trial 65 with value: 0.9288721355359725.\n",
      "[I 2025-12-23 17:39:04,528] Trial 116 finished with value: 0.9262825201765293 and parameters: {'C': 0.07654203927561114, 'solver': 'saga', 'penalty_saga': 'l2'}. Best is trial 65 with value: 0.9288721355359725.\n",
      "[I 2025-12-23 17:39:04,778] Trial 117 finished with value: 0.9126175012544161 and parameters: {'C': 0.0551598732918612, 'solver': 'saga', 'penalty_saga': 'elasticnet', 'l1_ratio': 0.9861958458885176}. Best is trial 65 with value: 0.9288721355359725.\n",
      "[I 2025-12-23 17:39:04,928] Trial 118 finished with value: 0.9271169154324623 and parameters: {'C': 0.8022505722157077, 'solver': 'saga', 'penalty_saga': 'l1'}. Best is trial 65 with value: 0.9288721355359725.\n",
      "[I 2025-12-23 17:39:05,038] Trial 119 finished with value: 0.9287023562490454 and parameters: {'C': 0.1728477721389381, 'solver': 'saga', 'penalty_saga': 'l2'}. Best is trial 65 with value: 0.9288721355359725.\n",
      "[I 2025-12-23 17:39:05,180] Trial 120 finished with value: 0.926662759048158 and parameters: {'C': 0.4866308609308973, 'solver': 'saga', 'penalty_saga': 'l2'}. Best is trial 65 with value: 0.9288721355359725.\n",
      "[I 2025-12-23 17:39:05,294] Trial 121 finished with value: 0.9285342773215681 and parameters: {'C': 0.16159040880598335, 'solver': 'saga', 'penalty_saga': 'l2'}. Best is trial 65 with value: 0.9288721355359725.\n",
      "[I 2025-12-23 17:39:05,394] Trial 122 finished with value: 0.9269598407180265 and parameters: {'C': 0.10276595584927455, 'solver': 'saga', 'penalty_saga': 'l2'}. Best is trial 65 with value: 0.9288721355359725.\n",
      "C:\\Users\\APUESTAS\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\APUESTAS\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\APUESTAS\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\APUESTAS\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\APUESTAS\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "[I 2025-12-23 17:39:05,478] Trial 123 finished with value: 0.9247887383589543 and parameters: {'C': 0.20598036178880583, 'solver': 'saga', 'penalty_saga': None}. Best is trial 65 with value: 0.9288721355359725.\n",
      "[I 2025-12-23 17:39:05,553] Trial 124 finished with value: 0.9292131057289922 and parameters: {'C': 0.28244894047657965, 'solver': 'liblinear', 'penalty_lib': 'l1'}. Best is trial 124 with value: 0.9292131057289922.\n",
      "[I 2025-12-23 17:39:05,621] Trial 125 finished with value: 0.926771389559408 and parameters: {'C': 1.2063852819964838, 'solver': 'liblinear', 'penalty_lib': 'l1'}. Best is trial 124 with value: 0.9292131057289922.\n",
      "[I 2025-12-23 17:39:05,697] Trial 126 finished with value: 0.9290998232909462 and parameters: {'C': 0.2976140148943066, 'solver': 'liblinear', 'penalty_lib': 'l1'}. Best is trial 124 with value: 0.9292131057289922.\n",
      "[I 2025-12-23 17:39:05,769] Trial 127 finished with value: 0.9287575698077759 and parameters: {'C': 0.3514304690441685, 'solver': 'liblinear', 'penalty_lib': 'l1'}. Best is trial 124 with value: 0.9292131057289922.\n",
      "[I 2025-12-23 17:39:05,838] Trial 128 finished with value: 0.9288141629034182 and parameters: {'C': 0.3509747975573924, 'solver': 'liblinear', 'penalty_lib': 'l1'}. Best is trial 124 with value: 0.9292131057289922.\n",
      "[I 2025-12-23 17:39:05,910] Trial 129 finished with value: 0.9286422982699964 and parameters: {'C': 0.3950397334396669, 'solver': 'liblinear', 'penalty_lib': 'l1'}. Best is trial 124 with value: 0.9292131057289922.\n",
      "[I 2025-12-23 17:39:05,981] Trial 130 finished with value: 0.9281277951663593 and parameters: {'C': 0.6181106931008784, 'solver': 'liblinear', 'penalty_lib': 'l1'}. Best is trial 124 with value: 0.9292131057289922.\n",
      "[I 2025-12-23 17:39:06,053] Trial 131 finished with value: 0.9290988287410794 and parameters: {'C': 0.2667341070578498, 'solver': 'liblinear', 'penalty_lib': 'l1'}. Best is trial 124 with value: 0.9292131057289922.\n",
      "[I 2025-12-23 17:39:06,121] Trial 132 finished with value: 0.9289855463030335 and parameters: {'C': 0.27246491332216566, 'solver': 'liblinear', 'penalty_lib': 'l1'}. Best is trial 124 with value: 0.9292131057289922.\n",
      "[I 2025-12-23 17:39:06,194] Trial 133 finished with value: 0.9292131057289922 and parameters: {'C': 0.2843665118635976, 'solver': 'liblinear', 'penalty_lib': 'l1'}. Best is trial 124 with value: 0.9292131057289922.\n",
      "[I 2025-12-23 17:39:06,264] Trial 134 finished with value: 0.9290998232909462 and parameters: {'C': 0.29814122994818254, 'solver': 'liblinear', 'penalty_lib': 'l1'}. Best is trial 124 with value: 0.9292131057289922.\n",
      "[I 2025-12-23 17:39:06,337] Trial 135 finished with value: 0.9286980893092949 and parameters: {'C': 0.3777369340186423, 'solver': 'liblinear', 'penalty_lib': 'l1'}. Best is trial 124 with value: 0.9292131057289922.\n",
      "[I 2025-12-23 17:39:06,410] Trial 136 finished with value: 0.9292688005215292 and parameters: {'C': 0.28717190508070944, 'solver': 'liblinear', 'penalty_lib': 'l1'}. Best is trial 136 with value: 0.9292688005215292.\n",
      "[I 2025-12-23 17:39:06,478] Trial 137 finished with value: 0.9292132019757535 and parameters: {'C': 0.252842923678465, 'solver': 'liblinear', 'penalty_lib': 'l1'}. Best is trial 136 with value: 0.9292688005215292.\n",
      "[I 2025-12-23 17:39:06,553] Trial 138 finished with value: 0.9290988287410794 and parameters: {'C': 0.2661759686899559, 'solver': 'liblinear', 'penalty_lib': 'l1'}. Best is trial 136 with value: 0.9292688005215292.\n",
      "[I 2025-12-23 17:39:06,621] Trial 139 finished with value: 0.9290431339485427 and parameters: {'C': 0.27521658116563474, 'solver': 'liblinear', 'penalty_lib': 'l1'}. Best is trial 136 with value: 0.9292688005215292.\n",
      "[I 2025-12-23 17:39:06,697] Trial 140 finished with value: 0.9258130926394326 and parameters: {'C': 1.5999051633664805, 'solver': 'liblinear', 'penalty_lib': 'l1'}. Best is trial 136 with value: 0.9292688005215292.\n",
      "[I 2025-12-23 17:39:06,769] Trial 141 finished with value: 0.9292131057289922 and parameters: {'C': 0.29203075918915067, 'solver': 'liblinear', 'penalty_lib': 'l1'}. Best is trial 136 with value: 0.9292688005215292.\n",
      "[I 2025-12-23 17:39:06,838] Trial 142 finished with value: 0.9292688005215292 and parameters: {'C': 0.2862592961127962, 'solver': 'liblinear', 'penalty_lib': 'l1'}. Best is trial 136 with value: 0.9292688005215292.\n",
      "[I 2025-12-23 17:39:06,909] Trial 143 finished with value: 0.9290422356454371 and parameters: {'C': 0.2675551284730847, 'solver': 'liblinear', 'penalty_lib': 'l1'}. Best is trial 136 with value: 0.9292688005215292.\n",
      "[I 2025-12-23 17:39:06,980] Trial 144 finished with value: 0.9281288859629873 and parameters: {'C': 0.5767453271872629, 'solver': 'liblinear', 'penalty_lib': 'l1'}. Best is trial 136 with value: 0.9292688005215292.\n",
      "[I 2025-12-23 17:39:07,052] Trial 145 finished with value: 0.9290422356454371 and parameters: {'C': 0.25739327117194616, 'solver': 'liblinear', 'penalty_lib': 'l1'}. Best is trial 136 with value: 0.9292688005215292.\n",
      "[I 2025-12-23 17:39:07,123] Trial 146 finished with value: 0.9272246155583531 and parameters: {'C': 0.8892889213177587, 'solver': 'liblinear', 'penalty_lib': 'l1'}. Best is trial 136 with value: 0.9292688005215292.\n",
      "[I 2025-12-23 17:39:07,193] Trial 147 finished with value: 0.9289856425497949 and parameters: {'C': 0.26941137755641864, 'solver': 'liblinear', 'penalty_lib': 'l1'}. Best is trial 136 with value: 0.9292688005215292.\n",
      "[I 2025-12-23 17:39:07,264] Trial 148 finished with value: 0.9287526933052035 and parameters: {'C': 0.4665464778257817, 'solver': 'liblinear', 'penalty_lib': 'l1'}. Best is trial 136 with value: 0.9292688005215292.\n",
      "[I 2025-12-23 17:39:07,328] Trial 149 finished with value: 0.9278457279912532 and parameters: {'C': 0.7319219041797096, 'solver': 'liblinear', 'penalty_lib': 'l1'}. Best is trial 136 with value: 0.9292688005215292.\n",
      "[I 2025-12-23 17:39:07,406] Trial 150 finished with value: 0.9289298515104967 and parameters: {'C': 0.27425713739550894, 'solver': 'liblinear', 'penalty_lib': 'l1'}. Best is trial 136 with value: 0.9292688005215292.\n",
      "[I 2025-12-23 17:39:07,477] Trial 151 finished with value: 0.9289856425497949 and parameters: {'C': 0.2680944148394935, 'solver': 'liblinear', 'penalty_lib': 'l1'}. Best is trial 136 with value: 0.9292688005215292.\n",
      "[I 2025-12-23 17:39:07,547] Trial 152 finished with value: 0.929155421836722 and parameters: {'C': 0.2625141499176755, 'solver': 'liblinear', 'penalty_lib': 'l1'}. Best is trial 136 with value: 0.9292688005215292.\n",
      "[I 2025-12-23 17:39:07,618] Trial 153 finished with value: 0.9290988287410796 and parameters: {'C': 0.2614575157637702, 'solver': 'liblinear', 'penalty_lib': 'l1'}. Best is trial 136 with value: 0.9292688005215292.\n",
      "[I 2025-12-23 17:39:07,688] Trial 154 finished with value: 0.9286951056596944 and parameters: {'C': 0.5195046516021682, 'solver': 'liblinear', 'penalty_lib': 'l1'}. Best is trial 136 with value: 0.9292688005215292.\n",
      "[I 2025-12-23 17:39:07,761] Trial 155 finished with value: 0.9293254898639327 and parameters: {'C': 0.25435175314966557, 'solver': 'liblinear', 'penalty_lib': 'l1'}. Best is trial 155 with value: 0.9293254898639327.\n",
      "[I 2025-12-23 17:39:07,830] Trial 156 finished with value: 0.9287545861581759 and parameters: {'C': 0.443300149416659, 'solver': 'liblinear', 'penalty_lib': 'l1'}. Best is trial 155 with value: 0.9293254898639327.\n",
      "[I 2025-12-23 17:39:07,903] Trial 157 finished with value: 0.9269414575866189 and parameters: {'C': 1.1723871544313196, 'solver': 'liblinear', 'penalty_lib': 'l1'}. Best is trial 155 with value: 0.9293254898639327.\n",
      "[I 2025-12-23 17:39:07,976] Trial 158 finished with value: 0.9280146089750746 and parameters: {'C': 0.6775712368301549, 'solver': 'liblinear', 'penalty_lib': 'l1'}. Best is trial 155 with value: 0.9293254898639327.\n",
      "[I 2025-12-23 17:39:08,047] Trial 159 finished with value: 0.929210410819676 and parameters: {'C': 0.3077896419118082, 'solver': 'liblinear', 'penalty_lib': 'l1'}. Best is trial 155 with value: 0.9293254898639327.\n",
      "[I 2025-12-23 17:39:08,114] Trial 160 finished with value: 0.9262326322719241 and parameters: {'C': 0.12036092301585172, 'solver': 'liblinear', 'penalty_lib': 'l1'}. Best is trial 155 with value: 0.9293254898639327.\n",
      "[I 2025-12-23 17:39:08,187] Trial 161 finished with value: 0.9292122074258866 and parameters: {'C': 0.24283502527519793, 'solver': 'liblinear', 'penalty_lib': 'l1'}. Best is trial 155 with value: 0.9293254898639327.\n",
      "[I 2025-12-23 17:39:08,257] Trial 162 finished with value: 0.9288130721067903 and parameters: {'C': 0.3365433643740625, 'solver': 'liblinear', 'penalty_lib': 'l1'}. Best is trial 155 with value: 0.9293254898639327.\n",
      "[I 2025-12-23 17:39:08,328] Trial 163 finished with value: 0.9286979930625335 and parameters: {'C': 0.4540131195893222, 'solver': 'liblinear', 'penalty_lib': 'l1'}. Best is trial 155 with value: 0.9293254898639327.\n",
      "[I 2025-12-23 17:39:08,399] Trial 164 finished with value: 0.9290435189355877 and parameters: {'C': 0.2262935750894606, 'solver': 'liblinear', 'penalty_lib': 'l1'}. Best is trial 155 with value: 0.9293254898639327.\n",
      "[I 2025-12-23 17:39:08,470] Trial 165 finished with value: 0.9290435189355877 and parameters: {'C': 0.23320956508842128, 'solver': 'liblinear', 'penalty_lib': 'l1'}. Best is trial 155 with value: 0.9293254898639327.\n",
      "[I 2025-12-23 17:39:08,538] Trial 166 finished with value: 0.9258932982738463 and parameters: {'C': 0.10165048049950746, 'solver': 'liblinear', 'penalty_lib': 'l1'}. Best is trial 155 with value: 0.9293254898639327.\n",
      "[I 2025-12-23 17:39:08,610] Trial 167 finished with value: 0.9281854790586298 and parameters: {'C': 0.566425301146004, 'solver': 'liblinear', 'penalty_lib': 'l1'}. Best is trial 155 with value: 0.9293254898639327.\n",
      "[I 2025-12-23 17:39:08,678] Trial 168 finished with value: 0.9290444172386934 and parameters: {'C': 0.2231851082207731, 'solver': 'liblinear', 'penalty_lib': 'l1'}. Best is trial 155 with value: 0.9293254898639327.\n",
      "[I 2025-12-23 17:39:08,752] Trial 169 finished with value: 0.9286422982699964 and parameters: {'C': 0.40171566068649606, 'solver': 'liblinear', 'penalty_lib': 'l1'}. Best is trial 155 with value: 0.9293254898639327.\n",
      "[I 2025-12-23 17:39:08,821] Trial 170 finished with value: 0.9276200614182667 and parameters: {'C': 0.7666906951558553, 'solver': 'liblinear', 'penalty_lib': 'l1'}. Best is trial 155 with value: 0.9293254898639327.\n",
      "[I 2025-12-23 17:39:08,894] Trial 171 finished with value: 0.9292132019757535 and parameters: {'C': 0.2547835704812155, 'solver': 'liblinear', 'penalty_lib': 'l1'}. Best is trial 155 with value: 0.9293254898639327.\n",
      "[I 2025-12-23 17:39:08,964] Trial 172 finished with value: 0.9262875250081167 and parameters: {'C': 0.1275116242043868, 'solver': 'liblinear', 'penalty_lib': 'l1'}. Best is trial 155 with value: 0.9293254898639327.\n",
      "[I 2025-12-23 17:39:09,038] Trial 173 finished with value: 0.9291018123906797 and parameters: {'C': 0.2166901933287016, 'solver': 'liblinear', 'penalty_lib': 'l1'}. Best is trial 155 with value: 0.9293254898639327.\n",
      "[I 2025-12-23 17:39:09,109] Trial 174 finished with value: 0.9288696652024326 and parameters: {'C': 0.3318629553252208, 'solver': 'liblinear', 'penalty_lib': 'l1'}. Best is trial 155 with value: 0.9293254898639327.\n",
      "[I 2025-12-23 17:39:09,180] Trial 175 finished with value: 0.9286422982699964 and parameters: {'C': 0.4011356068331998, 'solver': 'liblinear', 'penalty_lib': 'l1'}. Best is trial 155 with value: 0.9293254898639327.\n",
      "[I 2025-12-23 17:39:09,247] Trial 176 finished with value: 0.5 and parameters: {'C': 0.0010842966949753594, 'solver': 'liblinear', 'penalty_lib': 'l1'}. Best is trial 155 with value: 0.9293254898639327.\n",
      "[I 2025-12-23 17:39:09,319] Trial 177 finished with value: 0.9290444172386934 and parameters: {'C': 0.2237685313285718, 'solver': 'liblinear', 'penalty_lib': 'l1'}. Best is trial 155 with value: 0.9293254898639327.\n",
      "[I 2025-12-23 17:39:09,388] Trial 178 finished with value: 0.9262326322719241 and parameters: {'C': 0.12139733938767232, 'solver': 'liblinear', 'penalty_lib': 'l1'}. Best is trial 155 with value: 0.9293254898639327.\n",
      "[I 2025-12-23 17:39:09,458] Trial 179 finished with value: 0.9282411738511666 and parameters: {'C': 0.5810489014765328, 'solver': 'liblinear', 'penalty_lib': 'l1'}. Best is trial 155 with value: 0.9293254898639327.\n",
      "[I 2025-12-23 17:39:09,528] Trial 180 finished with value: 0.925192076453294 and parameters: {'C': 2.4513815692279053, 'solver': 'liblinear', 'penalty_lib': 'l1'}. Best is trial 155 with value: 0.9293254898639327.\n",
      "[I 2025-12-23 17:39:09,601] Trial 181 finished with value: 0.9291018123906797 and parameters: {'C': 0.21670377334201613, 'solver': 'liblinear', 'penalty_lib': 'l1'}. Best is trial 155 with value: 0.9293254898639327.\n",
      "[I 2025-12-23 17:39:09,671] Trial 182 finished with value: 0.9288696652024326 and parameters: {'C': 0.33218847746651536, 'solver': 'liblinear', 'penalty_lib': 'l1'}. Best is trial 155 with value: 0.9293254898639327.\n",
      "[I 2025-12-23 17:39:09,743] Trial 183 finished with value: 0.9281934354575636 and parameters: {'C': 0.2061953715973941, 'solver': 'liblinear', 'penalty_lib': 'l2'}. Best is trial 155 with value: 0.9293254898639327.\n",
      "[I 2025-12-23 17:39:09,812] Trial 184 finished with value: 0.9264564059919383 and parameters: {'C': 0.12992068273253507, 'solver': 'liblinear', 'penalty_lib': 'l1'}. Best is trial 155 with value: 0.9293254898639327.\n",
      "[I 2025-12-23 17:39:09,883] Trial 185 finished with value: 0.9291018123906797 and parameters: {'C': 0.2158846585778667, 'solver': 'liblinear', 'penalty_lib': 'l1'}. Best is trial 155 with value: 0.9293254898639327.\n",
      "[I 2025-12-23 17:39:09,955] Trial 186 finished with value: 0.9238656677536135 and parameters: {'C': 0.08642213825798524, 'solver': 'liblinear', 'penalty_lib': 'l1'}. Best is trial 155 with value: 0.9293254898639327.\n",
      "[I 2025-12-23 17:39:10,026] Trial 187 finished with value: 0.9291538177240335 and parameters: {'C': 0.3054733138305346, 'solver': 'liblinear', 'penalty_lib': 'l1'}. Best is trial 155 with value: 0.9293254898639327.\n",
      "[I 2025-12-23 17:39:10,097] Trial 188 finished with value: 0.9286979930625335 and parameters: {'C': 0.42486358658920614, 'solver': 'liblinear', 'penalty_lib': 'l1'}. Best is trial 155 with value: 0.9293254898639327.\n",
      "[I 2025-12-23 17:39:10,168] Trial 189 finished with value: 0.928699982162267 and parameters: {'C': 0.3576787307668911, 'solver': 'liblinear', 'penalty_lib': 'l1'}. Best is trial 155 with value: 0.9293254898639327.\n",
      "[I 2025-12-23 17:39:10,237] Trial 190 finished with value: 0.9271114293670685 and parameters: {'C': 0.9130330317016295, 'solver': 'liblinear', 'penalty_lib': 'l1'}. Best is trial 155 with value: 0.9293254898639327.\n",
      "[I 2025-12-23 17:39:10,310] Trial 191 finished with value: 0.9289298515104967 and parameters: {'C': 0.2745377012550097, 'solver': 'liblinear', 'penalty_lib': 'l1'}. Best is trial 155 with value: 0.9293254898639327.\n",
      "[I 2025-12-23 17:39:10,380] Trial 192 finished with value: 0.926848675708729 and parameters: {'C': 0.14187851073928295, 'solver': 'liblinear', 'penalty_lib': 'l1'}. Best is trial 155 with value: 0.9293254898639327.\n",
      "[I 2025-12-23 17:39:10,452] Trial 193 finished with value: 0.9281431304836593 and parameters: {'C': 0.19362282752509782, 'solver': 'liblinear', 'penalty_lib': 'l1'}. Best is trial 155 with value: 0.9293254898639327.\n",
      "[I 2025-12-23 17:39:10,521] Trial 194 finished with value: 0.9290406315327487 and parameters: {'C': 0.31935582184933164, 'solver': 'liblinear', 'penalty_lib': 'l1'}. Best is trial 155 with value: 0.9293254898639327.\n",
      "[I 2025-12-23 17:39:10,594] Trial 195 finished with value: 0.9288091901540845 and parameters: {'C': 0.4972413838804216, 'solver': 'liblinear', 'penalty_lib': 'l1'}. Best is trial 155 with value: 0.9293254898639327.\n",
      "[I 2025-12-23 17:39:10,664] Trial 196 finished with value: 0.9291585017330833 and parameters: {'C': 0.21795839145228188, 'solver': 'liblinear', 'penalty_lib': 'l1'}. Best is trial 155 with value: 0.9293254898639327.\n",
      "[I 2025-12-23 17:39:10,735] Trial 197 finished with value: 0.9289327389133355 and parameters: {'C': 0.212662034200388, 'solver': 'liblinear', 'penalty_lib': 'l1'}. Best is trial 155 with value: 0.9293254898639327.\n",
      "[I 2025-12-23 17:39:10,821] Trial 198 finished with value: 0.9268487719554903 and parameters: {'C': 0.14242776889218828, 'solver': 'liblinear', 'penalty_lib': 'l1'}. Best is trial 155 with value: 0.9293254898639327.\n",
      "[I 2025-12-23 17:39:10,910] Trial 199 finished with value: 0.9289829476404787 and parameters: {'C': 0.32681407632081383, 'solver': 'liblinear', 'penalty_lib': 'l1'}. Best is trial 155 with value: 0.9293254898639327.\n",
      "[I 2025-12-23 17:39:10,978] Trial 200 finished with value: 0.926491888964603 and parameters: {'C': 0.49827758915926834, 'solver': 'liblinear', 'penalty_lib': 'l2'}. Best is trial 155 with value: 0.9293254898639327.\n",
      "[I 2025-12-23 17:39:11,050] Trial 201 finished with value: 0.9292688005215292 and parameters: {'C': 0.24592214445104812, 'solver': 'liblinear', 'penalty_lib': 'l1'}. Best is trial 155 with value: 0.9293254898639327.\n",
      "[I 2025-12-23 17:39:11,121] Trial 202 finished with value: 0.9291585017330833 and parameters: {'C': 0.21796736828144747, 'solver': 'liblinear', 'penalty_lib': 'l1'}. Best is trial 155 with value: 0.9293254898639327.\n",
      "[I 2025-12-23 17:39:11,188] Trial 203 finished with value: 0.9280864411412557 and parameters: {'C': 0.18890118950572746, 'solver': 'liblinear', 'penalty_lib': 'l1'}. Best is trial 155 with value: 0.9293254898639327.\n",
      "[I 2025-12-23 17:39:11,271] Trial 204 finished with value: 0.9288761458176932 and parameters: {'C': 0.21244796850292524, 'solver': 'liblinear', 'penalty_lib': 'l1'}. Best is trial 155 with value: 0.9293254898639327.\n",
      "[I 2025-12-23 17:39:11,350] Trial 205 finished with value: 0.928699982162267 and parameters: {'C': 0.35611170230738776, 'solver': 'liblinear', 'penalty_lib': 'l1'}. Best is trial 155 with value: 0.9293254898639327.\n",
      "[I 2025-12-23 17:39:11,421] Trial 206 finished with value: 0.926848675708729 and parameters: {'C': 0.1394613516478424, 'solver': 'liblinear', 'penalty_lib': 'l1'}. Best is trial 155 with value: 0.9293254898639327.\n",
      "[I 2025-12-23 17:39:11,497] Trial 207 finished with value: 0.9290422356454371 and parameters: {'C': 0.26503326995786425, 'solver': 'liblinear', 'penalty_lib': 'l1'}. Best is trial 155 with value: 0.9293254898639327.\n",
      "[I 2025-12-23 17:39:11,582] Trial 208 finished with value: 0.9286980893092949 and parameters: {'C': 0.4057722240962343, 'solver': 'liblinear', 'penalty_lib': 'l1'}. Best is trial 155 with value: 0.9293254898639327.\n",
      "[I 2025-12-23 17:39:11,664] Trial 209 finished with value: 0.9261179702969663 and parameters: {'C': 0.1030884613511133, 'solver': 'liblinear', 'penalty_lib': 'l1'}. Best is trial 155 with value: 0.9293254898639327.\n",
      "[I 2025-12-23 17:39:11,740] Trial 210 finished with value: 0.9280145127283135 and parameters: {'C': 0.637768491607928, 'solver': 'liblinear', 'penalty_lib': 'l1'}. Best is trial 155 with value: 0.9293254898639327.\n",
      "[I 2025-12-23 17:39:11,812] Trial 211 finished with value: 0.9289856425497949 and parameters: {'C': 0.27004590082748675, 'solver': 'liblinear', 'penalty_lib': 'l1'}. Best is trial 155 with value: 0.9293254898639327.\n",
      "[I 2025-12-23 17:39:11,879] Trial 212 finished with value: 0.9280864411412557 and parameters: {'C': 0.189586458776884, 'solver': 'liblinear', 'penalty_lib': 'l1'}. Best is trial 155 with value: 0.9293254898639327.\n",
      "[I 2025-12-23 17:39:11,955] Trial 213 finished with value: 0.9293235970109606 and parameters: {'C': 0.30259740287119685, 'solver': 'liblinear', 'penalty_lib': 'l1'}. Best is trial 155 with value: 0.9293254898639327.\n",
      "[I 2025-12-23 17:39:12,028] Trial 214 finished with value: 0.9289829476404787 and parameters: {'C': 0.32835503841545927, 'solver': 'liblinear', 'penalty_lib': 'l1'}. Best is trial 155 with value: 0.9293254898639327.\n",
      "[I 2025-12-23 17:39:12,097] Trial 215 finished with value: 0.9279747307336441 and parameters: {'C': 0.1657858654609305, 'solver': 'liblinear', 'penalty_lib': 'l1'}. Best is trial 155 with value: 0.9293254898639327.\n",
      "[I 2025-12-23 17:39:12,164] Trial 216 finished with value: 0.5 and parameters: {'C': 2.423805735868087e-05, 'solver': 'liblinear', 'penalty_lib': 'l1'}. Best is trial 155 with value: 0.9293254898639327.\n",
      "[I 2025-12-23 17:39:12,237] Trial 217 finished with value: 0.9286413999668912 and parameters: {'C': 0.4583165541528437, 'solver': 'liblinear', 'penalty_lib': 'l1'}. Best is trial 155 with value: 0.9293254898639327.\n",
      "[I 2025-12-23 17:39:12,303] Trial 218 finished with value: 0.9290453155417986 and parameters: {'C': 0.22268725171082887, 'solver': 'liblinear', 'penalty_lib': 'l1'}. Best is trial 155 with value: 0.9293254898639327.\n",
      "[I 2025-12-23 17:39:12,378] Trial 219 finished with value: 0.9290396369828823 and parameters: {'C': 0.3248517734465543, 'solver': 'liblinear', 'penalty_lib': 'l1'}. Best is trial 155 with value: 0.9293254898639327.\n",
      "[I 2025-12-23 17:39:12,451] Trial 220 finished with value: 0.9270178454328345 and parameters: {'C': 0.1506863272917735, 'solver': 'liblinear', 'penalty_lib': 'l1'}. Best is trial 155 with value: 0.9293254898639327.\n",
      "[I 2025-12-23 17:39:12,527] Trial 221 finished with value: 0.9292122074258866 and parameters: {'C': 0.2426828246206777, 'solver': 'liblinear', 'penalty_lib': 'l1'}. Best is trial 155 with value: 0.9293254898639327.\n",
      "[I 2025-12-23 17:39:12,600] Trial 222 finished with value: 0.9292122074258866 and parameters: {'C': 0.2415466503658444, 'solver': 'liblinear', 'penalty_lib': 'l1'}. Best is trial 155 with value: 0.9293254898639327.\n",
      "[I 2025-12-23 17:39:12,671] Trial 223 finished with value: 0.9290435189355877 and parameters: {'C': 0.22801827492415505, 'solver': 'liblinear', 'penalty_lib': 'l1'}. Best is trial 155 with value: 0.9293254898639327.\n",
      "[I 2025-12-23 17:39:12,743] Trial 224 finished with value: 0.9286980893092949 and parameters: {'C': 0.41040203334200176, 'solver': 'liblinear', 'penalty_lib': 'l1'}. Best is trial 155 with value: 0.9293254898639327.\n",
      "[I 2025-12-23 17:39:12,813] Trial 225 finished with value: 0.9281431304836593 and parameters: {'C': 0.19142897206296725, 'solver': 'liblinear', 'penalty_lib': 'l1'}. Best is trial 155 with value: 0.9293254898639327.\n",
      "[I 2025-12-23 17:39:12,894] Trial 226 finished with value: 0.9290396369828823 and parameters: {'C': 0.32599031155111013, 'solver': 'liblinear', 'penalty_lib': 'l1'}. Best is trial 155 with value: 0.9293254898639327.\n",
      "[I 2025-12-23 17:39:12,969] Trial 227 finished with value: 0.9284684445368413 and parameters: {'C': 0.5511138996921232, 'solver': 'liblinear', 'penalty_lib': 'l1'}. Best is trial 155 with value: 0.9293254898639327.\n",
      "[I 2025-12-23 17:39:13,038] Trial 228 finished with value: 0.9262893216143278 and parameters: {'C': 0.12166939250625819, 'solver': 'liblinear', 'penalty_lib': 'l1'}. Best is trial 155 with value: 0.9293254898639327.\n",
      "[I 2025-12-23 17:39:13,110] Trial 229 finished with value: 0.9292688005215292 and parameters: {'C': 0.24727784425354157, 'solver': 'liblinear', 'penalty_lib': 'l1'}. Best is trial 155 with value: 0.9293254898639327.\n",
      "[I 2025-12-23 17:39:13,178] Trial 230 finished with value: 0.927974345746599 and parameters: {'C': 0.17687490321816113, 'solver': 'liblinear', 'penalty_lib': 'l1'}. Best is trial 155 with value: 0.9293254898639327.\n",
      "[I 2025-12-23 17:39:13,252] Trial 231 finished with value: 0.9292688967682905 and parameters: {'C': 0.2536547217693654, 'solver': 'liblinear', 'penalty_lib': 'l1'}. Best is trial 155 with value: 0.9293254898639327.\n",
      "[I 2025-12-23 17:39:13,327] Trial 232 finished with value: 0.9292132019757535 and parameters: {'C': 0.2361022594937891, 'solver': 'liblinear', 'penalty_lib': 'l1'}. Best is trial 155 with value: 0.9293254898639327.\n",
      "[I 2025-12-23 17:39:13,397] Trial 233 finished with value: 0.9290435189355877 and parameters: {'C': 0.23218253732651806, 'solver': 'liblinear', 'penalty_lib': 'l1'}. Best is trial 155 with value: 0.9293254898639327.\n",
      "[I 2025-12-23 17:39:13,464] Trial 234 finished with value: 0.9278549676803374 and parameters: {'C': 0.15817211071438442, 'solver': 'liblinear', 'penalty_lib': 'l2'}. Best is trial 155 with value: 0.9293254898639327.\n",
      "[I 2025-12-23 17:39:13,537] Trial 235 finished with value: 0.9291585017330833 and parameters: {'C': 0.2206849567438402, 'solver': 'liblinear', 'penalty_lib': 'l1'}. Best is trial 155 with value: 0.9293254898639327.\n",
      "[I 2025-12-23 17:39:13,610] Trial 236 finished with value: 0.9286980893092949 and parameters: {'C': 0.4112546873766029, 'solver': 'liblinear', 'penalty_lib': 'l1'}. Best is trial 155 with value: 0.9293254898639327.\n",
      "[I 2025-12-23 17:39:13,678] Trial 237 finished with value: 0.9289856425497949 and parameters: {'C': 0.26976987488479826, 'solver': 'liblinear', 'penalty_lib': 'l1'}. Best is trial 155 with value: 0.9293254898639327.\n",
      "[I 2025-12-23 17:39:13,821] Trial 238 finished with value: 0.9247887383589543 and parameters: {'C': 98.67416108635796, 'solver': 'liblinear', 'penalty_lib': 'l1'}. Best is trial 155 with value: 0.9293254898639327.\n",
      "[I 2025-12-23 17:39:13,897] Trial 239 finished with value: 0.9242038147083017 and parameters: {'C': 0.09033822801535167, 'solver': 'liblinear', 'penalty_lib': 'l1'}. Best is trial 155 with value: 0.9293254898639327.\n",
      "[I 2025-12-23 17:39:13,978] Trial 240 finished with value: 0.9277501549572857 and parameters: {'C': 0.16003708152890353, 'solver': 'liblinear', 'penalty_lib': 'l1'}. Best is trial 155 with value: 0.9293254898639327.\n",
      "[I 2025-12-23 17:39:14,059] Trial 241 finished with value: 0.9287063665307661 and parameters: {'C': 0.20944929295176118, 'solver': 'liblinear', 'penalty_lib': 'l1'}. Best is trial 155 with value: 0.9293254898639327.\n",
      "[I 2025-12-23 17:39:14,138] Trial 242 finished with value: 0.9291001120312302 and parameters: {'C': 0.22467121048389596, 'solver': 'liblinear', 'penalty_lib': 'l1'}. Best is trial 155 with value: 0.9293254898639327.\n",
      "[I 2025-12-23 17:39:14,219] Trial 243 finished with value: 0.9290406315327487 and parameters: {'C': 0.31770418987458204, 'solver': 'liblinear', 'penalty_lib': 'l1'}. Best is trial 155 with value: 0.9293254898639327.\n",
      "[I 2025-12-23 17:39:14,294] Trial 244 finished with value: 0.9292122074258866 and parameters: {'C': 0.24238674050735273, 'solver': 'liblinear', 'penalty_lib': 'l1'}. Best is trial 155 with value: 0.9293254898639327.\n",
      "[I 2025-12-23 17:39:14,364] Trial 245 finished with value: 0.9286980893092949 and parameters: {'C': 0.4077986934823997, 'solver': 'liblinear', 'penalty_lib': 'l1'}. Best is trial 155 with value: 0.9293254898639327.\n",
      "[I 2025-12-23 17:39:14,437] Trial 246 finished with value: 0.9293819867128137 and parameters: {'C': 0.29045887470856185, 'solver': 'liblinear', 'penalty_lib': 'l1'}. Best is trial 246 with value: 0.9293819867128137.\n",
      "[I 2025-12-23 17:39:14,511] Trial 247 finished with value: 0.9291565126333499 and parameters: {'C': 0.29268697024689566, 'solver': 'liblinear', 'penalty_lib': 'l1'}. Best is trial 246 with value: 0.9293819867128137.\n",
      "[I 2025-12-23 17:39:14,582] Trial 248 finished with value: 0.9290396369828823 and parameters: {'C': 0.32535304914825863, 'solver': 'liblinear', 'penalty_lib': 'l1'}. Best is trial 246 with value: 0.9293819867128137.\n",
      "[I 2025-12-23 17:39:14,654] Trial 249 finished with value: 0.9287526933052035 and parameters: {'C': 0.47190407610113216, 'solver': 'liblinear', 'penalty_lib': 'l1'}. Best is trial 246 with value: 0.9293819867128137.\n",
      "[I 2025-12-23 17:39:14,721] Trial 250 finished with value: 0.9290998232909462 and parameters: {'C': 0.29755029864752847, 'solver': 'liblinear', 'penalty_lib': 'l1'}. Best is trial 246 with value: 0.9293819867128137.\n",
      "[I 2025-12-23 17:39:14,797] Trial 251 finished with value: 0.9280711058239557 and parameters: {'C': 0.6311678521132191, 'solver': 'liblinear', 'penalty_lib': 'l1'}. Best is trial 246 with value: 0.9293819867128137.\n",
      "[I 2025-12-23 17:39:14,870] Trial 252 finished with value: 0.9286413999668912 and parameters: {'C': 0.4181937525801595, 'solver': 'liblinear', 'penalty_lib': 'l1'}. Best is trial 246 with value: 0.9293819867128137.\n",
      "[I 2025-12-23 17:39:14,937] Trial 253 finished with value: 0.9270743422817155 and parameters: {'C': 0.1442937851375475, 'solver': 'liblinear', 'penalty_lib': 'l1'}. Best is trial 246 with value: 0.9293819867128137.\n",
      "[I 2025-12-23 17:39:15,013] Trial 254 finished with value: 0.9292131057289922 and parameters: {'C': 0.28444995315204585, 'solver': 'liblinear', 'penalty_lib': 'l1'}. Best is trial 246 with value: 0.9293819867128137.\n",
      "[I 2025-12-23 17:39:15,078] Trial 255 finished with value: 0.929155421836722 and parameters: {'C': 0.2638399163046353, 'solver': 'liblinear', 'penalty_lib': 'l1'}. Best is trial 246 with value: 0.9293819867128137.\n",
      "[I 2025-12-23 17:39:15,153] Trial 256 finished with value: 0.9258342027624102 and parameters: {'C': 0.11454039079556438, 'solver': 'liblinear', 'penalty_lib': 'l1'}. Best is trial 246 with value: 0.9293819867128137.\n",
      "[I 2025-12-23 17:39:15,221] Trial 257 finished with value: 0.9281379331585491 and parameters: {'C': 0.18100174707740901, 'solver': 'liblinear', 'penalty_lib': 'l2'}. Best is trial 246 with value: 0.9293819867128137.\n",
      "[I 2025-12-23 17:39:15,303] Trial 258 finished with value: 0.9286960039627999 and parameters: {'C': 0.509419696549038, 'solver': 'liblinear', 'penalty_lib': 'l1'}. Best is trial 246 with value: 0.9293819867128137.\n",
      "[I 2025-12-23 17:39:15,377] Trial 259 finished with value: 0.928699982162267 and parameters: {'C': 0.3571345877224467, 'solver': 'liblinear', 'penalty_lib': 'l1'}. Best is trial 246 with value: 0.9293819867128137.\n",
      "[I 2025-12-23 17:39:15,447] Trial 260 finished with value: 0.9290988287410796 and parameters: {'C': 0.2593089194825871, 'solver': 'liblinear', 'penalty_lib': 'l1'}. Best is trial 246 with value: 0.9293819867128137.\n",
      "[I 2025-12-23 17:39:15,518] Trial 261 finished with value: 0.927974345746599 and parameters: {'C': 0.17113919288065058, 'solver': 'liblinear', 'penalty_lib': 'l1'}. Best is trial 246 with value: 0.9293819867128137.\n",
      "[I 2025-12-23 17:39:15,587] Trial 262 finished with value: 0.9285857051743541 and parameters: {'C': 0.3919512232443144, 'solver': 'liblinear', 'penalty_lib': 'l1'}. Best is trial 246 with value: 0.9293819867128137.\n",
      "[I 2025-12-23 17:39:15,664] Trial 263 finished with value: 0.9293254898639327 and parameters: {'C': 0.24843044228775743, 'solver': 'liblinear', 'penalty_lib': 'l1'}. Best is trial 246 with value: 0.9293819867128137.\n",
      "[I 2025-12-23 17:39:15,728] Trial 264 finished with value: 0.9264564059919383 and parameters: {'C': 0.1299231498579431, 'solver': 'liblinear', 'penalty_lib': 'l1'}. Best is trial 246 with value: 0.9293819867128137.\n",
      "[I 2025-12-23 17:39:15,803] Trial 265 finished with value: 0.9291585017330833 and parameters: {'C': 0.21944263844969955, 'solver': 'liblinear', 'penalty_lib': 'l1'}. Best is trial 246 with value: 0.9293819867128137.\n",
      "[I 2025-12-23 17:39:15,878] Trial 266 finished with value: 0.9281432267304206 and parameters: {'C': 0.18735311481390665, 'solver': 'liblinear', 'penalty_lib': 'l1'}. Best is trial 246 with value: 0.9293819867128137.\n",
      "[I 2025-12-23 17:39:15,950] Trial 267 finished with value: 0.9290435189355877 and parameters: {'C': 0.22520293244577444, 'solver': 'liblinear', 'penalty_lib': 'l1'}. Best is trial 246 with value: 0.9293819867128137.\n",
      "[I 2025-12-23 17:39:16,021] Trial 268 finished with value: 0.9280146089750747 and parameters: {'C': 0.6543774777303287, 'solver': 'liblinear', 'penalty_lib': 'l1'}. Best is trial 246 with value: 0.9293819867128137.\n",
      "[I 2025-12-23 17:39:16,093] Trial 269 finished with value: 0.9266223033261598 and parameters: {'C': 0.13673591838629393, 'solver': 'liblinear', 'penalty_lib': 'l1'}. Best is trial 246 with value: 0.9293819867128137.\n",
      "[I 2025-12-23 17:39:16,164] Trial 270 finished with value: 0.9286413999668911 and parameters: {'C': 0.38109126725999865, 'solver': 'liblinear', 'penalty_lib': 'l1'}. Best is trial 246 with value: 0.9293819867128137.\n",
      "[I 2025-12-23 17:39:16,237] Trial 271 finished with value: 0.9208881137816378 and parameters: {'C': 0.07395608835946789, 'solver': 'liblinear', 'penalty_lib': 'l1'}. Best is trial 246 with value: 0.9293819867128137.\n",
      "[I 2025-12-23 17:39:16,309] Trial 272 finished with value: 0.9290435189355877 and parameters: {'C': 0.231449743727701, 'solver': 'liblinear', 'penalty_lib': 'l1'}. Best is trial 246 with value: 0.9293819867128137.\n",
      "[I 2025-12-23 17:39:16,380] Trial 273 finished with value: 0.928087628184645 and parameters: {'C': 0.17834078564090086, 'solver': 'liblinear', 'penalty_lib': 'l1'}. Best is trial 246 with value: 0.9293819867128137.\n",
      "[I 2025-12-23 17:39:16,452] Trial 274 finished with value: 0.9258932982738463 and parameters: {'C': 0.10186081381919104, 'solver': 'liblinear', 'penalty_lib': 'l1'}. Best is trial 246 with value: 0.9293819867128137.\n",
      "[I 2025-12-23 17:39:16,560] Trial 275 finished with value: 0.9247896366620596 and parameters: {'C': 38.07491040110261, 'solver': 'liblinear', 'penalty_lib': 'l1'}. Best is trial 246 with value: 0.9293819867128137.\n",
      "[I 2025-12-23 17:39:16,628] Trial 276 finished with value: 0.9288696652024326 and parameters: {'C': 0.3324042484486806, 'solver': 'liblinear', 'penalty_lib': 'l1'}. Best is trial 246 with value: 0.9293819867128137.\n",
      "[I 2025-12-23 17:39:16,703] Trial 277 finished with value: 0.9286951056596944 and parameters: {'C': 0.5188728414608422, 'solver': 'liblinear', 'penalty_lib': 'l1'}. Best is trial 246 with value: 0.9293819867128137.\n",
      "[I 2025-12-23 17:39:16,776] Trial 278 finished with value: 0.9279659722783661 and parameters: {'C': 0.25070638638680964, 'solver': 'liblinear', 'penalty_lib': 'l2'}. Best is trial 246 with value: 0.9293819867128137.\n",
      "[I 2025-12-23 17:39:16,849] Trial 279 finished with value: 0.9275811777267029 and parameters: {'C': 0.1572680462236941, 'solver': 'liblinear', 'penalty_lib': 'l1'}. Best is trial 246 with value: 0.9293819867128137.\n",
      "[I 2025-12-23 17:39:16,921] Trial 280 finished with value: 0.9286980893092949 and parameters: {'C': 0.41003152081999295, 'solver': 'liblinear', 'penalty_lib': 'l1'}. Best is trial 246 with value: 0.9293819867128137.\n",
      "[I 2025-12-23 17:39:16,993] Trial 281 finished with value: 0.9290988287410796 and parameters: {'C': 0.26179727184840945, 'solver': 'liblinear', 'penalty_lib': 'l1'}. Best is trial 246 with value: 0.9293819867128137.\n",
      "[I 2025-12-23 17:39:17,068] Trial 282 finished with value: 0.926399812896296 and parameters: {'C': 0.13105430288601996, 'solver': 'liblinear', 'penalty_lib': 'l1'}. Best is trial 246 with value: 0.9293819867128137.\n",
      "[I 2025-12-23 17:39:17,137] Trial 283 finished with value: 0.9285374855469446 and parameters: {'C': 0.20791192018171747, 'solver': 'liblinear', 'penalty_lib': 'l1'}. Best is trial 246 with value: 0.9293819867128137.\n",
      "[I 2025-12-23 17:39:17,213] Trial 284 finished with value: 0.9290406315327487 and parameters: {'C': 0.3175551599428048, 'solver': 'liblinear', 'penalty_lib': 'l1'}. Best is trial 246 with value: 0.9293819867128137.\n",
      "[I 2025-12-23 17:39:17,281] Trial 285 finished with value: 0.9274500896378169 and parameters: {'C': 0.8258673571926896, 'solver': 'liblinear', 'penalty_lib': 'l1'}. Best is trial 246 with value: 0.9293819867128137.\n",
      "[I 2025-12-23 17:39:17,372] Trial 286 finished with value: 0.9289781673846674 and parameters: {'C': 0.49275809867144926, 'solver': 'liblinear', 'penalty_lib': 'l1'}. Best is trial 246 with value: 0.9293819867128137.\n",
      "[I 2025-12-23 17:39:17,458] Trial 287 finished with value: 0.9281997235793016 and parameters: {'C': 0.1941896229606727, 'solver': 'liblinear', 'penalty_lib': 'l1'}. Best is trial 246 with value: 0.9293819867128137.\n",
      "[I 2025-12-23 17:39:17,529] Trial 288 finished with value: 0.929210410819676 and parameters: {'C': 0.30890647298899554, 'solver': 'liblinear', 'penalty_lib': 'l1'}. Best is trial 246 with value: 0.9293819867128137.\n",
      "[I 2025-12-23 17:39:17,603] Trial 289 finished with value: 0.9288141629034182 and parameters: {'C': 0.3489905043730825, 'solver': 'liblinear', 'penalty_lib': 'l1'}. Best is trial 246 with value: 0.9293819867128137.\n",
      "[I 2025-12-23 17:39:17,676] Trial 290 finished with value: 0.9282986652499143 and parameters: {'C': 0.5601980562765724, 'solver': 'liblinear', 'penalty_lib': 'l1'}. Best is trial 246 with value: 0.9293819867128137.\n",
      "[I 2025-12-23 17:39:17,750] Trial 291 finished with value: 0.9290998232909462 and parameters: {'C': 0.2985337155915697, 'solver': 'liblinear', 'penalty_lib': 'l1'}. Best is trial 246 with value: 0.9293819867128137.\n",
      "[I 2025-12-23 17:39:17,821] Trial 292 finished with value: 0.9285290158319505 and parameters: {'C': 0.4337935811065609, 'solver': 'liblinear', 'penalty_lib': 'l1'}. Best is trial 246 with value: 0.9293819867128137.\n",
      "[I 2025-12-23 17:39:17,897] Trial 293 finished with value: 0.9270753368315823 and parameters: {'C': 0.1490219073341725, 'solver': 'liblinear', 'penalty_lib': 'l1'}. Best is trial 246 with value: 0.9293819867128137.\n",
      "[I 2025-12-23 17:39:17,970] Trial 294 finished with value: 0.9292131057289922 and parameters: {'C': 0.2793976728108627, 'solver': 'liblinear', 'penalty_lib': 'l1'}. Best is trial 246 with value: 0.9293819867128137.\n",
      "[I 2025-12-23 17:39:18,038] Trial 295 finished with value: 0.9289262582980751 and parameters: {'C': 0.33006630726737607, 'solver': 'liblinear', 'penalty_lib': 'l1'}. Best is trial 246 with value: 0.9293819867128137.\n",
      "[I 2025-12-23 17:39:18,114] Trial 296 finished with value: 0.9278457279912532 and parameters: {'C': 0.7187955816531468, 'solver': 'liblinear', 'penalty_lib': 'l1'}. Best is trial 246 with value: 0.9293819867128137.\n",
      "[I 2025-12-23 17:39:18,187] Trial 297 finished with value: 0.9286979930625335 and parameters: {'C': 0.4524861076969296, 'solver': 'liblinear', 'penalty_lib': 'l1'}. Best is trial 246 with value: 0.9293819867128137.\n",
      "[I 2025-12-23 17:39:18,258] Trial 298 finished with value: 0.9278489041343759 and parameters: {'C': 0.2759363237003054, 'solver': 'liblinear', 'penalty_lib': 'l2'}. Best is trial 246 with value: 0.9293819867128137.\n",
      "[I 2025-12-23 17:39:18,328] Trial 299 finished with value: 0.9259500838630114 and parameters: {'C': 0.10545566846474298, 'solver': 'liblinear', 'penalty_lib': 'l1'}. Best is trial 246 with value: 0.9293819867128137.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[67 11]\n",
      " [10 62]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.86      0.86        78\n",
      "           1       0.85      0.86      0.86        72\n",
      "\n",
      "    accuracy                           0.86       150\n",
      "   macro avg       0.86      0.86      0.86       150\n",
      "weighted avg       0.86      0.86      0.86       150\n",
      "\n",
      "ROC-AUC Score: 0.9225\n",
      "score in training 0.8691275167785235\n",
      "score in testing 0.86\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'C': 0.29045887470856185, 'solver': 'liblinear', 'penalty_lib': 'l1'}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic_regression_optuna(df, \"HeartDisease\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "c884ab92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_forest_optuna(df, target):\n",
    "    X = df.drop(columns=[target])\n",
    "    y = df[target]\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42, stratify=y)\n",
    "    \n",
    "    col_num = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "    col_cat = X.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "    \n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', StandardScaler(), col_num),\n",
    "            ('cat', OneHotEncoder(handle_unknown='ignore'), col_cat)\n",
    "        ])\n",
    "    \n",
    "    def objective(trial):\n",
    "        n_estimators = trial.suggest_int('n_estimators', 5, 500)\n",
    "        max_depth = trial.suggest_int('max_depth', 3, 30)\n",
    "        min_samples_split = trial.suggest_int('min_samples_split', 2, 20)\n",
    "        min_samples_leaf = trial.suggest_int('min_samples_leaf', 1, 20)\n",
    "        max_features = trial.suggest_categorical('max_features', ['sqrt', 'log2', None])\n",
    "        criterion = trial.suggest_categorical('criterion', ['gini', 'entropy'])\n",
    "        \n",
    "        model = RandomForestClassifier(\n",
    "            n_estimators=n_estimators,\n",
    "            max_depth=max_depth,\n",
    "            min_samples_split=min_samples_split,\n",
    "            min_samples_leaf=min_samples_leaf,\n",
    "            max_features=max_features,\n",
    "            criterion=criterion,\n",
    "            random_state=42,\n",
    "            n_jobs=-1\n",
    "        )\n",
    "        \n",
    "        pipe = Pipeline(steps=[('preprocessor', preprocessor), ('model', model)])\n",
    "        score = cross_val_score(pipe, X_train, y_train, cv=5, scoring='roc_auc').mean()\n",
    "        return score\n",
    "\n",
    "    study = optuna.create_study(direction='maximize')\n",
    "    study.optimize(lambda trial: objective(trial), n_trials=20)\n",
    "\n",
    "    best_model = RandomForestClassifier(\n",
    "        n_estimators=study.best_params['n_estimators'],\n",
    "        max_depth=study.best_params['max_depth'],\n",
    "        min_samples_split=study.best_params['min_samples_split'],\n",
    "        min_samples_leaf=study.best_params['min_samples_leaf'],\n",
    "        max_features=study.best_params['max_features'],\n",
    "        criterion=study.best_params['criterion'],\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    best_pipe = Pipeline(steps=[('preprocessor', preprocessor), ('model', best_model)])\n",
    "    best_pipe.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = best_pipe.predict(X_test)\n",
    "    y_proba = best_pipe.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    roc_auc = roc_auc_score(y_test, y_proba)\n",
    "    print(f\"ROC-AUC Score: {roc_auc:.4f}\")\n",
    "    \n",
    "    print(\"score in training\", best_pipe.score(X_train, y_train))\n",
    "    print(\"score in testing\", best_pipe.score(X_test, y_test))\n",
    "    \n",
    "    return study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6aee6eb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-23 17:46:37,505] A new study created in memory with name: no-name-934a863b-7b71-4bbe-8a4d-b10390da1307\n",
      "[I 2025-12-23 17:46:39,912] Trial 0 finished with value: 0.9321992898272307 and parameters: {'n_estimators': 339, 'max_depth': 29, 'min_samples_split': 5, 'min_samples_leaf': 9, 'max_features': 'log2', 'criterion': 'gini'}. Best is trial 0 with value: 0.9321992898272307.\n",
      "[I 2025-12-23 17:46:40,913] Trial 1 finished with value: 0.9318019831965987 and parameters: {'n_estimators': 135, 'max_depth': 28, 'min_samples_split': 18, 'min_samples_leaf': 8, 'max_features': 'log2', 'criterion': 'gini'}. Best is trial 0 with value: 0.9321992898272307.\n",
      "[I 2025-12-23 17:46:43,593] Trial 2 finished with value: 0.9290973208751525 and parameters: {'n_estimators': 408, 'max_depth': 26, 'min_samples_split': 13, 'min_samples_leaf': 16, 'max_features': 'sqrt', 'criterion': 'gini'}. Best is trial 0 with value: 0.9321992898272307.\n",
      "[I 2025-12-23 17:46:45,861] Trial 3 finished with value: 0.9288249425406836 and parameters: {'n_estimators': 344, 'max_depth': 24, 'min_samples_split': 3, 'min_samples_leaf': 18, 'max_features': 'log2', 'criterion': 'gini'}. Best is trial 0 with value: 0.9321992898272307.\n",
      "[I 2025-12-23 17:46:48,278] Trial 4 finished with value: 0.93338604447627 and parameters: {'n_estimators': 369, 'max_depth': 22, 'min_samples_split': 20, 'min_samples_leaf': 8, 'max_features': 'log2', 'criterion': 'entropy'}. Best is trial 4 with value: 0.93338604447627.\n",
      "[I 2025-12-23 17:46:49,729] Trial 5 finished with value: 0.9296547821165817 and parameters: {'n_estimators': 208, 'max_depth': 9, 'min_samples_split': 14, 'min_samples_leaf': 16, 'max_features': 'sqrt', 'criterion': 'gini'}. Best is trial 4 with value: 0.93338604447627.\n",
      "[I 2025-12-23 17:46:51,278] Trial 6 finished with value: 0.9242533176258618 and parameters: {'n_estimators': 231, 'max_depth': 24, 'min_samples_split': 12, 'min_samples_leaf': 4, 'max_features': None, 'criterion': 'entropy'}. Best is trial 4 with value: 0.93338604447627.\n",
      "[I 2025-12-23 17:46:52,028] Trial 7 finished with value: 0.9229436237803931 and parameters: {'n_estimators': 87, 'max_depth': 4, 'min_samples_split': 16, 'min_samples_leaf': 13, 'max_features': None, 'criterion': 'entropy'}. Best is trial 4 with value: 0.93338604447627.\n",
      "[I 2025-12-23 17:46:53,944] Trial 8 finished with value: 0.9318140140417608 and parameters: {'n_estimators': 291, 'max_depth': 10, 'min_samples_split': 12, 'min_samples_leaf': 11, 'max_features': 'log2', 'criterion': 'entropy'}. Best is trial 4 with value: 0.93338604447627.\n",
      "[I 2025-12-23 17:46:54,944] Trial 9 finished with value: 0.9283075199519535 and parameters: {'n_estimators': 135, 'max_depth': 9, 'min_samples_split': 5, 'min_samples_leaf': 18, 'max_features': 'log2', 'criterion': 'entropy'}. Best is trial 4 with value: 0.93338604447627.\n",
      "[I 2025-12-23 17:46:58,113] Trial 10 finished with value: 0.9326491471895304 and parameters: {'n_estimators': 497, 'max_depth': 18, 'min_samples_split': 20, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'criterion': 'entropy'}. Best is trial 4 with value: 0.93338604447627.\n",
      "[I 2025-12-23 17:47:01,128] Trial 11 finished with value: 0.9324237693568278 and parameters: {'n_estimators': 472, 'max_depth': 18, 'min_samples_split': 20, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'criterion': 'entropy'}. Best is trial 4 with value: 0.93338604447627.\n",
      "[I 2025-12-23 17:47:04,211] Trial 12 finished with value: 0.9324776033786464 and parameters: {'n_estimators': 485, 'max_depth': 18, 'min_samples_split': 20, 'min_samples_leaf': 6, 'max_features': 'sqrt', 'criterion': 'entropy'}. Best is trial 4 with value: 0.93338604447627.\n",
      "[I 2025-12-23 17:47:06,844] Trial 13 finished with value: 0.9329947693093462 and parameters: {'n_estimators': 407, 'max_depth': 21, 'min_samples_split': 17, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'criterion': 'entropy'}. Best is trial 4 with value: 0.93338604447627.\n",
      "[I 2025-12-23 17:47:09,450] Trial 14 finished with value: 0.9248768362277943 and parameters: {'n_estimators': 405, 'max_depth': 23, 'min_samples_split': 9, 'min_samples_leaf': 4, 'max_features': None, 'criterion': 'entropy'}. Best is trial 4 with value: 0.93338604447627.\n",
      "[I 2025-12-23 17:47:12,094] Trial 15 finished with value: 0.9331022769417142 and parameters: {'n_estimators': 409, 'max_depth': 21, 'min_samples_split': 16, 'min_samples_leaf': 4, 'max_features': 'log2', 'criterion': 'entropy'}. Best is trial 4 with value: 0.93338604447627.\n",
      "[I 2025-12-23 17:47:14,195] Trial 16 finished with value: 0.9324227427247074 and parameters: {'n_estimators': 315, 'max_depth': 15, 'min_samples_split': 9, 'min_samples_leaf': 6, 'max_features': 'log2', 'criterion': 'entropy'}. Best is trial 4 with value: 0.93338604447627.\n",
      "[I 2025-12-23 17:47:14,530] Trial 17 finished with value: 0.9269035684449218 and parameters: {'n_estimators': 13, 'max_depth': 15, 'min_samples_split': 15, 'min_samples_leaf': 12, 'max_features': 'log2', 'criterion': 'entropy'}. Best is trial 4 with value: 0.93338604447627.\n",
      "[I 2025-12-23 17:47:16,878] Trial 18 finished with value: 0.9324802662057088 and parameters: {'n_estimators': 374, 'max_depth': 22, 'min_samples_split': 17, 'min_samples_leaf': 4, 'max_features': 'log2', 'criterion': 'entropy'}. Best is trial 4 with value: 0.93338604447627.\n",
      "[I 2025-12-23 17:47:18,728] Trial 19 finished with value: 0.932821300563236 and parameters: {'n_estimators': 267, 'max_depth': 13, 'min_samples_split': 18, 'min_samples_leaf': 7, 'max_features': 'log2', 'criterion': 'entropy'}. Best is trial 4 with value: 0.93338604447627.\n",
      "[I 2025-12-23 17:47:21,529] Trial 20 finished with value: 0.9315827972388728 and parameters: {'n_estimators': 430, 'max_depth': 20, 'min_samples_split': 9, 'min_samples_leaf': 10, 'max_features': 'log2', 'criterion': 'entropy'}. Best is trial 4 with value: 0.93338604447627.\n",
      "[I 2025-12-23 17:47:24,400] Trial 21 finished with value: 0.9323642888583468 and parameters: {'n_estimators': 446, 'max_depth': 20, 'min_samples_split': 18, 'min_samples_leaf': 3, 'max_features': 'sqrt', 'criterion': 'entropy'}. Best is trial 4 with value: 0.93338604447627.\n",
      "[I 2025-12-23 17:47:26,978] Trial 22 finished with value: 0.9336079253433122 and parameters: {'n_estimators': 376, 'max_depth': 21, 'min_samples_split': 15, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'criterion': 'entropy'}. Best is trial 22 with value: 0.9336079253433122.\n",
      "[I 2025-12-23 17:47:29,397] Trial 23 finished with value: 0.9251549252034336 and parameters: {'n_estimators': 363, 'max_depth': 26, 'min_samples_split': 15, 'min_samples_leaf': 3, 'max_features': None, 'criterion': 'entropy'}. Best is trial 22 with value: 0.9336079253433122.\n",
      "[I 2025-12-23 17:47:31,421] Trial 24 finished with value: 0.9334400389093573 and parameters: {'n_estimators': 308, 'max_depth': 26, 'min_samples_split': 14, 'min_samples_leaf': 6, 'max_features': 'log2', 'criterion': 'entropy'}. Best is trial 22 with value: 0.9336079253433122.\n",
      "[I 2025-12-23 17:47:33,444] Trial 25 finished with value: 0.9329323051612647 and parameters: {'n_estimators': 302, 'max_depth': 26, 'min_samples_split': 11, 'min_samples_leaf': 7, 'max_features': 'sqrt', 'criterion': 'entropy'}. Best is trial 22 with value: 0.9336079253433122.\n",
      "[I 2025-12-23 17:47:34,878] Trial 26 finished with value: 0.9316844979833097 and parameters: {'n_estimators': 205, 'max_depth': 30, 'min_samples_split': 14, 'min_samples_leaf': 9, 'max_features': 'log2', 'criterion': 'gini'}. Best is trial 22 with value: 0.9336079253433122.\n",
      "[I 2025-12-23 17:47:36,594] Trial 27 finished with value: 0.9328744929399793 and parameters: {'n_estimators': 255, 'max_depth': 27, 'min_samples_split': 11, 'min_samples_leaf': 6, 'max_features': 'log2', 'criterion': 'entropy'}. Best is trial 22 with value: 0.9336079253433122.\n",
      "[I 2025-12-23 17:47:38,744] Trial 28 finished with value: 0.9238262707459892 and parameters: {'n_estimators': 330, 'max_depth': 25, 'min_samples_split': 7, 'min_samples_leaf': 2, 'max_features': None, 'criterion': 'entropy'}. Best is trial 22 with value: 0.9336079253433122.\n",
      "[I 2025-12-23 17:47:41,094] Trial 29 finished with value: 0.9326501417393971 and parameters: {'n_estimators': 367, 'max_depth': 29, 'min_samples_split': 13, 'min_samples_leaf': 9, 'max_features': 'sqrt', 'criterion': 'gini'}. Best is trial 22 with value: 0.9336079253433122.\n",
      "[I 2025-12-23 17:47:42,995] Trial 30 finished with value: 0.931413691679275 and parameters: {'n_estimators': 276, 'max_depth': 23, 'min_samples_split': 19, 'min_samples_leaf': 14, 'max_features': 'log2', 'criterion': 'entropy'}. Best is trial 22 with value: 0.9336079253433122.\n",
      "[I 2025-12-23 17:47:45,469] Trial 31 finished with value: 0.9336687853787053 and parameters: {'n_estimators': 387, 'max_depth': 21, 'min_samples_split': 15, 'min_samples_leaf': 5, 'max_features': 'log2', 'criterion': 'entropy'}. Best is trial 31 with value: 0.9336687853787053.\n",
      "[I 2025-12-23 17:47:47,662] Trial 32 finished with value: 0.933444594589392 and parameters: {'n_estimators': 342, 'max_depth': 19, 'min_samples_split': 15, 'min_samples_leaf': 5, 'max_features': 'log2', 'criterion': 'entropy'}. Best is trial 31 with value: 0.9336687853787053.\n",
      "[I 2025-12-23 17:47:49,850] Trial 33 finished with value: 0.9338911474795539 and parameters: {'n_estimators': 331, 'max_depth': 16, 'min_samples_split': 15, 'min_samples_leaf': 3, 'max_features': 'log2', 'criterion': 'entropy'}. Best is trial 33 with value: 0.9338911474795539.\n",
      "[I 2025-12-23 17:47:52,728] Trial 34 finished with value: 0.9329270436716472 and parameters: {'n_estimators': 454, 'max_depth': 15, 'min_samples_split': 16, 'min_samples_leaf': 3, 'max_features': 'log2', 'criterion': 'gini'}. Best is trial 33 with value: 0.9338911474795539.\n",
      "[I 2025-12-23 17:47:54,963] Trial 35 finished with value: 0.9334444983426309 and parameters: {'n_estimators': 343, 'max_depth': 13, 'min_samples_split': 15, 'min_samples_leaf': 5, 'max_features': 'log2', 'criterion': 'entropy'}. Best is trial 33 with value: 0.9338911474795539.\n",
      "[I 2025-12-23 17:47:57,429] Trial 36 finished with value: 0.9324797208073949 and parameters: {'n_estimators': 389, 'max_depth': 17, 'min_samples_split': 13, 'min_samples_leaf': 2, 'max_features': 'log2', 'criterion': 'gini'}. Best is trial 33 with value: 0.9338911474795539.\n",
      "[I 2025-12-23 17:47:59,664] Trial 37 finished with value: 0.9333259544149672 and parameters: {'n_estimators': 335, 'max_depth': 19, 'min_samples_split': 17, 'min_samples_leaf': 5, 'max_features': 'sqrt', 'criterion': 'entropy'}. Best is trial 33 with value: 0.9338911474795539.\n",
      "[I 2025-12-23 17:48:01,344] Trial 38 finished with value: 0.931523541316168 and parameters: {'n_estimators': 237, 'max_depth': 13, 'min_samples_split': 12, 'min_samples_leaf': 2, 'max_features': 'log2', 'criterion': 'gini'}. Best is trial 33 with value: 0.9338911474795539.\n",
      "[I 2025-12-23 17:48:04,164] Trial 39 finished with value: 0.9286020350415207 and parameters: {'n_estimators': 425, 'max_depth': 16, 'min_samples_split': 10, 'min_samples_leaf': 20, 'max_features': 'log2', 'criterion': 'entropy'}. Best is trial 33 with value: 0.9338911474795539.\n",
      "[I 2025-12-23 17:48:06,528] Trial 40 finished with value: 0.9272075798816036 and parameters: {'n_estimators': 356, 'max_depth': 4, 'min_samples_split': 2, 'min_samples_leaf': 8, 'max_features': None, 'criterion': 'entropy'}. Best is trial 33 with value: 0.9338911474795539.\n",
      "[I 2025-12-23 17:48:08,711] Trial 41 finished with value: 0.9335578770274381 and parameters: {'n_estimators': 338, 'max_depth': 12, 'min_samples_split': 15, 'min_samples_leaf': 5, 'max_features': 'log2', 'criterion': 'entropy'}. Best is trial 33 with value: 0.9338911474795539.\n",
      "[I 2025-12-23 17:48:11,161] Trial 42 finished with value: 0.9328187981474423 and parameters: {'n_estimators': 384, 'max_depth': 11, 'min_samples_split': 13, 'min_samples_leaf': 5, 'max_features': 'log2', 'criterion': 'entropy'}. Best is trial 33 with value: 0.9338911474795539.\n",
      "[I 2025-12-23 17:48:13,128] Trial 43 finished with value: 0.9338265979849778 and parameters: {'n_estimators': 287, 'max_depth': 8, 'min_samples_split': 15, 'min_samples_leaf': 3, 'max_features': 'log2', 'criterion': 'entropy'}. Best is trial 33 with value: 0.9338911474795539.\n",
      "[I 2025-12-23 17:48:14,511] Trial 44 finished with value: 0.9326946719076237 and parameters: {'n_estimators': 204, 'max_depth': 7, 'min_samples_split': 16, 'min_samples_leaf': 3, 'max_features': 'log2', 'criterion': 'entropy'}. Best is trial 33 with value: 0.9338911474795539.\n",
      "[I 2025-12-23 17:48:16,378] Trial 45 finished with value: 0.9331015711321313 and parameters: {'n_estimators': 281, 'max_depth': 6, 'min_samples_split': 14, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'criterion': 'entropy'}. Best is trial 33 with value: 0.9338911474795539.\n",
      "[I 2025-12-23 17:48:18,478] Trial 46 finished with value: 0.9325933561502323 and parameters: {'n_estimators': 319, 'max_depth': 11, 'min_samples_split': 18, 'min_samples_leaf': 1, 'max_features': 'log2', 'criterion': 'entropy'}. Best is trial 33 with value: 0.9338911474795539.\n",
      "[I 2025-12-23 17:48:20,394] Trial 47 finished with value: 0.9331544426863368 and parameters: {'n_estimators': 291, 'max_depth': 8, 'min_samples_split': 12, 'min_samples_leaf': 4, 'max_features': 'log2', 'criterion': 'entropy'}. Best is trial 33 with value: 0.9338911474795539.\n",
      "[I 2025-12-23 17:48:21,496] Trial 48 finished with value: 0.9336623689279524 and parameters: {'n_estimators': 154, 'max_depth': 12, 'min_samples_split': 16, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'criterion': 'entropy'}. Best is trial 33 with value: 0.9338911474795539.\n",
      "[I 2025-12-23 17:48:22,744] Trial 49 finished with value: 0.9323675933304845 and parameters: {'n_estimators': 170, 'max_depth': 9, 'min_samples_split': 17, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'criterion': 'entropy'}. Best is trial 33 with value: 0.9338911474795539.\n",
      "[I 2025-12-23 17:48:23,612] Trial 50 finished with value: 0.9318549189153117 and parameters: {'n_estimators': 106, 'max_depth': 5, 'min_samples_split': 16, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'criterion': 'gini'}. Best is trial 33 with value: 0.9338911474795539.\n",
      "[I 2025-12-23 17:48:26,188] Trial 51 finished with value: 0.9333281360082234 and parameters: {'n_estimators': 392, 'max_depth': 12, 'min_samples_split': 15, 'min_samples_leaf': 3, 'max_features': 'sqrt', 'criterion': 'entropy'}. Best is trial 33 with value: 0.9338911474795539.\n",
      "[I 2025-12-23 17:48:26,800] Trial 52 finished with value: 0.9318039081318247 and parameters: {'n_estimators': 44, 'max_depth': 14, 'min_samples_split': 14, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'criterion': 'entropy'}. Best is trial 33 with value: 0.9338911474795539.\n",
      "[I 2025-12-23 17:48:28,128] Trial 53 finished with value: 0.9324168395900145 and parameters: {'n_estimators': 175, 'max_depth': 17, 'min_samples_split': 19, 'min_samples_leaf': 4, 'max_features': 'sqrt', 'criterion': 'entropy'}. Best is trial 33 with value: 0.9338911474795539.\n",
      "[I 2025-12-23 17:48:29,863] Trial 54 finished with value: 0.9325898591845718 and parameters: {'n_estimators': 252, 'max_depth': 11, 'min_samples_split': 17, 'min_samples_leaf': 3, 'max_features': 'log2', 'criterion': 'entropy'}. Best is trial 33 with value: 0.9338911474795539.\n",
      "[I 2025-12-23 17:48:31,444] Trial 55 finished with value: 0.9260089227164172 and parameters: {'n_estimators': 226, 'max_depth': 10, 'min_samples_split': 15, 'min_samples_leaf': 7, 'max_features': None, 'criterion': 'entropy'}. Best is trial 33 with value: 0.9338911474795539.\n",
      "[I 2025-12-23 17:48:33,544] Trial 56 finished with value: 0.9295585995197928 and parameters: {'n_estimators': 319, 'max_depth': 3, 'min_samples_split': 16, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'criterion': 'entropy'}. Best is trial 33 with value: 0.9338911474795539.\n",
      "[I 2025-12-23 17:48:35,844] Trial 57 finished with value: 0.9324261434436064 and parameters: {'n_estimators': 351, 'max_depth': 16, 'min_samples_split': 12, 'min_samples_leaf': 5, 'max_features': 'log2', 'criterion': 'entropy'}. Best is trial 33 with value: 0.9338911474795539.\n",
      "[I 2025-12-23 17:48:36,499] Trial 58 finished with value: 0.9320823179300017 and parameters: {'n_estimators': 73, 'max_depth': 14, 'min_samples_split': 19, 'min_samples_leaf': 1, 'max_features': 'log2', 'criterion': 'entropy'}. Best is trial 33 with value: 0.9338911474795539.\n",
      "[I 2025-12-23 17:48:38,487] Trial 59 finished with value: 0.933273050778508 and parameters: {'n_estimators': 303, 'max_depth': 22, 'min_samples_split': 14, 'min_samples_leaf': 4, 'max_features': 'sqrt', 'criterion': 'entropy'}. Best is trial 33 with value: 0.9338911474795539.\n",
      "[I 2025-12-23 17:48:39,511] Trial 60 finished with value: 0.9322478302771777 and parameters: {'n_estimators': 136, 'max_depth': 8, 'min_samples_split': 16, 'min_samples_leaf': 8, 'max_features': 'log2', 'criterion': 'entropy'}. Best is trial 33 with value: 0.9338911474795539.\n",
      "[I 2025-12-23 17:48:41,793] Trial 61 finished with value: 0.9333313121513461 and parameters: {'n_estimators': 334, 'max_depth': 19, 'min_samples_split': 15, 'min_samples_leaf': 5, 'max_features': 'log2', 'criterion': 'entropy'}. Best is trial 33 with value: 0.9338911474795539.\n",
      "[I 2025-12-23 17:48:44,228] Trial 62 finished with value: 0.9329891869971909 and parameters: {'n_estimators': 373, 'max_depth': 18, 'min_samples_split': 13, 'min_samples_leaf': 6, 'max_features': 'log2', 'criterion': 'entropy'}. Best is trial 33 with value: 0.9338911474795539.\n",
      "[I 2025-12-23 17:48:46,978] Trial 63 finished with value: 0.9332696500596087 and parameters: {'n_estimators': 415, 'max_depth': 21, 'min_samples_split': 15, 'min_samples_leaf': 4, 'max_features': 'log2', 'criterion': 'entropy'}. Best is trial 33 with value: 0.9338911474795539.\n",
      "[I 2025-12-23 17:48:49,245] Trial 64 finished with value: 0.9329295140051871 and parameters: {'n_estimators': 352, 'max_depth': 20, 'min_samples_split': 17, 'min_samples_leaf': 3, 'max_features': 'log2', 'criterion': 'entropy'}. Best is trial 33 with value: 0.9338911474795539.\n",
      "[I 2025-12-23 17:48:51,861] Trial 65 finished with value: 0.9325944469468602 and parameters: {'n_estimators': 400, 'max_depth': 23, 'min_samples_split': 14, 'min_samples_leaf': 7, 'max_features': 'log2', 'criterion': 'entropy'}. Best is trial 33 with value: 0.9338911474795539.\n",
      "[I 2025-12-23 17:48:53,862] Trial 66 finished with value: 0.9238744262088915 and parameters: {'n_estimators': 288, 'max_depth': 19, 'min_samples_split': 18, 'min_samples_leaf': 14, 'max_features': None, 'criterion': 'entropy'}. Best is trial 33 with value: 0.9338911474795539.\n",
      "[I 2025-12-23 17:48:56,694] Trial 67 finished with value: 0.9332197942372572 and parameters: {'n_estimators': 441, 'max_depth': 24, 'min_samples_split': 13, 'min_samples_leaf': 2, 'max_features': 'log2', 'criterion': 'entropy'}. Best is trial 33 with value: 0.9338911474795539.\n",
      "[I 2025-12-23 17:48:59,663] Trial 68 finished with value: 0.9329315993516818 and parameters: {'n_estimators': 465, 'max_depth': 21, 'min_samples_split': 16, 'min_samples_leaf': 4, 'max_features': 'sqrt', 'criterion': 'entropy'}. Best is trial 33 with value: 0.9338911474795539.\n",
      "[I 2025-12-23 17:49:01,464] Trial 69 finished with value: 0.932364096364824 and parameters: {'n_estimators': 267, 'max_depth': 12, 'min_samples_split': 5, 'min_samples_leaf': 6, 'max_features': 'log2', 'criterion': 'gini'}. Best is trial 33 with value: 0.9338911474795539.\n",
      "[I 2025-12-23 17:49:03,894] Trial 70 finished with value: 0.9335565937372874 and parameters: {'n_estimators': 376, 'max_depth': 17, 'min_samples_split': 15, 'min_samples_leaf': 5, 'max_features': 'log2', 'criterion': 'entropy'}. Best is trial 33 with value: 0.9338911474795539.\n",
      "[I 2025-12-23 17:49:06,379] Trial 71 finished with value: 0.9336131868329296 and parameters: {'n_estimators': 382, 'max_depth': 17, 'min_samples_split': 15, 'min_samples_leaf': 5, 'max_features': 'log2', 'criterion': 'entropy'}. Best is trial 33 with value: 0.9338911474795539.\n",
      "[I 2025-12-23 17:49:08,811] Trial 72 finished with value: 0.9328752949963235 and parameters: {'n_estimators': 380, 'max_depth': 17, 'min_samples_split': 14, 'min_samples_leaf': 3, 'max_features': 'log2', 'criterion': 'entropy'}. Best is trial 33 with value: 0.9338911474795539.\n",
      "[I 2025-12-23 17:49:11,594] Trial 73 finished with value: 0.9330452988590269 and parameters: {'n_estimators': 424, 'max_depth': 15, 'min_samples_split': 15, 'min_samples_leaf': 7, 'max_features': 'log2', 'criterion': 'entropy'}. Best is trial 33 with value: 0.9338911474795539.\n",
      "[I 2025-12-23 17:49:13,964] Trial 74 finished with value: 0.9319279060426284 and parameters: {'n_estimators': 363, 'max_depth': 18, 'min_samples_split': 16, 'min_samples_leaf': 11, 'max_features': 'log2', 'criterion': 'entropy'}. Best is trial 33 with value: 0.9338911474795539.\n",
      "[I 2025-12-23 17:49:16,094] Trial 75 finished with value: 0.9334948995632963 and parameters: {'n_estimators': 324, 'max_depth': 16, 'min_samples_split': 14, 'min_samples_leaf': 5, 'max_features': 'log2', 'criterion': 'entropy'}. Best is trial 33 with value: 0.9338911474795539.\n",
      "[I 2025-12-23 17:49:18,678] Trial 76 finished with value: 0.932543724903657 and parameters: {'n_estimators': 400, 'max_depth': 14, 'min_samples_split': 17, 'min_samples_leaf': 8, 'max_features': 'log2', 'criterion': 'entropy'}. Best is trial 33 with value: 0.9338911474795539.\n",
      "[I 2025-12-23 17:49:21,149] Trial 77 finished with value: 0.9336080215900735 and parameters: {'n_estimators': 378, 'max_depth': 20, 'min_samples_split': 15, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'criterion': 'entropy'}. Best is trial 33 with value: 0.9338911474795539.\n",
      "[I 2025-12-23 17:49:23,818] Trial 78 finished with value: 0.9331655431461398 and parameters: {'n_estimators': 415, 'max_depth': 20, 'min_samples_split': 17, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'criterion': 'entropy'}. Best is trial 33 with value: 0.9338911474795539.\n",
      "[I 2025-12-23 17:49:25,844] Trial 79 finished with value: 0.9323104227542744 and parameters: {'n_estimators': 305, 'max_depth': 22, 'min_samples_split': 18, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'criterion': 'gini'}. Best is trial 33 with value: 0.9338911474795539.\n",
      "[I 2025-12-23 17:49:28,229] Trial 80 finished with value: 0.9318598916646454 and parameters: {'n_estimators': 364, 'max_depth': 10, 'min_samples_split': 13, 'min_samples_leaf': 3, 'max_features': 'sqrt', 'criterion': 'entropy'}. Best is trial 33 with value: 0.9338911474795539.\n",
      "[I 2025-12-23 17:49:30,695] Trial 81 finished with value: 0.93326974630637 and parameters: {'n_estimators': 379, 'max_depth': 18, 'min_samples_split': 15, 'min_samples_leaf': 4, 'max_features': 'sqrt', 'criterion': 'entropy'}. Best is trial 33 with value: 0.9338911474795539.\n",
      "[I 2025-12-23 17:49:32,878] Trial 82 finished with value: 0.933723710197152 and parameters: {'n_estimators': 342, 'max_depth': 21, 'min_samples_split': 16, 'min_samples_leaf': 6, 'max_features': 'sqrt', 'criterion': 'entropy'}. Best is trial 33 with value: 0.9338911474795539.\n",
      "[I 2025-12-23 17:49:35,061] Trial 83 finished with value: 0.9334404559786563 and parameters: {'n_estimators': 336, 'max_depth': 24, 'min_samples_split': 16, 'min_samples_leaf': 6, 'max_features': 'sqrt', 'criterion': 'entropy'}. Best is trial 33 with value: 0.9338911474795539.\n",
      "[I 2025-12-23 17:49:37,294] Trial 84 finished with value: 0.9338846026997858 and parameters: {'n_estimators': 348, 'max_depth': 20, 'min_samples_split': 16, 'min_samples_leaf': 3, 'max_features': 'sqrt', 'criterion': 'entropy'}. Best is trial 33 with value: 0.9338911474795539.\n",
      "[I 2025-12-23 17:49:39,661] Trial 85 finished with value: 0.9337733093614734 and parameters: {'n_estimators': 350, 'max_depth': 21, 'min_samples_split': 16, 'min_samples_leaf': 3, 'max_features': 'sqrt', 'criterion': 'entropy'}. Best is trial 33 with value: 0.9338911474795539.\n",
      "[I 2025-12-23 17:49:41,929] Trial 86 finished with value: 0.9337733093614734 and parameters: {'n_estimators': 350, 'max_depth': 21, 'min_samples_split': 16, 'min_samples_leaf': 3, 'max_features': 'sqrt', 'criterion': 'entropy'}. Best is trial 33 with value: 0.9338911474795539.\n",
      "[I 2025-12-23 17:49:44,194] Trial 87 finished with value: 0.9328729209095448 and parameters: {'n_estimators': 350, 'max_depth': 23, 'min_samples_split': 17, 'min_samples_leaf': 3, 'max_features': 'sqrt', 'criterion': 'entropy'}. Best is trial 33 with value: 0.9338911474795539.\n",
      "[I 2025-12-23 17:49:46,278] Trial 88 finished with value: 0.9326412870373577 and parameters: {'n_estimators': 312, 'max_depth': 22, 'min_samples_split': 18, 'min_samples_leaf': 4, 'max_features': 'sqrt', 'criterion': 'entropy'}. Best is trial 33 with value: 0.9338911474795539.\n",
      "[I 2025-12-23 17:49:48,195] Trial 89 finished with value: 0.9335437608357811 and parameters: {'n_estimators': 290, 'max_depth': 19, 'min_samples_split': 16, 'min_samples_leaf': 3, 'max_features': 'sqrt', 'criterion': 'entropy'}. Best is trial 33 with value: 0.9338911474795539.\n",
      "[I 2025-12-23 17:49:50,378] Trial 90 finished with value: 0.9332749436314801 and parameters: {'n_estimators': 327, 'max_depth': 25, 'min_samples_split': 17, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'criterion': 'entropy'}. Best is trial 33 with value: 0.9338911474795539.\n",
      "[I 2025-12-23 17:49:52,696] Trial 91 finished with value: 0.934566575168079 and parameters: {'n_estimators': 356, 'max_depth': 20, 'min_samples_split': 16, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'criterion': 'entropy'}. Best is trial 91 with value: 0.934566575168079.\n",
      "[I 2025-12-23 17:49:55,203] Trial 92 finished with value: 0.9341719313645095 and parameters: {'n_estimators': 393, 'max_depth': 21, 'min_samples_split': 16, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'criterion': 'entropy'}. Best is trial 91 with value: 0.934566575168079.\n",
      "[I 2025-12-23 17:49:57,599] Trial 93 finished with value: 0.934566575168079 and parameters: {'n_estimators': 356, 'max_depth': 21, 'min_samples_split': 16, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'criterion': 'entropy'}. Best is trial 91 with value: 0.934566575168079.\n",
      "[I 2025-12-23 17:49:59,878] Trial 94 finished with value: 0.9345666714148402 and parameters: {'n_estimators': 357, 'max_depth': 21, 'min_samples_split': 16, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'criterion': 'entropy'}. Best is trial 94 with value: 0.9345666714148402.\n",
      "[I 2025-12-23 17:50:02,161] Trial 95 finished with value: 0.9347939421005151 and parameters: {'n_estimators': 358, 'max_depth': 23, 'min_samples_split': 16, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'criterion': 'entropy'}. Best is trial 95 with value: 0.9347939421005151.\n",
      "[I 2025-12-23 17:50:04,464] Trial 96 finished with value: 0.9325879021670922 and parameters: {'n_estimators': 358, 'max_depth': 23, 'min_samples_split': 19, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'criterion': 'entropy'}. Best is trial 95 with value: 0.9347939421005151.\n",
      "[I 2025-12-23 17:50:07,063] Trial 97 finished with value: 0.9327058365319342 and parameters: {'n_estimators': 395, 'max_depth': 24, 'min_samples_split': 17, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'criterion': 'entropy'}. Best is trial 95 with value: 0.9347939421005151.\n",
      "[I 2025-12-23 17:50:09,161] Trial 98 finished with value: 0.9322533163425717 and parameters: {'n_estimators': 317, 'max_depth': 21, 'min_samples_split': 18, 'min_samples_leaf': 3, 'max_features': 'sqrt', 'criterion': 'gini'}. Best is trial 95 with value: 0.9347939421005151.\n",
      "[I 2025-12-23 17:50:11,428] Trial 99 finished with value: 0.934626761476143 and parameters: {'n_estimators': 348, 'max_depth': 25, 'min_samples_split': 16, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'criterion': 'entropy'}. Best is trial 95 with value: 0.9347939421005151.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[64 14]\n",
      " [ 8 64]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.82      0.85        78\n",
      "           1       0.82      0.89      0.85        72\n",
      "\n",
      "    accuracy                           0.85       150\n",
      "   macro avg       0.85      0.85      0.85       150\n",
      "weighted avg       0.86      0.85      0.85       150\n",
      "\n",
      "ROC-AUC Score: 0.9382\n",
      "score in training 0.9077181208053692\n",
      "score in testing 0.8533333333333334\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 358,\n",
       " 'max_depth': 23,\n",
       " 'min_samples_split': 16,\n",
       " 'min_samples_leaf': 2,\n",
       " 'max_features': 'sqrt',\n",
       " 'criterion': 'entropy'}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_forest_optuna(df, \"HeartDisease\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "c86e31a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_auc_score\n",
    "\n",
    "def svc_optuna(df, target):\n",
    "    X = df.drop(columns=[target])\n",
    "    y = df[target]\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42, stratify=y)\n",
    "    \n",
    "    col_num = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "    col_cat = X.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "    \n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', StandardScaler(), col_num),\n",
    "            ('cat', OneHotEncoder(handle_unknown='ignore'), col_cat)\n",
    "        ])\n",
    "    \n",
    "    def objective(trial):\n",
    "        C = trial.suggest_float('C', 1e-3, 1e3, log=True)\n",
    "        kernel = trial.suggest_categorical('kernel', ['linear', 'poly', 'rbf', 'sigmoid'])\n",
    "        gamma = trial.suggest_categorical('gamma', ['scale', 'auto'])\n",
    "        \n",
    "        model = SVC(\n",
    "            C=C,\n",
    "            kernel=kernel,\n",
    "            gamma=gamma,\n",
    "            probability=True,\n",
    "            random_state=42\n",
    "        )\n",
    "        \n",
    "        pipe = Pipeline(steps=[('preprocessor', preprocessor), ('model', model)])\n",
    "        score = cross_val_score(pipe, X_train, y_train, cv=5, scoring='roc_auc').mean()\n",
    "        return score\n",
    "\n",
    "    study = optuna.create_study(direction='maximize')\n",
    "    study.optimize(lambda trial: objective(trial), n_trials=50)\n",
    "\n",
    "    best_model = SVC(\n",
    "        C=study.best_params['C'],\n",
    "        kernel=study.best_params['kernel'],\n",
    "        gamma=study.best_params['gamma'],\n",
    "        probability=True,\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    best_pipe = Pipeline(steps=[('preprocessor', preprocessor), ('model', best_model)])\n",
    "    best_pipe.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = best_pipe.predict(X_test)\n",
    "    y_proba = best_pipe.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    print(\"--- SVC OPTIMIZADO ---\")\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(f\"ROC-AUC Score: {roc_auc_score(y_test, y_proba):.4f}\")\n",
    "    print(\"score in training\", best_pipe.score(X_train, y_train))\n",
    "    print(\"score in testing\", best_pipe.score(X_test, y_test))\n",
    "    \n",
    "    return study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f3735473",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-23 21:15:22,630] A new study created in memory with name: no-name-92ebfd46-fc97-44ef-b580-447c445d1a08\n",
      "[I 2025-12-23 21:15:22,909] Trial 0 finished with value: 0.9193972514491554 and parameters: {'C': 0.6277402379423255, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 0 with value: 0.9193972514491554.\n",
      "[I 2025-12-23 21:15:23,059] Trial 1 finished with value: 0.8337254105566014 and parameters: {'C': 54.653013212662174, 'kernel': 'sigmoid', 'gamma': 'scale'}. Best is trial 0 with value: 0.9193972514491554.\n",
      "[I 2025-12-23 21:15:23,247] Trial 2 finished with value: 0.899053733925187 and parameters: {'C': 36.90103196186415, 'kernel': 'poly', 'gamma': 'auto'}. Best is trial 0 with value: 0.9193972514491554.\n",
      "[I 2025-12-23 21:15:23,432] Trial 3 finished with value: 0.9210207739009582 and parameters: {'C': 0.8724655790443231, 'kernel': 'poly', 'gamma': 'scale'}. Best is trial 3 with value: 0.9210207739009582.\n",
      "[I 2025-12-23 21:15:23,788] Trial 4 finished with value: 0.906673782510552 and parameters: {'C': 0.017003794806579195, 'kernel': 'rbf', 'gamma': 'auto'}. Best is trial 3 with value: 0.9210207739009582.\n",
      "[I 2025-12-23 21:15:23,961] Trial 5 finished with value: 0.927137480157126 and parameters: {'C': 0.05775113178732997, 'kernel': 'linear', 'gamma': 'auto'}. Best is trial 5 with value: 0.927137480157126.\n",
      "[I 2025-12-23 21:15:24,164] Trial 6 finished with value: 0.8726201704979294 and parameters: {'C': 15.512599296434757, 'kernel': 'sigmoid', 'gamma': 'auto'}. Best is trial 5 with value: 0.927137480157126.\n",
      "[I 2025-12-23 21:15:24,327] Trial 7 finished with value: 0.83776527211526 and parameters: {'C': 18.36676240596818, 'kernel': 'sigmoid', 'gamma': 'scale'}. Best is trial 5 with value: 0.927137480157126.\n",
      "[I 2025-12-23 21:15:24,559] Trial 8 finished with value: 0.9212659144019802 and parameters: {'C': 6.063063179095542, 'kernel': 'rbf', 'gamma': 'auto'}. Best is trial 5 with value: 0.927137480157126.\n",
      "[I 2025-12-23 21:15:24,794] Trial 9 finished with value: 0.8477280951995965 and parameters: {'C': 828.737654554956, 'kernel': 'poly', 'gamma': 'scale'}. Best is trial 5 with value: 0.927137480157126.\n",
      "[I 2025-12-23 21:15:24,999] Trial 10 finished with value: 0.9083200512802744 and parameters: {'C': 0.0013885415853724335, 'kernel': 'linear', 'gamma': 'auto'}. Best is trial 5 with value: 0.927137480157126.\n",
      "[I 2025-12-23 21:15:25,147] Trial 11 finished with value: 0.9271402713132038 and parameters: {'C': 0.05186825226792335, 'kernel': 'linear', 'gamma': 'auto'}. Best is trial 11 with value: 0.9271402713132038.\n",
      "[I 2025-12-23 21:15:25,297] Trial 12 finished with value: 0.9271969606556073 and parameters: {'C': 0.052290788496704495, 'kernel': 'linear', 'gamma': 'auto'}. Best is trial 12 with value: 0.9271969606556073.\n",
      "[I 2025-12-23 21:15:25,451] Trial 13 finished with value: 0.9271393730100982 and parameters: {'C': 0.05291014124456095, 'kernel': 'linear', 'gamma': 'auto'}. Best is trial 12 with value: 0.9271969606556073.\n",
      "[I 2025-12-23 21:15:25,628] Trial 14 finished with value: 0.9212416923003873 and parameters: {'C': 0.004110931148489647, 'kernel': 'linear', 'gamma': 'auto'}. Best is trial 12 with value: 0.9271969606556073.\n",
      "[I 2025-12-23 21:15:25,779] Trial 15 finished with value: 0.9262721255263093 and parameters: {'C': 0.18420326498034606, 'kernel': 'linear', 'gamma': 'auto'}. Best is trial 12 with value: 0.9271969606556073.\n",
      "[I 2025-12-23 21:15:25,945] Trial 16 finished with value: 0.925632052481434 and parameters: {'C': 0.01630140691509727, 'kernel': 'linear', 'gamma': 'auto'}. Best is trial 12 with value: 0.9271969606556073.\n",
      "[I 2025-12-23 21:15:26,103] Trial 17 finished with value: 0.9255311537933416 and parameters: {'C': 0.23396976159519647, 'kernel': 'linear', 'gamma': 'auto'}. Best is trial 12 with value: 0.9271969606556073.\n",
      "[I 2025-12-23 21:15:26,349] Trial 18 finished with value: 0.9238212979966558 and parameters: {'C': 2.3721678222164453, 'kernel': 'linear', 'gamma': 'auto'}. Best is trial 12 with value: 0.9271969606556073.\n",
      "[I 2025-12-23 21:15:26,511] Trial 19 finished with value: 0.9234387492027558 and parameters: {'C': 0.007506154522906636, 'kernel': 'linear', 'gamma': 'auto'}. Best is trial 12 with value: 0.9271969606556073.\n",
      "[I 2025-12-23 21:15:26,662] Trial 20 finished with value: 0.9278030906759988 and parameters: {'C': 0.09821453794270588, 'kernel': 'linear', 'gamma': 'auto'}. Best is trial 20 with value: 0.9278030906759988.\n",
      "[I 2025-12-23 21:15:26,814] Trial 21 finished with value: 0.9283691178791834 and parameters: {'C': 0.08645083712170273, 'kernel': 'linear', 'gamma': 'auto'}. Best is trial 21 with value: 0.9283691178791834.\n",
      "[I 2025-12-23 21:15:26,970] Trial 22 finished with value: 0.9262153399371446 and parameters: {'C': 0.18840627529235257, 'kernel': 'linear', 'gamma': 'auto'}. Best is trial 21 with value: 0.9283691178791834.\n",
      "[I 2025-12-23 21:15:27,120] Trial 23 finished with value: 0.9283204170179674 and parameters: {'C': 0.07305703675355153, 'kernel': 'linear', 'gamma': 'auto'}. Best is trial 21 with value: 0.9283691178791834.\n",
      "[I 2025-12-23 21:15:27,283] Trial 24 finished with value: 0.9253565942506035 and parameters: {'C': 0.3857363258150334, 'kernel': 'linear', 'gamma': 'auto'}. Best is trial 21 with value: 0.9283691178791834.\n",
      "[I 2025-12-23 21:15:27,612] Trial 25 finished with value: 0.923708111805371 and parameters: {'C': 3.485483757779513, 'kernel': 'linear', 'gamma': 'auto'}. Best is trial 21 with value: 0.9283691178791834.\n",
      "[I 2025-12-23 21:15:27,968] Trial 26 finished with value: 0.9041864774583669 and parameters: {'C': 0.0013116622396353974, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 21 with value: 0.9283691178791834.\n",
      "[I 2025-12-23 21:15:28,245] Trial 27 finished with value: 0.9030069413164247 and parameters: {'C': 0.018690915204331696, 'kernel': 'sigmoid', 'gamma': 'auto'}. Best is trial 21 with value: 0.9283691178791834.\n",
      "[I 2025-12-23 21:15:28,461] Trial 28 finished with value: 0.9016149244077937 and parameters: {'C': 0.08470215506349223, 'kernel': 'poly', 'gamma': 'auto'}. Best is trial 21 with value: 0.9283691178791834.\n",
      "[I 2025-12-23 21:15:28,698] Trial 29 finished with value: 0.9192261567898241 and parameters: {'C': 1.145720993331793, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 21 with value: 0.9283691178791834.\n",
      "[I 2025-12-23 21:15:28,867] Trial 30 finished with value: 0.9202848069995777 and parameters: {'C': 0.003854789698105354, 'kernel': 'linear', 'gamma': 'auto'}. Best is trial 21 with value: 0.9283691178791834.\n",
      "[I 2025-12-23 21:15:29,014] Trial 31 finished with value: 0.9273512442139656 and parameters: {'C': 0.10908042647609854, 'kernel': 'linear', 'gamma': 'auto'}. Best is trial 21 with value: 0.9283691178791834.\n",
      "[I 2025-12-23 21:15:29,190] Trial 32 finished with value: 0.9255794696675125 and parameters: {'C': 0.5354310646474947, 'kernel': 'linear', 'gamma': 'auto'}. Best is trial 21 with value: 0.9283691178791834.\n",
      "[I 2025-12-23 21:15:29,337] Trial 33 finished with value: 0.9282559316878988 and parameters: {'C': 0.0843346216478659, 'kernel': 'linear', 'gamma': 'auto'}. Best is trial 21 with value: 0.9283691178791834.\n",
      "[I 2025-12-23 21:15:29,484] Trial 34 finished with value: 0.9264178110406585 and parameters: {'C': 0.02650100703279431, 'kernel': 'linear', 'gamma': 'scale'}. Best is trial 21 with value: 0.9283691178791834.\n",
      "[I 2025-12-23 21:15:29,674] Trial 35 finished with value: 0.9194269596161423 and parameters: {'C': 0.933410487094681, 'kernel': 'poly', 'gamma': 'auto'}. Best is trial 21 with value: 0.9283691178791834.\n",
      "[I 2025-12-23 21:15:29,947] Trial 36 finished with value: 0.9028937551251399 and parameters: {'C': 0.007332974978393943, 'kernel': 'sigmoid', 'gamma': 'auto'}. Best is trial 21 with value: 0.9283691178791834.\n",
      "[I 2025-12-23 21:15:30,100] Trial 37 finished with value: 0.9255842499233236 and parameters: {'C': 0.3405342648972353, 'kernel': 'linear', 'gamma': 'auto'}. Best is trial 21 with value: 0.9283691178791834.\n",
      "[I 2025-12-23 21:15:30,249] Trial 38 finished with value: 0.927633407635833 and parameters: {'C': 0.11613391125123218, 'kernel': 'linear', 'gamma': 'scale'}. Best is trial 21 with value: 0.9283691178791834.\n",
      "[I 2025-12-23 21:15:30,588] Trial 39 finished with value: 0.8748674361274409 and parameters: {'C': 150.0564550436844, 'kernel': 'rbf', 'gamma': 'auto'}. Best is trial 21 with value: 0.9283691178791834.\n",
      "[I 2025-12-23 21:15:30,851] Trial 40 finished with value: 0.9100111389585074 and parameters: {'C': 0.03116490514848966, 'kernel': 'sigmoid', 'gamma': 'auto'}. Best is trial 21 with value: 0.9283691178791834.\n",
      "[I 2025-12-23 21:15:31,000] Trial 41 finished with value: 0.9272372880485905 and parameters: {'C': 0.12775352774537507, 'kernel': 'linear', 'gamma': 'scale'}. Best is trial 21 with value: 0.9283691178791834.\n",
      "[I 2025-12-23 21:15:31,219] Trial 42 finished with value: 0.9233721464439387 and parameters: {'C': 1.6616285112180447, 'kernel': 'linear', 'gamma': 'scale'}. Best is trial 21 with value: 0.9283691178791834.\n",
      "[I 2025-12-23 21:15:31,378] Trial 43 finished with value: 0.9285956827552753 and parameters: {'C': 0.08832432287624255, 'kernel': 'linear', 'gamma': 'scale'}. Best is trial 43 with value: 0.9285956827552753.\n",
      "[I 2025-12-23 21:15:31,616] Trial 44 finished with value: 0.9012761678902839 and parameters: {'C': 0.010249386026194568, 'kernel': 'poly', 'gamma': 'scale'}. Best is trial 43 with value: 0.9285956827552753.\n",
      "[I 2025-12-23 21:15:31,768] Trial 45 finished with value: 0.9268158555631268 and parameters: {'C': 0.03832958043650458, 'kernel': 'linear', 'gamma': 'scale'}. Best is trial 43 with value: 0.9285956827552753.\n",
      "[I 2025-12-23 21:15:31,944] Trial 46 finished with value: 0.9254659947359437 and parameters: {'C': 0.5735989423936064, 'kernel': 'linear', 'gamma': 'scale'}. Best is trial 43 with value: 0.9285956827552753.\n",
      "[I 2025-12-23 21:15:32,103] Trial 47 finished with value: 0.9275299423674394 and parameters: {'C': 0.06618621717579237, 'kernel': 'linear', 'gamma': 'auto'}. Best is trial 43 with value: 0.9285956827552753.\n",
      "[I 2025-12-23 21:15:32,255] Trial 48 finished with value: 0.9254152726927405 and parameters: {'C': 0.2557922743414763, 'kernel': 'linear', 'gamma': 'auto'}. Best is trial 43 with value: 0.9285956827552753.\n",
      "[I 2025-12-23 21:15:32,593] Trial 49 finished with value: 0.9042438726103533 and parameters: {'C': 0.017166009403056588, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 43 with value: 0.9285956827552753.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- SVC OPTIMIZADO ---\n",
      "[[65 13]\n",
      " [10 62]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.83      0.85        78\n",
      "           1       0.83      0.86      0.84        72\n",
      "\n",
      "    accuracy                           0.85       150\n",
      "   macro avg       0.85      0.85      0.85       150\n",
      "weighted avg       0.85      0.85      0.85       150\n",
      "\n",
      "ROC-AUC Score: 0.9183\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'C': 0.08832432287624255, 'kernel': 'linear', 'gamma': 'scale'}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_optuna(df, \"HeartDisease\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "e985c59e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-23 21:40:15,095] A new study created in memory with name: no-name-84f44cf2-9a3c-415b-bff5-482896d5d32d\n",
      "[I 2025-12-23 21:40:15,714] Trial 0 finished with value: 0.9222547786720323 and parameters: {'C': 4.494250614730379, 'solver': 'saga', 'penalty_saga': 'elasticnet', 'l1_ratio': 0.45882931724670584}. Best is trial 0 with value: 0.9222547786720323.\n",
      "[I 2025-12-23 21:40:15,790] Trial 1 finished with value: 0.8992593058350099 and parameters: {'C': 0.00046594335409821377, 'solver': 'liblinear', 'penalty_lib': 'l2'}. Best is trial 0 with value: 0.9222547786720323.\n",
      "[I 2025-12-23 21:40:15,872] Trial 2 finished with value: 0.8981922786720322 and parameters: {'C': 1.7455005376426353e-05, 'solver': 'saga', 'penalty_saga': 'l2'}. Best is trial 0 with value: 0.9222547786720323.\n",
      "C:\\Users\\APUESTAS\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\APUESTAS\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\APUESTAS\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\APUESTAS\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\APUESTAS\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "[I 2025-12-23 21:40:15,971] Trial 3 finished with value: 0.9221202213279678 and parameters: {'C': 52.337505839256224, 'solver': 'lbfgs', 'penalty_lbfgs': None}. Best is trial 0 with value: 0.9222547786720323.\n",
      "[I 2025-12-23 21:40:16,074] Trial 4 finished with value: 0.9237990442655934 and parameters: {'C': 0.07942840920412854, 'solver': 'saga', 'penalty_saga': 'l2'}. Best is trial 4 with value: 0.9237990442655934.\n",
      "[I 2025-12-23 21:40:16,151] Trial 5 finished with value: 0.5 and parameters: {'C': 0.0002854331824794115, 'solver': 'saga', 'penalty_saga': 'l1'}. Best is trial 4 with value: 0.9237990442655934.\n",
      "C:\\Users\\APUESTAS\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\APUESTAS\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\APUESTAS\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\APUESTAS\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\APUESTAS\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "[I 2025-12-23 21:40:16,251] Trial 6 finished with value: 0.9221202213279678 and parameters: {'C': 30.13482993761462, 'solver': 'lbfgs', 'penalty_lbfgs': None}. Best is trial 4 with value: 0.9237990442655934.\n",
      "C:\\Users\\APUESTAS\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\APUESTAS\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\APUESTAS\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\APUESTAS\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\APUESTAS\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "[I 2025-12-23 21:40:16,344] Trial 7 finished with value: 0.9219416498993963 and parameters: {'C': 0.007518878882256855, 'solver': 'saga', 'penalty_saga': None}. Best is trial 4 with value: 0.9237990442655934.\n",
      "[I 2025-12-23 21:40:16,419] Trial 8 finished with value: 0.5 and parameters: {'C': 0.003167846351336946, 'solver': 'liblinear', 'penalty_lib': 'l1'}. Best is trial 4 with value: 0.9237990442655934.\n",
      "[I 2025-12-23 21:40:16,494] Trial 9 finished with value: 0.9013524899396378 and parameters: {'C': 0.0011567021582304625, 'solver': 'liblinear', 'penalty_lib': 'l2'}. Best is trial 4 with value: 0.9237990442655934.\n",
      "[I 2025-12-23 21:40:16,622] Trial 10 finished with value: 0.9235167253521126 and parameters: {'C': 0.24248472274186525, 'solver': 'saga', 'penalty_saga': 'l2'}. Best is trial 4 with value: 0.9237990442655934.\n",
      "[I 2025-12-23 21:40:16,759] Trial 11 finished with value: 0.9234727112676057 and parameters: {'C': 0.23936047581821568, 'solver': 'saga', 'penalty_saga': 'l2'}. Best is trial 4 with value: 0.9237990442655934.\n",
      "[I 2025-12-23 21:40:16,888] Trial 12 finished with value: 0.9235173541247486 and parameters: {'C': 0.2357073771607043, 'solver': 'saga', 'penalty_saga': 'l2'}. Best is trial 4 with value: 0.9237990442655934.\n",
      "[I 2025-12-23 21:40:17,003] Trial 13 finished with value: 0.922986041247485 and parameters: {'C': 0.13956501556383002, 'solver': 'saga', 'penalty_saga': 'l2'}. Best is trial 4 with value: 0.9237990442655934.\n",
      "[I 2025-12-23 21:40:17,278] Trial 14 finished with value: 0.9224773641851106 and parameters: {'C': 2.5341282138494994, 'solver': 'saga', 'penalty_saga': 'l2'}. Best is trial 4 with value: 0.9237990442655934.\n",
      "[I 2025-12-23 21:40:17,375] Trial 15 finished with value: 0.9234431589537223 and parameters: {'C': 0.06780352427986847, 'solver': 'lbfgs', 'penalty_lbfgs': 'l2'}. Best is trial 4 with value: 0.9237990442655934.\n",
      "[I 2025-12-23 21:40:17,544] Trial 16 finished with value: 0.923193536217304 and parameters: {'C': 1.8061344117014273, 'solver': 'saga', 'penalty_saga': 'l1'}. Best is trial 4 with value: 0.9237990442655934.\n",
      "C:\\Users\\APUESTAS\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\APUESTAS\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\APUESTAS\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\APUESTAS\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\APUESTAS\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "[I 2025-12-23 21:40:17,638] Trial 17 finished with value: 0.9219416498993963 and parameters: {'C': 0.017501441543360932, 'solver': 'saga', 'penalty_saga': None}. Best is trial 4 with value: 0.9237990442655934.\n",
      "[I 2025-12-23 21:40:17,720] Trial 18 finished with value: 0.924935236418511 and parameters: {'C': 0.5737136214348315, 'solver': 'liblinear', 'penalty_lib': 'l1'}. Best is trial 18 with value: 0.924935236418511.\n",
      "[I 2025-12-23 21:40:17,812] Trial 19 finished with value: 0.9222088782696176 and parameters: {'C': 8.596345836646687, 'solver': 'liblinear', 'penalty_lib': 'l1'}. Best is trial 18 with value: 0.924935236418511.\n",
      "[I 2025-12-23 21:40:17,893] Trial 20 finished with value: 0.924891222334004 and parameters: {'C': 0.6482565623875923, 'solver': 'liblinear', 'penalty_lib': 'l1'}. Best is trial 18 with value: 0.924935236418511.\n",
      "[I 2025-12-23 21:40:17,974] Trial 21 finished with value: 0.9237292505030181 and parameters: {'C': 1.242667156700718, 'solver': 'liblinear', 'penalty_lib': 'l1'}. Best is trial 18 with value: 0.924935236418511.\n",
      "[I 2025-12-23 21:40:18,054] Trial 22 finished with value: 0.9248899647887324 and parameters: {'C': 0.6833432284942313, 'solver': 'liblinear', 'penalty_lib': 'l1'}. Best is trial 18 with value: 0.924935236418511.\n",
      "[I 2025-12-23 21:40:18,135] Trial 23 finished with value: 0.9241316649899396 and parameters: {'C': 0.9646445825687759, 'solver': 'liblinear', 'penalty_lib': 'l1'}. Best is trial 18 with value: 0.924935236418511.\n",
      "[I 2025-12-23 21:40:18,247] Trial 24 finished with value: 0.922119592555332 and parameters: {'C': 21.066865667504963, 'solver': 'liblinear', 'penalty_lib': 'l1'}. Best is trial 18 with value: 0.924935236418511.\n",
      "[I 2025-12-23 21:40:18,322] Trial 25 finished with value: 0.9248905935613683 and parameters: {'C': 0.6085312272352562, 'solver': 'liblinear', 'penalty_lib': 'l1'}. Best is trial 18 with value: 0.924935236418511.\n",
      "[I 2025-12-23 21:40:18,400] Trial 26 finished with value: 0.8818429325955736 and parameters: {'C': 0.02547207095422034, 'solver': 'liblinear', 'penalty_lib': 'l1'}. Best is trial 18 with value: 0.924935236418511.\n",
      "[I 2025-12-23 21:40:18,480] Trial 27 finished with value: 0.9246221076458753 and parameters: {'C': 0.48572272364342345, 'solver': 'liblinear', 'penalty_lib': 'l1'}. Best is trial 18 with value: 0.924935236418511.\n",
      "[I 2025-12-23 21:40:18,570] Trial 28 finished with value: 0.9223428068410463 and parameters: {'C': 6.151746380911417, 'solver': 'liblinear', 'penalty_lib': 'l1'}. Best is trial 18 with value: 0.924935236418511.\n",
      "[I 2025-12-23 21:40:18,649] Trial 29 finished with value: 0.9221648641851108 and parameters: {'C': 9.701627077991668, 'solver': 'liblinear', 'penalty_lib': 'l2'}. Best is trial 18 with value: 0.924935236418511.\n",
      "[I 2025-12-23 21:40:18,769] Trial 30 finished with value: 0.9219862927565392 and parameters: {'C': 85.40001444530206, 'solver': 'liblinear', 'penalty_lib': 'l1'}. Best is trial 18 with value: 0.924935236418511.\n",
      "[I 2025-12-23 21:40:18,848] Trial 31 finished with value: 0.9248905935613683 and parameters: {'C': 0.6085387265956248, 'solver': 'liblinear', 'penalty_lib': 'l1'}. Best is trial 18 with value: 0.924935236418511.\n",
      "[I 2025-12-23 21:40:18,930] Trial 32 finished with value: 0.9226999496981891 and parameters: {'C': 3.4059998505978313, 'solver': 'liblinear', 'penalty_lib': 'l1'}. Best is trial 18 with value: 0.924935236418511.\n",
      "[I 2025-12-23 21:40:19,005] Trial 33 finished with value: 0.8984978621730383 and parameters: {'C': 0.036020616190932414, 'solver': 'liblinear', 'penalty_lib': 'l1'}. Best is trial 18 with value: 0.924935236418511.\n",
      "[I 2025-12-23 21:40:19,088] Trial 34 finished with value: 0.924622736418511 and parameters: {'C': 0.4175263255882072, 'solver': 'liblinear', 'penalty_lib': 'l1'}. Best is trial 18 with value: 0.924935236418511.\n",
      "[I 2025-12-23 21:40:19,185] Trial 35 finished with value: 0.9238889587525151 and parameters: {'C': 0.074159376910272, 'solver': 'lbfgs', 'penalty_lbfgs': 'l2'}. Best is trial 18 with value: 0.924935236418511.\n",
      "[I 2025-12-23 21:40:19,270] Trial 36 finished with value: 0.9230137072434607 and parameters: {'C': 1.9463744103219154, 'solver': 'liblinear', 'penalty_lib': 'l1'}. Best is trial 18 with value: 0.924935236418511.\n",
      "[I 2025-12-23 21:40:19,351] Trial 37 finished with value: 0.9248905935613683 and parameters: {'C': 0.6818227797418892, 'solver': 'liblinear', 'penalty_lib': 'l1'}. Best is trial 18 with value: 0.924935236418511.\n",
      "[I 2025-12-23 21:40:19,438] Trial 38 finished with value: 0.8981476358148892 and parameters: {'C': 1.0754363039137913e-05, 'solver': 'lbfgs', 'penalty_lbfgs': 'l2'}. Best is trial 18 with value: 0.924935236418511.\n",
      "[I 2025-12-23 21:40:19,514] Trial 39 finished with value: 0.5 and parameters: {'C': 0.000139469492317199, 'solver': 'liblinear', 'penalty_lib': 'l1'}. Best is trial 18 with value: 0.924935236418511.\n",
      "[I 2025-12-23 21:40:19,594] Trial 40 finished with value: 0.9128269617706237 and parameters: {'C': 0.007551154925004249, 'solver': 'liblinear', 'penalty_lib': 'l2'}. Best is trial 18 with value: 0.924935236418511.\n",
      "[I 2025-12-23 21:40:19,678] Trial 41 finished with value: 0.9244881790744467 and parameters: {'C': 0.8912367759425919, 'solver': 'liblinear', 'penalty_lib': 'l1'}. Best is trial 18 with value: 0.924935236418511.\n",
      "[I 2025-12-23 21:40:19,787] Trial 42 finished with value: 0.9220749496981892 and parameters: {'C': 18.539859007403937, 'solver': 'liblinear', 'penalty_lib': 'l1'}. Best is trial 18 with value: 0.924935236418511.\n",
      "[I 2025-12-23 21:40:19,869] Trial 43 finished with value: 0.9240530684104626 and parameters: {'C': 0.17210484827324316, 'solver': 'liblinear', 'penalty_lib': 'l1'}. Best is trial 18 with value: 0.924935236418511.\n",
      "[I 2025-12-23 21:40:19,952] Trial 44 finished with value: 0.9245328219315896 and parameters: {'C': 0.4501445401059328, 'solver': 'liblinear', 'penalty_lib': 'l1'}. Best is trial 18 with value: 0.924935236418511.\n",
      "[I 2025-12-23 21:40:20,043] Trial 45 finished with value: 0.922432092555332 and parameters: {'C': 5.068213341541569, 'solver': 'liblinear', 'penalty_lib': 'l1'}. Best is trial 18 with value: 0.924935236418511.\n",
      "C:\\Users\\APUESTAS\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\APUESTAS\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\APUESTAS\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\APUESTAS\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\APUESTAS\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "[I 2025-12-23 21:40:20,148] Trial 46 finished with value: 0.9221202213279678 and parameters: {'C': 0.09020697337460351, 'solver': 'lbfgs', 'penalty_lbfgs': None}. Best is trial 18 with value: 0.924935236418511.\n",
      "[I 2025-12-23 21:40:20,228] Trial 47 finished with value: 0.9243995221327967 and parameters: {'C': 0.3026419879333957, 'solver': 'liblinear', 'penalty_lib': 'l1'}. Best is trial 18 with value: 0.924935236418511.\n",
      "[I 2025-12-23 21:40:20,309] Trial 48 finished with value: 0.9226119215291751 and parameters: {'C': 3.0075952345843637, 'solver': 'liblinear', 'penalty_lib': 'l1'}. Best is trial 18 with value: 0.924935236418511.\n",
      "[I 2025-12-23 21:40:20,379] Trial 49 finished with value: 0.922768485915493 and parameters: {'C': 0.13376327988872352, 'solver': 'liblinear', 'penalty_lib': 'l2'}. Best is trial 18 with value: 0.924935236418511.\n",
      "C:\\Users\\APUESTAS\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\APUESTAS\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\APUESTAS\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\APUESTAS\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\APUESTAS\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "[I 2025-12-23 21:40:20,485] Trial 50 finished with value: 0.9221202213279678 and parameters: {'C': 1.2995132468196033, 'solver': 'lbfgs', 'penalty_lbfgs': None}. Best is trial 18 with value: 0.924935236418511.\n",
      "[I 2025-12-23 21:40:20,574] Trial 51 finished with value: 0.9244888078470825 and parameters: {'C': 0.8286595067093864, 'solver': 'liblinear', 'penalty_lib': 'l1'}. Best is trial 18 with value: 0.924935236418511.\n",
      "[I 2025-12-23 21:40:20,655] Trial 52 finished with value: 0.924935236418511 and parameters: {'C': 0.5681540510949098, 'solver': 'liblinear', 'penalty_lib': 'l1'}. Best is trial 18 with value: 0.924935236418511.\n",
      "[I 2025-12-23 21:40:20,728] Trial 53 finished with value: 0.8964040492957747 and parameters: {'C': 0.033924509708355276, 'solver': 'liblinear', 'penalty_lib': 'l1'}. Best is trial 18 with value: 0.924935236418511.\n",
      "[I 2025-12-23 21:40:20,811] Trial 54 finished with value: 0.9245774647887324 and parameters: {'C': 0.2857365875872263, 'solver': 'liblinear', 'penalty_lib': 'l1'}. Best is trial 18 with value: 0.924935236418511.\n",
      "[I 2025-12-23 21:40:20,887] Trial 55 finished with value: 0.9223459507042253 and parameters: {'C': 1.5786482711508927, 'solver': 'liblinear', 'penalty_lib': 'l2'}. Best is trial 18 with value: 0.924935236418511.\n",
      "[I 2025-12-23 21:40:20,971] Trial 56 finished with value: 0.924935236418511 and parameters: {'C': 0.5907935292693404, 'solver': 'liblinear', 'penalty_lib': 'l1'}. Best is trial 18 with value: 0.924935236418511.\n",
      "[I 2025-12-23 21:40:21,064] Trial 57 finished with value: 0.9220303068410463 and parameters: {'C': 11.102485287705008, 'solver': 'liblinear', 'penalty_lib': 'l1'}. Best is trial 18 with value: 0.924935236418511.\n",
      "[I 2025-12-23 21:40:21,155] Trial 58 finished with value: 0.7900943158953722 and parameters: {'C': 0.01149247207857202, 'solver': 'saga', 'penalty_saga': 'elasticnet', 'l1_ratio': 0.9665551401361858}. Best is trial 18 with value: 0.924935236418511.\n",
      "[I 2025-12-23 21:40:21,244] Trial 59 finished with value: 0.9211299044265593 and parameters: {'C': 0.09208507627423909, 'solver': 'liblinear', 'penalty_lib': 'l1'}. Best is trial 18 with value: 0.924935236418511.\n",
      "[I 2025-12-23 21:40:21,325] Trial 60 finished with value: 0.904378772635815 and parameters: {'C': 0.044590736646899096, 'solver': 'liblinear', 'penalty_lib': 'l1'}. Best is trial 18 with value: 0.924935236418511.\n",
      "[I 2025-12-23 21:40:21,408] Trial 61 finished with value: 0.9245780935613682 and parameters: {'C': 0.45777040298447264, 'solver': 'liblinear', 'penalty_lib': 'l1'}. Best is trial 18 with value: 0.924935236418511.\n",
      "[I 2025-12-23 21:40:21,498] Trial 62 finished with value: 0.924622736418511 and parameters: {'C': 0.781817481024372, 'solver': 'liblinear', 'penalty_lib': 'l1'}. Best is trial 18 with value: 0.924935236418511.\n",
      "[I 2025-12-23 21:40:21,583] Trial 63 finished with value: 0.9241410965794771 and parameters: {'C': 0.20238940527589383, 'solver': 'liblinear', 'penalty_lib': 'l1'}. Best is trial 18 with value: 0.924935236418511.\n",
      "[I 2025-12-23 21:40:21,677] Trial 64 finished with value: 0.9228351358148894 and parameters: {'C': 2.4391283612569796, 'solver': 'liblinear', 'penalty_lib': 'l1'}. Best is trial 18 with value: 0.924935236418511.\n",
      "[I 2025-12-23 21:40:21,774] Trial 65 finished with value: 0.9248899647887324 and parameters: {'C': 0.5353079775398243, 'solver': 'liblinear', 'penalty_lib': 'l1'}. Best is trial 18 with value: 0.924935236418511.\n",
      "[I 2025-12-23 21:40:21,864] Trial 66 finished with value: 0.9236846076458752 and parameters: {'C': 1.2627611950870523, 'solver': 'liblinear', 'penalty_lib': 'l1'}. Best is trial 18 with value: 0.924935236418511.\n",
      "[I 2025-12-23 21:40:22,103] Trial 67 finished with value: 0.9225660211267606 and parameters: {'C': 4.260227504868381, 'solver': 'saga', 'penalty_saga': 'l1'}. Best is trial 18 with value: 0.924935236418511.\n",
      "[I 2025-12-23 21:40:22,181] Trial 68 finished with value: 0.9245328219315896 and parameters: {'C': 0.3233013438380429, 'solver': 'liblinear', 'penalty_lib': 'l1'}. Best is trial 18 with value: 0.924935236418511.\n",
      "[I 2025-12-23 21:40:22,280] Trial 69 finished with value: 0.9227665995975857 and parameters: {'C': 0.12628325786763844, 'solver': 'lbfgs', 'penalty_lbfgs': 'l2'}. Best is trial 18 with value: 0.924935236418511.\n",
      "[I 2025-12-23 21:40:22,365] Trial 70 finished with value: 0.9224779929577466 and parameters: {'C': 2.1417125655427673, 'solver': 'liblinear', 'penalty_lib': 'l2'}. Best is trial 18 with value: 0.924935236418511.\n",
      "[I 2025-12-23 21:40:22,444] Trial 71 finished with value: 0.924935236418511 and parameters: {'C': 0.6261732830393956, 'solver': 'liblinear', 'penalty_lib': 'l1'}. Best is trial 18 with value: 0.924935236418511.\n",
      "[I 2025-12-23 21:40:22,524] Trial 72 finished with value: 0.924935865191147 and parameters: {'C': 0.6607331317635029, 'solver': 'liblinear', 'penalty_lib': 'l1'}. Best is trial 72 with value: 0.924935865191147.\n",
      "[I 2025-12-23 21:40:22,605] Trial 73 finished with value: 0.9245397384305836 and parameters: {'C': 0.2125044559835885, 'solver': 'liblinear', 'penalty_lib': 'l1'}. Best is trial 72 with value: 0.924935865191147.\n",
      "[I 2025-12-23 21:40:22,688] Trial 74 finished with value: 0.9237292505030181 and parameters: {'C': 1.3350095137318219, 'solver': 'liblinear', 'penalty_lib': 'l1'}. Best is trial 72 with value: 0.924935865191147.\n",
      "[I 2025-12-23 21:40:22,765] Trial 75 finished with value: 0.913577087525151 and parameters: {'C': 0.05875146545523516, 'solver': 'liblinear', 'penalty_lib': 'l1'}. Best is trial 72 with value: 0.924935865191147.\n",
      "[I 2025-12-23 21:40:22,843] Trial 76 finished with value: 0.5 and parameters: {'C': 4.2391748257400845e-05, 'solver': 'liblinear', 'penalty_lib': 'l1'}. Best is trial 72 with value: 0.924935865191147.\n",
      "[I 2025-12-23 21:40:22,922] Trial 77 finished with value: 0.9248905935613683 and parameters: {'C': 0.5951144717254172, 'solver': 'liblinear', 'penalty_lib': 'l1'}. Best is trial 72 with value: 0.924935865191147.\n",
      "[I 2025-12-23 21:40:23,014] Trial 78 finished with value: 0.9222535211267605 and parameters: {'C': 7.263342986135752, 'solver': 'liblinear', 'penalty_lib': 'l1'}. Best is trial 72 with value: 0.924935865191147.\n",
      "C:\\Users\\APUESTAS\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\APUESTAS\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\APUESTAS\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\APUESTAS\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\APUESTAS\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1232: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "[I 2025-12-23 21:40:23,122] Trial 79 finished with value: 0.9219416498993963 and parameters: {'C': 0.0024999837041580074, 'solver': 'saga', 'penalty_saga': None}. Best is trial 72 with value: 0.924935865191147.\n",
      "[I 2025-12-23 21:40:23,205] Trial 80 finished with value: 0.9246661217303822 and parameters: {'C': 0.3497004934181315, 'solver': 'liblinear', 'penalty_lib': 'l1'}. Best is trial 72 with value: 0.924935865191147.\n",
      "[I 2025-12-23 21:40:23,291] Trial 81 finished with value: 0.924622736418511 and parameters: {'C': 0.7827354188962027, 'solver': 'liblinear', 'penalty_lib': 'l1'}. Best is trial 72 with value: 0.924935865191147.\n",
      "[I 2025-12-23 21:40:23,371] Trial 82 finished with value: 0.924354879275654 and parameters: {'C': 0.9333410299627253, 'solver': 'liblinear', 'penalty_lib': 'l1'}. Best is trial 72 with value: 0.924935865191147.\n",
      "[I 2025-12-23 21:40:23,451] Trial 83 finished with value: 0.9233463279678068 and parameters: {'C': 0.13863016569460992, 'solver': 'liblinear', 'penalty_lib': 'l1'}. Best is trial 72 with value: 0.924935865191147.\n",
      "[I 2025-12-23 21:40:23,538] Trial 84 finished with value: 0.9226999496981891 and parameters: {'C': 3.3986099982751, 'solver': 'liblinear', 'penalty_lib': 'l1'}. Best is trial 72 with value: 0.924935865191147.\n",
      "[I 2025-12-23 21:40:23,621] Trial 85 finished with value: 0.9248899647887324 and parameters: {'C': 0.5376804286215316, 'solver': 'liblinear', 'penalty_lib': 'l1'}. Best is trial 72 with value: 0.924935865191147.\n",
      "[I 2025-12-23 21:40:23,724] Trial 86 finished with value: 0.9232928822937627 and parameters: {'C': 0.25106460807903924, 'solver': 'lbfgs', 'penalty_lbfgs': 'l2'}. Best is trial 72 with value: 0.924935865191147.\n",
      "[I 2025-12-23 21:40:23,806] Trial 87 finished with value: 0.9231922786720324 and parameters: {'C': 1.8423534313091523, 'solver': 'liblinear', 'penalty_lib': 'l1'}. Best is trial 72 with value: 0.924935865191147.\n",
      "[I 2025-12-23 21:40:23,881] Trial 88 finished with value: 0.9222585513078471 and parameters: {'C': 1.0419629259578354, 'solver': 'liblinear', 'penalty_lib': 'l2'}. Best is trial 72 with value: 0.924935865191147.\n",
      "[I 2025-12-23 21:40:23,965] Trial 89 finished with value: 0.924891222334004 and parameters: {'C': 0.6393047515097572, 'solver': 'liblinear', 'penalty_lib': 'l1'}. Best is trial 72 with value: 0.924935865191147.\n",
      "[I 2025-12-23 21:40:24,044] Trial 90 finished with value: 0.9245328219315896 and parameters: {'C': 0.39346599355718864, 'solver': 'liblinear', 'penalty_lib': 'l1'}. Best is trial 72 with value: 0.924935865191147.\n",
      "[I 2025-12-23 21:40:24,122] Trial 91 finished with value: 0.924935236418511 and parameters: {'C': 0.5723429191729282, 'solver': 'liblinear', 'penalty_lib': 'l1'}. Best is trial 72 with value: 0.924935865191147.\n",
      "[I 2025-12-23 21:40:24,205] Trial 92 finished with value: 0.9240536971830986 and parameters: {'C': 0.1840352250674359, 'solver': 'liblinear', 'penalty_lib': 'l1'}. Best is trial 72 with value: 0.924935865191147.\n",
      "[I 2025-12-23 21:40:24,299] Trial 93 finished with value: 0.924891222334004 and parameters: {'C': 0.6541999917753888, 'solver': 'liblinear', 'penalty_lib': 'l1'}. Best is trial 72 with value: 0.924935865191147.\n",
      "[I 2025-12-23 21:40:24,382] Trial 94 finished with value: 0.9236846076458753 and parameters: {'C': 1.368169370532372, 'solver': 'liblinear', 'penalty_lib': 'l1'}. Best is trial 72 with value: 0.924935865191147.\n",
      "[I 2025-12-23 21:40:24,462] Trial 95 finished with value: 0.9217058601609658 and parameters: {'C': 0.1033119608324598, 'solver': 'liblinear', 'penalty_lib': 'l1'}. Best is trial 72 with value: 0.924935865191147.\n",
      "[I 2025-12-23 21:40:24,543] Trial 96 finished with value: 0.9245774647887324 and parameters: {'C': 0.3459957066302096, 'solver': 'liblinear', 'penalty_lib': 'l1'}. Best is trial 72 with value: 0.924935865191147.\n",
      "[I 2025-12-23 21:40:24,622] Trial 97 finished with value: 0.9248905935613683 and parameters: {'C': 0.606343285225629, 'solver': 'liblinear', 'penalty_lib': 'l1'}. Best is trial 72 with value: 0.924935865191147.\n",
      "[I 2025-12-23 21:40:24,711] Trial 98 finished with value: 0.9227458501006037 and parameters: {'C': 2.5387813607798684, 'solver': 'liblinear', 'penalty_lib': 'l1'}. Best is trial 72 with value: 0.924935865191147.\n",
      "[I 2025-12-23 21:40:24,955] Trial 99 finished with value: 0.9223025653923542 and parameters: {'C': 1.0218571345851377, 'solver': 'saga', 'penalty_saga': 'elasticnet', 'l1_ratio': 0.00022221182865578282}. Best is trial 72 with value: 0.924935865191147.\n",
      "[I 2025-12-23 21:40:24,996] A new study created in memory with name: no-name-96a9b18d-40c3-4b5e-a92d-a8dbccf31a3a\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[34  5]\n",
      " [ 2 34]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.87      0.91        39\n",
      "           1       0.87      0.94      0.91        36\n",
      "\n",
      "    accuracy                           0.91        75\n",
      "   macro avg       0.91      0.91      0.91        75\n",
      "weighted avg       0.91      0.91      0.91        75\n",
      "\n",
      "ROC-AUC Score: 0.9537\n",
      "score in training 0.8688524590163934\n",
      "score in testing 0.9066666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-23 21:40:26,256] Trial 0 finished with value: 0.9156356891348088 and parameters: {'n_estimators': 154, 'max_depth': 11, 'min_samples_split': 7, 'min_samples_leaf': 2, 'max_features': None, 'criterion': 'gini'}. Best is trial 0 with value: 0.9156356891348088.\n",
      "[I 2025-12-23 21:40:27,889] Trial 1 finished with value: 0.9280633802816901 and parameters: {'n_estimators': 212, 'max_depth': 27, 'min_samples_split': 19, 'min_samples_leaf': 3, 'max_features': 'sqrt', 'criterion': 'gini'}. Best is trial 1 with value: 0.9280633802816901.\n",
      "[I 2025-12-23 21:40:29,489] Trial 2 finished with value: 0.9191118586519114 and parameters: {'n_estimators': 205, 'max_depth': 25, 'min_samples_split': 13, 'min_samples_leaf': 12, 'max_features': None, 'criterion': 'gini'}. Best is trial 1 with value: 0.9280633802816901.\n",
      "[I 2025-12-23 21:40:32,258] Trial 3 finished with value: 0.9296730382293761 and parameters: {'n_estimators': 378, 'max_depth': 20, 'min_samples_split': 13, 'min_samples_leaf': 5, 'max_features': 'sqrt', 'criterion': 'gini'}. Best is trial 3 with value: 0.9296730382293761.\n",
      "[I 2025-12-23 21:40:33,064] Trial 4 finished with value: 0.92815203722334 and parameters: {'n_estimators': 82, 'max_depth': 9, 'min_samples_split': 16, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'criterion': 'entropy'}. Best is trial 3 with value: 0.9296730382293761.\n",
      "[I 2025-12-23 21:40:34,455] Trial 5 finished with value: 0.9258915995975855 and parameters: {'n_estimators': 169, 'max_depth': 22, 'min_samples_split': 16, 'min_samples_leaf': 14, 'max_features': 'log2', 'criterion': 'gini'}. Best is trial 3 with value: 0.9296730382293761.\n",
      "[I 2025-12-23 21:40:37,928] Trial 6 finished with value: 0.9306124245472835 and parameters: {'n_estimators': 484, 'max_depth': 24, 'min_samples_split': 14, 'min_samples_leaf': 1, 'max_features': 'log2', 'criterion': 'entropy'}. Best is trial 6 with value: 0.9306124245472835.\n",
      "[I 2025-12-23 21:40:38,605] Trial 7 finished with value: 0.9178973843058351 and parameters: {'n_estimators': 67, 'max_depth': 6, 'min_samples_split': 11, 'min_samples_leaf': 14, 'max_features': None, 'criterion': 'gini'}. Best is trial 6 with value: 0.9306124245472835.\n",
      "[I 2025-12-23 21:40:39,922] Trial 8 finished with value: 0.9197594944668008 and parameters: {'n_estimators': 164, 'max_depth': 17, 'min_samples_split': 20, 'min_samples_leaf': 19, 'max_features': None, 'criterion': 'entropy'}. Best is trial 6 with value: 0.9306124245472835.\n",
      "[I 2025-12-23 21:40:40,922] Trial 9 finished with value: 0.9272126509054326 and parameters: {'n_estimators': 115, 'max_depth': 13, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'criterion': 'entropy'}. Best is trial 6 with value: 0.9306124245472835.\n",
      "[I 2025-12-23 21:40:44,490] Trial 10 finished with value: 0.9304740945674045 and parameters: {'n_estimators': 457, 'max_depth': 29, 'min_samples_split': 7, 'min_samples_leaf': 7, 'max_features': 'log2', 'criterion': 'entropy'}. Best is trial 6 with value: 0.9306124245472835.\n",
      "[I 2025-12-23 21:40:48,096] Trial 11 finished with value: 0.9301622233400403 and parameters: {'n_estimators': 469, 'max_depth': 30, 'min_samples_split': 7, 'min_samples_leaf': 7, 'max_features': 'log2', 'criterion': 'entropy'}. Best is trial 6 with value: 0.9306124245472835.\n",
      "[I 2025-12-23 21:40:51,721] Trial 12 finished with value: 0.9297132796780684 and parameters: {'n_estimators': 491, 'max_depth': 30, 'min_samples_split': 8, 'min_samples_leaf': 8, 'max_features': 'log2', 'criterion': 'entropy'}. Best is trial 6 with value: 0.9306124245472835.\n",
      "[I 2025-12-23 21:40:54,205] Trial 13 finished with value: 0.9289530935613681 and parameters: {'n_estimators': 338, 'max_depth': 24, 'min_samples_split': 3, 'min_samples_leaf': 8, 'max_features': 'log2', 'criterion': 'entropy'}. Best is trial 6 with value: 0.9306124245472835.\n",
      "[I 2025-12-23 21:40:56,982] Trial 14 finished with value: 0.9316366951710261 and parameters: {'n_estimators': 380, 'max_depth': 19, 'min_samples_split': 10, 'min_samples_leaf': 5, 'max_features': 'log2', 'criterion': 'entropy'}. Best is trial 14 with value: 0.9316366951710261.\n",
      "[I 2025-12-23 21:40:59,338] Trial 15 finished with value: 0.9315033953722335 and parameters: {'n_estimators': 323, 'max_depth': 18, 'min_samples_split': 10, 'min_samples_leaf': 5, 'max_features': 'log2', 'criterion': 'entropy'}. Best is trial 14 with value: 0.9316366951710261.\n",
      "[I 2025-12-23 21:41:01,572] Trial 16 finished with value: 0.9313223088531186 and parameters: {'n_estimators': 302, 'max_depth': 17, 'min_samples_split': 10, 'min_samples_leaf': 5, 'max_features': 'log2', 'criterion': 'entropy'}. Best is trial 14 with value: 0.9316366951710261.\n",
      "[I 2025-12-23 21:41:04,574] Trial 17 finished with value: 0.9316348088531188 and parameters: {'n_estimators': 400, 'max_depth': 14, 'min_samples_split': 4, 'min_samples_leaf': 5, 'max_features': 'log2', 'criterion': 'entropy'}. Best is trial 14 with value: 0.9316366951710261.\n",
      "[I 2025-12-23 21:41:07,605] Trial 18 finished with value: 0.9250873993963783 and parameters: {'n_estimators': 408, 'max_depth': 3, 'min_samples_split': 4, 'min_samples_leaf': 11, 'max_features': 'log2', 'criterion': 'entropy'}. Best is trial 14 with value: 0.9316366951710261.\n",
      "[I 2025-12-23 21:41:09,813] Trial 19 finished with value: 0.928600352112676 and parameters: {'n_estimators': 271, 'max_depth': 13, 'min_samples_split': 4, 'min_samples_leaf': 9, 'max_features': 'log2', 'criterion': 'entropy'}. Best is trial 14 with value: 0.9316366951710261.\n",
      "[I 2025-12-23 21:41:10,573] A new study created in memory with name: no-name-ef37ee0f-e2e6-48ef-8131-f488d3973107\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[34  5]\n",
      " [ 2 34]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.87      0.91        39\n",
      "           1       0.87      0.94      0.91        36\n",
      "\n",
      "    accuracy                           0.91        75\n",
      "   macro avg       0.91      0.91      0.91        75\n",
      "weighted avg       0.91      0.91      0.91        75\n",
      "\n",
      "ROC-AUC Score: 0.9601\n",
      "score in training 0.9031296572280179\n",
      "score in testing 0.9066666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-23 21:41:10,789] Trial 0 finished with value: 0.9225710513078471 and parameters: {'C': 1.1730686120982512, 'kernel': 'linear', 'gamma': 'scale'}. Best is trial 0 with value: 0.9225710513078471.\n",
      "[I 2025-12-23 21:41:11,078] Trial 1 finished with value: 0.8969944668008047 and parameters: {'C': 0.005034375566273604, 'kernel': 'poly', 'gamma': 'scale'}. Best is trial 0 with value: 0.9225710513078471.\n",
      "[I 2025-12-23 21:41:11,376] Trial 2 finished with value: 0.9084840291750502 and parameters: {'C': 5.548779365971086, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 0 with value: 0.9225710513078471.\n",
      "[I 2025-12-23 21:41:11,577] Trial 3 finished with value: 0.9152357897384306 and parameters: {'C': 0.003272938132454389, 'kernel': 'linear', 'gamma': 'auto'}. Best is trial 0 with value: 0.9225710513078471.\n",
      "[I 2025-12-23 21:41:11,923] Trial 4 finished with value: 0.8735965794768612 and parameters: {'C': 380.7464143721494, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 0 with value: 0.9225710513078471.\n",
      "[I 2025-12-23 21:41:12,753] Trial 5 finished with value: 0.9217674798792757 and parameters: {'C': 12.597206440743966, 'kernel': 'linear', 'gamma': 'scale'}. Best is trial 0 with value: 0.9225710513078471.\n",
      "[I 2025-12-23 21:41:13,072] Trial 6 finished with value: 0.9125282947686116 and parameters: {'C': 3.110499632486964, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 0 with value: 0.9225710513078471.\n",
      "[I 2025-12-23 21:41:13,316] Trial 7 finished with value: 0.9181193410462776 and parameters: {'C': 0.08119729250662032, 'kernel': 'sigmoid', 'gamma': 'scale'}. Best is trial 0 with value: 0.9225710513078471.\n",
      "[I 2025-12-23 21:41:13,598] Trial 8 finished with value: 0.9148314889336018 and parameters: {'C': 10.596192080265824, 'kernel': 'rbf', 'gamma': 'auto'}. Best is trial 0 with value: 0.9225710513078471.\n",
      "[I 2025-12-23 21:41:13,772] Trial 9 finished with value: 0.8514518360160966 and parameters: {'C': 39.94028938775811, 'kernel': 'sigmoid', 'gamma': 'auto'}. Best is trial 0 with value: 0.9225710513078471.\n",
      "[I 2025-12-23 21:41:13,944] Trial 10 finished with value: 0.9221761820925553 and parameters: {'C': 0.23606535239532742, 'kernel': 'linear', 'gamma': 'auto'}. Best is trial 0 with value: 0.9225710513078471.\n",
      "[I 2025-12-23 21:41:14,109] Trial 11 finished with value: 0.921783199195171 and parameters: {'C': 0.12211125328013805, 'kernel': 'linear', 'gamma': 'auto'}. Best is trial 0 with value: 0.9225710513078471.\n",
      "[I 2025-12-23 21:41:14,281] Trial 12 finished with value: 0.9219988682092556 and parameters: {'C': 0.22196760154713188, 'kernel': 'linear', 'gamma': 'auto'}. Best is trial 0 with value: 0.9225710513078471.\n",
      "[I 2025-12-23 21:41:14,464] Trial 13 finished with value: 0.9221686368209255 and parameters: {'C': 0.5327238368218279, 'kernel': 'linear', 'gamma': 'auto'}. Best is trial 0 with value: 0.9225710513078471.\n",
      "[I 2025-12-23 21:41:14,709] Trial 14 finished with value: 0.9070051559356136 and parameters: {'C': 0.02247595041165857, 'kernel': 'poly', 'gamma': 'scale'}. Best is trial 0 with value: 0.9225710513078471.\n",
      "[I 2025-12-23 21:41:14,938] Trial 15 finished with value: 0.9220353370221328 and parameters: {'C': 1.478980624622358, 'kernel': 'linear', 'gamma': 'auto'}. Best is trial 0 with value: 0.9225710513078471.\n",
      "[I 2025-12-23 21:41:15,105] Trial 16 finished with value: 0.919748490945674 and parameters: {'C': 0.023211438197593862, 'kernel': 'linear', 'gamma': 'auto'}. Best is trial 0 with value: 0.9225710513078471.\n",
      "[I 2025-12-23 21:41:19,197] Trial 17 finished with value: 0.9218121227364187 and parameters: {'C': 77.00027407364011, 'kernel': 'linear', 'gamma': 'scale'}. Best is trial 0 with value: 0.9225710513078471.\n",
      "[I 2025-12-23 21:41:19,547] Trial 18 finished with value: 0.9015329476861167 and parameters: {'C': 0.0010588749264875603, 'kernel': 'sigmoid', 'gamma': 'auto'}. Best is trial 0 with value: 0.9225710513078471.\n",
      "[I 2025-12-23 21:41:19,744] Trial 19 finished with value: 0.9220969567404426 and parameters: {'C': 0.4653249253005784, 'kernel': 'poly', 'gamma': 'scale'}. Best is trial 0 with value: 0.9225710513078471.\n",
      "[I 2025-12-23 21:41:19,905] Trial 20 finished with value: 0.9208551307847083 and parameters: {'C': 0.04287434652399011, 'kernel': 'linear', 'gamma': 'auto'}. Best is trial 0 with value: 0.9225710513078471.\n",
      "[I 2025-12-23 21:41:20,097] Trial 21 finished with value: 0.922347208249497 and parameters: {'C': 0.6028242592773023, 'kernel': 'linear', 'gamma': 'auto'}. Best is trial 0 with value: 0.9225710513078471.\n",
      "[I 2025-12-23 21:41:20,305] Trial 22 finished with value: 0.9227502515090544 and parameters: {'C': 1.0040928990791713, 'kernel': 'linear', 'gamma': 'auto'}. Best is trial 22 with value: 0.9227502515090544.\n",
      "[I 2025-12-23 21:41:20,519] Trial 23 finished with value: 0.9227502515090544 and parameters: {'C': 0.9921396321034286, 'kernel': 'linear', 'gamma': 'auto'}. Best is trial 22 with value: 0.9227502515090544.\n",
      "[I 2025-12-23 21:41:20,814] Trial 24 finished with value: 0.921946051307847 and parameters: {'C': 2.360410573157237, 'kernel': 'linear', 'gamma': 'auto'}. Best is trial 22 with value: 0.9227502515090544.\n",
      "[I 2025-12-23 21:41:22,644] Trial 25 finished with value: 0.9218567655935613 and parameters: {'C': 33.50891034259334, 'kernel': 'linear', 'gamma': 'auto'}. Best is trial 22 with value: 0.9227502515090544.\n",
      "[I 2025-12-23 21:41:22,881] Trial 26 finished with value: 0.921946680080483 and parameters: {'C': 1.5535561360944883, 'kernel': 'linear', 'gamma': 'scale'}. Best is trial 22 with value: 0.9227502515090544.\n",
      "[I 2025-12-23 21:41:23,081] Trial 27 finished with value: 0.8968636820925553 and parameters: {'C': 6.591045345433645, 'kernel': 'sigmoid', 'gamma': 'auto'}. Best is trial 22 with value: 0.9227502515090544.\n",
      "[I 2025-12-23 21:41:23,372] Trial 28 finished with value: 0.8525584758551308 and parameters: {'C': 875.5401817463506, 'kernel': 'poly', 'gamma': 'scale'}. Best is trial 22 with value: 0.9227502515090544.\n",
      "[I 2025-12-23 21:41:23,628] Trial 29 finished with value: 0.8977056086519115 and parameters: {'C': 0.007776604062522614, 'kernel': 'poly', 'gamma': 'scale'}. Best is trial 22 with value: 0.9227502515090544.\n",
      "[I 2025-12-23 21:41:23,838] Trial 30 finished with value: 0.9229728370221328 and parameters: {'C': 0.9102443217753321, 'kernel': 'linear', 'gamma': 'auto'}. Best is trial 30 with value: 0.9229728370221328.\n",
      "[I 2025-12-23 21:41:24,087] Trial 31 finished with value: 0.9227948943661971 and parameters: {'C': 1.0031643768448146, 'kernel': 'linear', 'gamma': 'auto'}. Best is trial 30 with value: 0.9229728370221328.\n",
      "[I 2025-12-23 21:41:24,296] Trial 32 finished with value: 0.9229288229376259 and parameters: {'C': 0.9300421427093369, 'kernel': 'linear', 'gamma': 'auto'}. Best is trial 30 with value: 0.9229728370221328.\n",
      "[I 2025-12-23 21:41:24,471] Trial 33 finished with value: 0.9219944668008049 and parameters: {'C': 0.2457275103023676, 'kernel': 'linear', 'gamma': 'auto'}. Best is trial 30 with value: 0.9229728370221328.\n",
      "[I 2025-12-23 21:41:24,852] Trial 34 finished with value: 0.9220806086519115 and parameters: {'C': 4.1774254908437936, 'kernel': 'linear', 'gamma': 'auto'}. Best is trial 30 with value: 0.9229728370221328.\n",
      "[I 2025-12-23 21:41:25,069] Trial 35 finished with value: 0.9229288229376259 and parameters: {'C': 0.8734258167323755, 'kernel': 'linear', 'gamma': 'auto'}. Best is trial 30 with value: 0.9229728370221328.\n",
      "[I 2025-12-23 21:41:25,383] Trial 36 finished with value: 0.9178200452716296 and parameters: {'C': 0.11638951380388408, 'kernel': 'rbf', 'gamma': 'auto'}. Best is trial 30 with value: 0.9229728370221328.\n",
      "[I 2025-12-23 21:41:26,505] Trial 37 finished with value: 0.9219014084507042 and parameters: {'C': 18.929615411805308, 'kernel': 'linear', 'gamma': 'auto'}. Best is trial 30 with value: 0.9229728370221328.\n",
      "[I 2025-12-23 21:41:26,822] Trial 38 finished with value: 0.92190203722334 and parameters: {'C': 2.9212651254625452, 'kernel': 'linear', 'gamma': 'auto'}. Best is trial 30 with value: 0.9229728370221328.\n",
      "[I 2025-12-23 21:41:27,098] Trial 39 finished with value: 0.916518485915493 and parameters: {'C': 8.086850847607959, 'kernel': 'rbf', 'gamma': 'auto'}. Best is trial 30 with value: 0.9229728370221328.\n",
      "[I 2025-12-23 21:41:27,275] Trial 40 finished with value: 0.8360796026156943 and parameters: {'C': 140.4841661477736, 'kernel': 'sigmoid', 'gamma': 'auto'}. Best is trial 30 with value: 0.9229728370221328.\n",
      "[I 2025-12-23 21:41:27,497] Trial 41 finished with value: 0.9227502515090544 and parameters: {'C': 0.9992530376394438, 'kernel': 'linear', 'gamma': 'auto'}. Best is trial 30 with value: 0.9229728370221328.\n",
      "[I 2025-12-23 21:41:27,682] Trial 42 finished with value: 0.9223918511066398 and parameters: {'C': 0.38267174921694047, 'kernel': 'linear', 'gamma': 'auto'}. Best is trial 30 with value: 0.9229728370221328.\n",
      "[I 2025-12-23 21:41:27,900] Trial 43 finished with value: 0.9230174798792758 and parameters: {'C': 0.8736157581408729, 'kernel': 'linear', 'gamma': 'auto'}. Best is trial 43 with value: 0.9230174798792758.\n",
      "[I 2025-12-23 21:41:28,161] Trial 44 finished with value: 0.9219460513078472 and parameters: {'C': 1.8950931006389296, 'kernel': 'linear', 'gamma': 'auto'}. Best is trial 43 with value: 0.9230174798792758.\n",
      "[I 2025-12-23 21:41:28,328] Trial 45 finished with value: 0.9203590291750503 and parameters: {'C': 0.0713874927868655, 'kernel': 'linear', 'gamma': 'auto'}. Best is trial 43 with value: 0.9230174798792758.\n",
      "[I 2025-12-23 21:41:28,594] Trial 46 finished with value: 0.9214159959758552 and parameters: {'C': 4.026536288345446, 'kernel': 'rbf', 'gamma': 'auto'}. Best is trial 43 with value: 0.9230174798792758.\n",
      "[I 2025-12-23 21:41:28,789] Trial 47 finished with value: 0.9227049798792756 and parameters: {'C': 0.7116556368569998, 'kernel': 'linear', 'gamma': 'auto'}. Best is trial 43 with value: 0.9230174798792758.\n",
      "[I 2025-12-23 21:41:28,960] Trial 48 finished with value: 0.9219045523138834 and parameters: {'C': 0.2502740043169533, 'kernel': 'linear', 'gamma': 'auto'}. Best is trial 43 with value: 0.9230174798792758.\n",
      "[I 2025-12-23 21:41:29,126] Trial 49 finished with value: 0.9219171277665996 and parameters: {'C': 0.1316966458664406, 'kernel': 'linear', 'gamma': 'auto'}. Best is trial 43 with value: 0.9230174798792758.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- SVC OPTIMIZADO ---\n",
      "[[34  5]\n",
      " [ 2 34]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.87      0.91        39\n",
      "           1       0.87      0.94      0.91        36\n",
      "\n",
      "    accuracy                           0.91        75\n",
      "   macro avg       0.91      0.91      0.91        75\n",
      "weighted avg       0.91      0.91      0.91        75\n",
      "\n",
      "ROC-AUC Score: 0.9459\n",
      "score in training 0.8628912071535022\n",
      "score in testing 0.9066666666666666\n"
     ]
    }
   ],
   "source": [
    "params_finales_lr = logistic_regression_optuna(df, \"HeartDisease\")\n",
    "params_finales_rf = random_forest_optuna(df, \"HeartDisease\")\n",
    "params_finales_svc = svc_optuna(df, \"HeartDisease\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "8742fe05",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import StackingClassifier\n",
    "\n",
    "def create_triple_stacking(df, target, params_lr, params_rf, params_svc):\n",
    "    X = df.drop(columns=[target])\n",
    "    y = df[target]\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42, stratify=y)\n",
    "    \n",
    "    col_num = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "    col_cat = X.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "    \n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', StandardScaler(), col_num),\n",
    "            ('cat', OneHotEncoder(handle_unknown='ignore'), col_cat)\n",
    "        ])\n",
    "\n",
    "    penalty_lr = params_lr.get('penalty_lib') or params_lr.get('penalty_saga') or params_lr.get('penalty_lbfgs')\n",
    "    \n",
    "    model_lr = LogisticRegression(\n",
    "        C=params_lr['C'],\n",
    "        solver=params_lr['solver'],\n",
    "        penalty=penalty_lr,\n",
    "        l1_ratio=params_lr.get('l1_ratio'),\n",
    "        max_iter=2000,\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    model_rf = RandomForestClassifier(\n",
    "        n_estimators=params_rf['n_estimators'],\n",
    "        max_depth=params_rf['max_depth'],\n",
    "        min_samples_split=params_rf['min_samples_split'],\n",
    "        min_samples_leaf=params_rf['min_samples_leaf'],\n",
    "        max_features=params_rf['max_features'],\n",
    "        criterion=params_rf['criterion'],\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "    model_svc = SVC(\n",
    "        C=params_svc['C'],\n",
    "        kernel=params_svc['kernel'],\n",
    "        gamma=params_svc['gamma'],\n",
    "        probability=True,\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    base_models = [\n",
    "        ('lr', Pipeline(steps=[('preprocessor', preprocessor), ('model', model_lr)])),\n",
    "        ('rf', Pipeline(steps=[('preprocessor', preprocessor), ('model', model_rf)])),\n",
    "        ('svc', Pipeline(steps=[('preprocessor', preprocessor), ('model', model_svc)]))\n",
    "    ]\n",
    "\n",
    "    stacking_model = StackingClassifier(\n",
    "        estimators=base_models,\n",
    "        final_estimator=LogisticRegression(),\n",
    "        cv=5,\n",
    "        stack_method='predict_proba'\n",
    "    )\n",
    "\n",
    "    stacking_model.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = stacking_model.predict(X_test)\n",
    "    y_proba = stacking_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    print(\"\\n--- RESULTADOS DEL ENSAMBLE TRIPLE ---\")\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(f\"ROC-AUC Score: {roc_auc_score(y_test, y_proba):.4f}\")\n",
    "    print(f\"Score in testing: {stacking_model.score(X_test, y_test):.4f}\")\n",
    "    print(f\"Score in training: {stacking_model.score(X_train, y_train):.4f}\")\n",
    "\n",
    "    return stacking_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "9ce6c45a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- RESULTADOS DEL ENSAMBLE TRIPLE ---\n",
      "[[34  5]\n",
      " [ 2 34]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.87      0.91        39\n",
      "           1       0.87      0.94      0.91        36\n",
      "\n",
      "    accuracy                           0.91        75\n",
      "   macro avg       0.91      0.91      0.91        75\n",
      "weighted avg       0.91      0.91      0.91        75\n",
      "\n",
      "ROC-AUC Score: 0.9573\n",
      "Score in testing: 0.9067\n",
      "Score in training: 0.8882\n"
     ]
    }
   ],
   "source": [
    "# Llamas a la función de Stacking usando los resultados anteriores\n",
    "modelo_ensamble_final = create_triple_stacking(\n",
    "    df=df, \n",
    "    target=\"HeartDisease\", \n",
    "    params_lr=params_finales_lr, \n",
    "    params_rf=params_finales_rf, \n",
    "    params_svc=params_finales_svc\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "ed1b00f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "25ec0db5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ ¡Modelo guardado con éxito!\n",
      "Archivo generado: modelo_heart_disease_stacking.pkl\n"
     ]
    }
   ],
   "source": [
    "joblib.dump(modelo_ensamble_final, 'modelo_heart_disease_stacking.pkl')\n",
    "\n",
    "print(\"\\n✅ ¡Modelo guardado con éxito!\")\n",
    "print(\"Archivo generado: modelo_heart_disease_stacking.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "792dfdad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_ensemble_importance(model, X_test, y_test):\n",
    "    # Calculamos la importancia por permutación\n",
    "    results = permutation_importance(model, X_test, y_test, n_repeats=10, random_state=42, scoring='roc_auc')\n",
    "    \n",
    "    # Organizamos los datos\n",
    "    feature_importance = pd.Series(results.importances_mean, index=X_test.columns)\n",
    "    feature_importance = feature_importance.sort_values(ascending=True)\n",
    "\n",
    "    # Graficamos\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    feature_importance.plot(kind='barh', color='skyblue')\n",
    "    plt.title('Importancia de Variables: Ensamble Triple (0.95 AUC)')\n",
    "    plt.xlabel('Caída en ROC-AUC al desordenar la variable')\n",
    "    plt.show()\n",
    "\n",
    "# Uso:\n",
    "# plot_ensemble_importance(mejor_modelo_ensamble, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "4aca5c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.inspection import permutation_importance\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "937d4f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=[\"HeartDisease\"])\n",
    "y = df[\"HeartDisease\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "4478b84c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_ensemble_importance(modelo_ensamble_final, X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "640370c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "# 1. Llamamos a tu función y guardamos el objeto retornado en una variable\n",
    "modelo_ensamble_final = create_triple_stacking(\n",
    "    df, \n",
    "    \"HeartDisease\", \n",
    "    params_lr, \n",
    "    params_rf, \n",
    "    params_svc\n",
    ")\n",
    "\n",
    "# 2. Guardamos físicamente el modelo en tu computadora\n",
    "# El nombre del archivo debe coincidir con el que pusimos en la app de Streamlit\n",
    "joblib.dump(modelo_ensamble_final, 'modelo_heart_disease_stacking.pkl')\n",
    "\n",
    "print(\"\\n✅ ¡Modelo guardado con éxito!\")\n",
    "print(\"Archivo generado: modelo_heart_disease_stacking.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df3bb14c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f20ce37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "779d72cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_regression_adjusted_basemodel(df,target):\n",
    "    # 1. Dividir los datos en características (X) y objetivo (y)\n",
    "    X = df.drop(columns=[target])\n",
    "    y = df[target]\n",
    "    \n",
    "    # 2. Dividir en conjunto de entrenamiento y prueba\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "    \n",
    "    # 3. Preprocesamiento: Escalado y codificación\n",
    "    numeric_features = X.select_dtypes(include=['int64', 'float64']).columns\n",
    "    categorical_features = X.select_dtypes(include=['object', 'category']).columns\n",
    "    \n",
    "    preprocessor = ColumnTransformer(transformers=[\n",
    "        ('num', StandardScaler(), numeric_features),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
    "    ])\n",
    "    \n",
    "    # 4. Crear el pipeline con LogisticRegression\n",
    "    pipe = Pipeline(steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('classifier', LogisticRegression(solver='liblinear', random_state=42))\n",
    "    ])\n",
    "    \n",
    "    param_grid = {\n",
    "    'classifier__C': [0.001, 0.01, 0.1, 1, 10, 100], # Fuerza de regularización (menor C = más regularización)\n",
    "    'classifier__penalty': ['l1', 'l2'],             # Tipo de penalización (Lasso o Ridge)\n",
    "    'classifier__max_iter': [100, 200, 500]          # Iteraciones para converger\n",
    "    }\n",
    "\n",
    "    # 3. Configurar el GridSearchCV\n",
    "    # Usamos StratifiedKFold para mantener la proporción de clases en cada fold\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "    grid_search = GridSearchCV(\n",
    "        estimator=pipe,\n",
    "        param_grid=param_grid,\n",
    "        cv=cv,\n",
    "        scoring='roc_auc', # Puedes cambiarlo por 'f1' o 'accuracy'\n",
    "        n_jobs=-1,         # Usa todos los núcleos de tu CPU\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    # 4. Entrenar\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    # 5. Ver mejores resultados\n",
    "    print(f\"Mejor Score (AUC): {grid_search.best_score_:.4f}\")\n",
    "    print(f\"Mejores Parámetros: {grid_search.best_params_}\")\n",
    "    # --- NUEVA SECCIÓN: EXTRAER RESULTADOS POR FOLD ---\n",
    "    \n",
    "    # 1. Obtener el índice de la mejor combinación\n",
    "    best_index = grid_search.best_index_\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*30)\n",
    "    print(\"RESULTADOS POR FOLD (Mejor Modelo)\")\n",
    "    print(\"=\"*30)\n",
    "    \n",
    "    # 2. Iterar sobre los resultados de los folds para ese índice\n",
    "    for i in range(cv.n_splits):\n",
    "        fold_score = grid_search.cv_results_[f'split{i}_test_score'][best_index]\n",
    "        print(f\"Fold {i+1}: AUC = {fold_score:.4f}\")\n",
    "    \n",
    "    print(\"-\" * 30)\n",
    "    print(f\"Mejor Score Promedio (AUC): {grid_search.best_score_:.4f}\")\n",
    "    print(f\"Mejores Parámetros: {grid_search.best_params_}\")\n",
    "\n",
    "    print(\"Score in Training:\", grid_search.best_estimator_.score(X_train, y_train))\n",
    "    print(\"Score in Testing:\", grid_search.best_estimator_.score(X_test, y_test))\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    # 1. Obtener los nombres de las columnas después de la transformación\n",
    "    # Extraemos los nombres de las categorías del OneHotEncoder\n",
    "    cat_encoder = grid_search.best_estimator_.named_steps['preprocessor'].named_transformers_['cat']\n",
    "    cat_features_transformed = cat_encoder.get_feature_names_out(categorical_features)\n",
    "\n",
    "    # Combinamos nombres numéricos y categóricos transformados\n",
    "    all_features = np.concatenate([numeric_features, cat_features_transformed])\n",
    "\n",
    "    # 2. Extraer los coeficientes del mejor modelo\n",
    "    coefficients = grid_search.best_estimator_.named_steps['classifier'].coef_[0]\n",
    "\n",
    "    # 3. Crear un DataFrame para visualizar mejor\n",
    "    feature_importance = pd.DataFrame({\n",
    "        'Feature': all_features,\n",
    "        'Coefficient': coefficients\n",
    "    })\n",
    "\n",
    "    # Añadimos el valor absoluto para ordenar por importancia real (positiva o negativa)\n",
    "    feature_importance['Abs_Coefficient'] = feature_importance['Coefficient'].abs()\n",
    "    feature_importance = feature_importance.sort_values(by='Abs_Coefficient', ascending=False)\n",
    "\n",
    "    # 4. Graficar\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    colors = ['red' if c > 0 else 'blue' for c in feature_importance['Coefficient']]\n",
    "    plt.barh(feature_importance['Feature'], feature_importance['Coefficient'], color=colors)\n",
    "    plt.xlabel(\"Valor del Coeficiente (Peso)\")\n",
    "    plt.title(\"Importancia de las Variables (Modelo Logistic Regression L1)\")\n",
    "    plt.axvline(0, color='black', linestyle='--', linewidth=0.8)\n",
    "    plt.grid(axis='x', alpha=0.3)\n",
    "    plt.show()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "b0e8c47c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n",
      "Mejor Score (AUC): 0.9190\n",
      "Mejores Parámetros: {'classifier__C': 0.1, 'classifier__max_iter': 100, 'classifier__penalty': 'l1'}\n",
      "\n",
      "==============================\n",
      "RESULTADOS POR FOLD (Mejor Modelo)\n",
      "==============================\n",
      "Fold 1: AUC = 0.9393\n",
      "Fold 2: AUC = 0.8960\n",
      "Fold 3: AUC = 0.9394\n",
      "Fold 4: AUC = 0.9150\n",
      "Fold 5: AUC = 0.9054\n",
      "------------------------------\n",
      "Mejor Score Promedio (AUC): 0.9190\n",
      "Mejores Parámetros: {'classifier__C': 0.1, 'classifier__max_iter': 100, 'classifier__penalty': 'l1'}\n",
      "Score in Training: 0.8643815201192251\n",
      "Score in Testing: 0.8666666666666667\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "logistic_regression_adjusted_basemodel(df,\"HeartDisease\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a96171f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing app.py\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import optuna\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "def objective(trial, X, y):\n",
    "    # 1. Definir el espacio de búsqueda de hiperparámetros\n",
    "    n_estimators = trial.suggest_int('n_estimators', 10, 500)\n",
    "    max_depth = trial.suggest_int('max_depth', 2, 20)\n",
    "    min_samples_split = trial.suggest_int('min_samples_split', 2, 10)\n",
    "    min_samples_leaf = trial.suggest_int('min_samples_leaf', 1, 10)\n",
    "    max_features = trial.suggest_categorical('max_features', ['sqrt', 'log2', None])\n",
    "\n",
    "    # 2. Configurar el preprocesamiento (usando tu lógica anterior)\n",
    "    numeric_features = X.select_dtypes(include=['int64', 'float64']).columns\n",
    "    categorical_features = X.select_dtypes(include=['object', 'category']).columns\n",
    "    \n",
    "    preprocessor = ColumnTransformer(transformers=[\n",
    "        ('num', StandardScaler(), numeric_features),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
    "    ])\n",
    "\n",
    "    # 3. Crear el pipeline con los parámetros sugeridos por Optuna\n",
    "    clf = RandomForestClassifier(\n",
    "        n_estimators=n_estimators,\n",
    "        max_depth=max_depth,\n",
    "        min_samples_split=min_samples_split,\n",
    "        min_samples_leaf=min_samples_leaf,\n",
    "        max_features=max_features,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    pipe = Pipeline(steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('classifier', clf)\n",
    "    ])\n",
    "\n",
    "    # 4. Usar validación cruzada para evaluar la robustez del modelo\n",
    "    # Optuna buscará maximizar el promedio del ROC-AUC\n",
    "    score = cross_val_score(pipe, X, y, cv=5, scoring='roc_auc').mean()\n",
    "    \n",
    "    return score\n",
    "\n",
    "def run_optuna_optimization(df, target):\n",
    "    X = df.drop(columns=[target])\n",
    "    y = df[target]\n",
    "\n",
    "    # Crear el estudio de Optuna\n",
    "    study = optuna.create_study(direction='maximize')\n",
    "    study.optimize(lambda trial: objective(trial, X, y), n_trials=100)\n",
    "\n",
    "    print(\"\\n--- Optimización Finalizada ---\")\n",
    "    print(f\"Mejor valor (ROC-AUC): {study.best_value:.4f}\")\n",
    "    print(\"Mejores parámetros:\", study.best_params)\n",
    "    \n",
    "    return study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffc38aae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a453b99",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4990f538",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "0b328aaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting app.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile app.py\n",
    "import streamlit as st\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Configuración de la página\n",
    "st.set_page_config(page_title=\"Asistente de Diagnóstico Cardíaco\", layout=\"centered\")\n",
    "\n",
    "# 1. Cargar el modelo guardado\n",
    "@st.cache_resource\n",
    "def load_model():\n",
    "    return joblib.load('modelo_heart_disease_stacking.pkl')\n",
    "\n",
    "model = load_model()\n",
    "\n",
    "st.title(\"🏥 Sistema de Predicción de Riesgo Cardíaco\")\n",
    "st.write(\"Ingrese los datos clínicos del paciente para evaluar el riesgo de enfermedad coronaria.\")\n",
    "\n",
    "# 2. Crear la interfaz de usuario (Inputs)\n",
    "st.sidebar.header(\"Datos del Paciente\")\n",
    "\n",
    "col1, col2 = st.columns(2)\n",
    "\n",
    "with col1:\n",
    "    age = st.slider(\"Edad\", 20, 90, 50)\n",
    "    sex = st.selectbox(\"Sexo\", [\"M\", \"F\"])\n",
    "    cp = st.selectbox(\"Tipo de Dolor de Pecho\", [\"ATA\", \"NAP\", \"ASY\", \"TA\"])\n",
    "    trestbps = st.slider(\"Presión Arterial en Reposo (mm Hg)\", 80, 200, 120)\n",
    "    chol = st.slider(\"Colesterol Sérico (mm/dl)\", 100, 600, 200)\n",
    "\n",
    "with col2:\n",
    "    fbs = st.radio(\"Azúcar en sangre en ayunas > 120 mg/dl\", [1, 0])\n",
    "    restecg = st.selectbox(\"Electrocardiograma en Reposo\", [\"Normal\", \"ST\", \"LVH\"])\n",
    "    thalach = st.slider(\"Frecuencia Cardíaca Máxima\", 60, 210, 150)\n",
    "    exang = st.radio(\"Angina inducida por ejercicio\", [\"Y\", \"N\"])\n",
    "    oldpeak = st.slider(\"Depresión del ST (Oldpeak)\", 0.0, 6.0, 1.0, 0.1)\n",
    "    slope = st.selectbox(\"Pendiente del Segmento ST\", [\"Up\", \"Flat\", \"Down\"])\n",
    "\n",
    "# 3. Procesar los datos ingresados\n",
    "input_data = {\n",
    "    'Age': age, 'Sex': sex, 'ChestPainType': cp, 'RestingBP': trestbps,\n",
    "    'Cholesterol': chol, 'FastingBS': fbs, 'RestingECG': restecg,\n",
    "    'MaxHR': thalach, 'ExerciseAngina': exang, 'Oldpeak': oldpeak, 'ST_Slope': slope\n",
    "}\n",
    "\n",
    "# 4. Botón de Predicción\n",
    "if st.button(\"Analizar Riesgo\"):\n",
    "    df_input = pd.DataFrame([input_data])\n",
    "    \n",
    "    # Obtener probabilidad del modelo\n",
    "    prob = model.predict_proba(df_input)[0][1]\n",
    "    \n",
    "    st.divider()\n",
    "    \n",
    "    # Mostrar resultados\n",
    "    if prob > 0.5:\n",
    "        st.error(f\"### RIESGO ALTO DETECTADO\")\n",
    "        st.write(f\"La probabilidad estimada de enfermedad cardíaca es del **{prob*100:.2f}%**.\")\n",
    "    else:\n",
    "        st.success(f\"### RIESGO BAJO\")\n",
    "        st.write(f\"La probabilidad estimada de enfermedad cardíaca es del **{prob*100:.2f}%**.\")\n",
    "\n",
    "    st.info(\"Nota: Este sistema es una herramienta de apoyo basada en datos y no sustituye un diagnóstico médico profesional.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "983f50e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
