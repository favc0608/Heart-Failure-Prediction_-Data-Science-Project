# ğŸ«€ Heart Disease Prediction â€” End-to-End ML Pipeline

<p align="center">
  <img src="https://img.shields.io/badge/Python-3.10+-blue?style=for-the-badge&logo=python&logoColor=white" alt="Python">
  <img src="https://img.shields.io/badge/Scikit--Learn-ML-orange?style=for-the-badge&logo=scikit-learn&logoColor=white" alt="Scikit-learn">
  <img src="https://img.shields.io/badge/Streamlit-App-red?style=for-the-badge&logo=streamlit&logoColor=white" alt="Streamlit">
  <img src="https://img.shields.io/badge/Optuna-Optimization-green?style=for-the-badge" alt="Optuna">
  <img src="https://img.shields.io/badge/XGBoost-Boosting-yellow?style=for-the-badge" alt="XGBoost">
</p>

<p align="center">
  <strong>ğŸ”¬ A complete Data Science project showcasing the full ML lifecycle: from EDA to deployment</strong>
</p>

<p align="center">
  <a href="https://favc0608-heart-failure-prediction--data-science-proj-app-mxautc.streamlit.app/">
    <img src="https://img.shields.io/badge/ğŸš€ LIVE DEMO-Click Here-success?style=for-the-badge" alt="Live Demo">
  </a>
</p>

---

## ğŸ“‹ Table of Contents

- [ğŸ¯ Project Overview](#-project-overview)
- [ğŸ’¡ Key Highlights](#-key-highlights)
- [ğŸ“Š Results Summary](#-results-summary)
- [ğŸ› ï¸ Tech Stack](#ï¸-tech-stack)
- [ğŸ“ Project Structure](#-project-structure)
- [ğŸš€ Quick Start](#-quick-start)
- [ğŸ“ˆ Methodology](#-methodology)
- [ğŸ” Model Comparison](#-model-comparison)
- [ğŸ“¸ Visualizations](#-visualizations)
- [ğŸ“ Skills Demonstrated](#-skills-demonstrated)
- [ğŸ“ Future Improvements](#-future-improvements)
- [ğŸ“« Contact](#-contact)

---

## ğŸ¯ Project Overview

**Cardiovascular diseases (CVDs)** are the **#1 cause of death globally**, claiming approximately **17.9 million lives annually** (31% of all deaths worldwide). Early detection is critical for prevention and treatment.

This project builds a **machine learning pipeline** to predict heart disease risk using clinical indicators, achieving **~95% ROC-AUC** with a stacking ensemble model.

### ğŸ¥ Business Impact
| Metric | Value | Significance |
|--------|-------|--------------|
| **Recall** | 88% | Minimizes missed diagnoses (false negatives) |
| **Precision** | 85% | Reduces unnecessary interventions |
| **ROC-AUC** | 0.95 | Excellent discrimination ability |

---

## ğŸ’¡ Key Highlights

âœ… **End-to-end ML pipeline** â€” From raw data to deployed application  
âœ… **5 baseline models compared** â€” Logistic Regression, SVC, Random Forest, Decision Tree, XGBoost  
âœ… **Bayesian hyperparameter optimization** â€” Using Optuna (100+ trials)  
âœ… **Stacking ensemble** â€” Combining diverse model perspectives  
âœ… **Interactive web app** â€” Deployed on Streamlit Cloud  
âœ… **Feature importance analysis** â€” Interpretable predictions  
âœ… **Reproducible workflow** â€” Modular code structure  

---

## ğŸ“Š Results Summary

### ğŸ† Final Model Performance

| Model | Train AUC | Test AUC | Status |
|-------|:---------:|:--------:|:------:|
| Logistic Regression (baseline) | 0.94 | 0.92 | âœ… Low overfit |
| SVC (baseline) | 0.96 | 0.93 | âœ… Low overfit |
| Random Forest (baseline) | 1.00 | 0.94 | âš ï¸ Medium overfit |
| Decision Tree (baseline) | 1.00 | 0.80 | ğŸ”´ High overfit |
| XGBoost (baseline) | 1.00 | 0.91 | ğŸ”´ High overfit |
| **ğŸ¥‡ Stacking Ensemble (tuned)** | **0.97** | **0.94** | âœ… **Best model** |

> The stacking ensemble combines Logistic Regression + Random Forest + SVC with a meta-learner, achieving robust generalization.

---

## ğŸ› ï¸ Tech Stack

<table>
<tr>
<td><strong>Category</strong></td>
<td><strong>Technologies</strong></td>
</tr>
<tr>
<td>ğŸ“Š Data Processing</td>
<td>Pandas, NumPy</td>
</tr>
<tr>
<td>ğŸ¤– Machine Learning</td>
<td>Scikit-learn, XGBoost</td>
</tr>
<tr>
<td>âš™ï¸ Hyperparameter Tuning</td>
<td>Optuna (Bayesian Optimization)</td>
</tr>
<tr>
<td>ğŸ“ˆ Visualization</td>
<td>Matplotlib, Seaborn</td>
</tr>
<tr>
<td>ğŸŒ Deployment</td>
<td>Streamlit</td>
</tr>
<tr>
<td>ğŸ’¾ Model Persistence</td>
<td>Joblib</td>
</tr>
</table>

---

## ğŸ“ Project Structure

```
heart-failure-project/
â”‚
â”œâ”€â”€ ğŸ“Š data/
â”‚   â”œâ”€â”€ raw/                    # Original dataset
â”‚   â””â”€â”€ processed/              # Cleaned data (heart_clean.csv)
â”‚
â”œâ”€â”€ ğŸ““ notebooks/
â”‚   â”œâ”€â”€ eda1.ipynb             # Exploratory Data Analysis
â”‚   â”œâ”€â”€ processing.ipynb       # Data preprocessing pipeline
â”‚   â””â”€â”€ models.ipynb           # Model training & evaluation
â”‚
â”œâ”€â”€ ğŸ”§ src/
â”‚   â”œâ”€â”€ models.py              # ML functions (training, tuning, stacking)
â”‚   â””â”€â”€ visualizations.py      # Plotting utilities
â”‚
â”œâ”€â”€ ğŸ¤– model/
â”‚   â””â”€â”€ modelo_heart_disease_stacking.pkl  # Saved production model
â”‚
â”œâ”€â”€ ğŸ“ˆ reports/
â”‚   â”œâ”€â”€ figures/               # Generated visualizations
â”‚   â””â”€â”€ tables/                # Binning analysis reports
â”‚
â”œâ”€â”€ ğŸŒ app.py                  # Streamlit web application
â”œâ”€â”€ ğŸ“‹ requirements.txt        # Dependencies
â””â”€â”€ ğŸ“– README.md
```

---

## ğŸš€ Quick Start

### 1ï¸âƒ£ Clone the repository
```bash
git clone https://github.com/YOUR_USERNAME/heart-failure-project.git
cd heart-failure-project
```

### 2ï¸âƒ£ Create virtual environment
```bash
python -m venv venv
source venv/bin/activate  # Linux/Mac
venv\Scripts\activate     # Windows
```

### 3ï¸âƒ£ Install dependencies
```bash
pip install -r requirements.txt
```

### 4ï¸âƒ£ Run the Streamlit app
```bash
streamlit run app.py
```

### 5ï¸âƒ£ Or explore the notebooks
```bash
jupyter lab
# Open notebooks/models.ipynb
```

---

## ğŸ“ˆ Methodology

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    ML PIPELINE WORKFLOW                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  1. DATA LOADING          2. PREPROCESSING                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚
â”‚  â”‚ heart.csv    â”‚â”€â”€â”€â”€â”€â”€â”€â–¶â”‚ â€¢ Handle missing     â”‚              â”‚
â”‚  â”‚ (918 rows)   â”‚        â”‚ â€¢ Scale numerics     â”‚              â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚ â€¢ Encode categoricalsâ”‚              â”‚
â”‚                          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚
â”‚                                     â”‚                          â”‚
â”‚  3. BASELINE MODELS                 â–¼                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”               â”‚
â”‚  â”‚ LogReg â”‚ SVC â”‚ RF â”‚ DecisionTree â”‚ XGBoost  â”‚               â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â”‚
â”‚                          â”‚                                     â”‚
â”‚  4. HYPERPARAMETER       â–¼                                     â”‚
â”‚     OPTIMIZATION    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                            â”‚
â”‚                     â”‚   OPTUNA    â”‚ 100+ trials                â”‚
â”‚                     â”‚  Bayesian   â”‚                            â”‚
â”‚                     â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜                            â”‚
â”‚                            â”‚                                   â”‚
â”‚  5. ENSEMBLE              â–¼                                    â”‚
â”‚     STACKING       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                            â”‚
â”‚                    â”‚ LR + RF + SVCâ”‚                            â”‚
â”‚                    â”‚   â”€â”€â”€â”€â”€â”€â”€    â”‚                            â”‚
â”‚                    â”‚  Meta-LR     â”‚                            â”‚
â”‚                    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜                            â”‚
â”‚                           â”‚                                    â”‚
â”‚  6. DEPLOYMENT            â–¼                                    â”‚
â”‚                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                            â”‚
â”‚                    â”‚  Streamlit   â”‚                            â”‚
â”‚                    â”‚   Web App    â”‚                            â”‚
â”‚                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ” Model Comparison

### Baseline vs Tuned Performance

| Stage | Model | ROC-AUC | Notes |
|-------|-------|:-------:|-------|
| Baseline | Logistic Regression | 0.92 | Simple, interpretable |
| Baseline | SVC | 0.93 | Good generalization |
| Baseline | Random Forest | 0.94 | Captures non-linearity |
| **Tuned** | Logistic Regression | 0.92 | Optuna optimized |
| **Tuned** | Random Forest | 0.94 | Reduced overfitting |
| **Final** | **Stacking Ensemble** | **0.935** | **Production model/ Reduced overfitting** |


---

## ğŸ“¸ Visualizations

### Feature Correlation Heatmap
<p align="center">
  <img src="reports/figures/heatmap_correlacion.png" width="600" alt="Correlation Heatmap">
</p>

### Numerical Features vs Target
<p align="center">
  <img src="reports/figures/histogramas_numericos.png" width="600" alt="Numerical Features vs Target">
</p>

### Feature Importance (Ensemble)
<p align="center">
  <img src="reports/figures/ensemble_feature_importance.png" width="600" alt="Feature Importance">
</p>

### Categorical Features vs Target
<p align="center">
  <img src="reports/figures/categoricas_vs_target.png" width="600" alt="Categorical Analysis">
</p>

---

## ğŸ“ Skills Demonstrated

| Area | Skills |
|------|--------|
| **Data Engineering** | Data cleaning, feature engineering, preprocessing pipelines |
| **Machine Learning** | Classification, ensemble methods, cross-validation |
| **Hyperparameter Tuning** | Bayesian optimization with Optuna |
| **Model Evaluation** | ROC-AUC, precision-recall, confusion matrix analysis |
| **MLOps** | Model serialization, pipeline design, deployment |
| **Software Engineering** | Modular code, documentation, reproducibility |
| **Data Visualization** | Matplotlib, Seaborn, interpretability plots |
| **Web Development** | Streamlit interactive applications |

---

## ğŸ“ Future Improvements

- [ ] ğŸ”¬ Add SHAP values for individual prediction explanations
- [ ] ğŸ“Š Implement calibration plots (Platt scaling)
- [ ] ğŸ“± Create API endpoint with FastAPI

---

## ğŸ“« Contact

<p align="center">
  <a href="https://www.linkedin.com/in/frank-alexander-vargas-chavez-664980381/">
    <img src="https://img.shields.io/badge/LinkedIn-Connect-blue?style=for-the-badge&logo=linkedin" alt="LinkedIn">
  </a>
  <a href="mailto:frankvargaschavez201@gmail.com">
    <img src="https://img.shields.io/badge/Email-Contact-red?style=for-the-badge&logo=gmail" alt="Email">
  </a>
  <a href="https://github.com/favc0608">
    <img src="https://img.shields.io/badge/GitHub-Follow-black?style=for-the-badge&logo=github" alt="GitHub">
  </a>
</p>

---

## ğŸ“š Dataset Information

**Source:** [UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/machine-learning-databases/heart-disease/) via Kaggle

Combined from 5 heart disease datasets:
- Cleveland (303 obs.)
- Hungarian (294 obs.)
- Switzerland (123 obs.)
- Long Beach VA (200 obs.)
- Stalog Heart (270 obs.)

**Final dataset:** 918 observations, 11 clinical features

### Feature Description

| Feature | Description | Type |
|---------|-------------|------|
| Age | Patient age in years | Numeric |
| Sex | M: Male, F: Female | Categorical |
| ChestPainType | TA, ATA, NAP, ASY | Categorical |
| RestingBP | Resting blood pressure (mm Hg) | Numeric |
| Cholesterol | Serum cholesterol (mg/dl) | Numeric |
| FastingBS | Fasting blood sugar > 120 mg/dl | Binary |
| RestingECG | Normal, ST, LVH | Categorical |
| MaxHR | Maximum heart rate achieved | Numeric |
| ExerciseAngina | Exercise-induced angina (Y/N) | Binary |
| Oldpeak | ST depression | Numeric |
| ST_Slope | Up, Flat, Down | Categorical |
| **HeartDisease** | **Target: 0 = Normal, 1 = Disease** | **Binary** |

---

<p align="center">
  <strong>â­ If you found this project useful, please consider giving it a star! â­</strong>
</p>

